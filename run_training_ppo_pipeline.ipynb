{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annalia321/FastGPT/blob/main/run_training_ppo_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gCUwyevcAIbo"
      },
      "source": [
        "# Training Pipeline\n",
        "[run_training_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "uPkkiUgMAIbr"
      },
      "source": [
        "# Stage 1: Continue Pretraining\n",
        "\n",
        "第一阶段：PT(Continue PreTraining)增量预训练，在海量领域文本数据上二次预训练GPT模型，以适配领域数据分布\n",
        "\n",
        "注意：\n",
        "1. 此阶段是可选的，如果你没有海量领域文本，可以跳过此阶段，直接进行SFT阶段的有监督微调\n",
        "2. 我实验发现：做领域知识注入，SFT比PT更高效，也可以跳过PT阶段\n",
        "\n",
        "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KagKbMn0AIbu"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B\n",
        "2. 数据集：PT阶段使用的是中文天龙八部小说部分文本和英文书籍部分文本，位于`data/pretrain`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyS69_1SAIbv"
      },
      "source": [
        "## 配置运行环境\n",
        "\n",
        "本地执行可注释以下配置环境的命令，colab执行要打开注释，用于配置环境\n",
        "\n",
        "colab建议使用T4 GPU训练，设置方式：`代码执行程序 -> 更改运行时类型 -> 运行时类型：Python3，硬件加速器：GPU，GPU类型：T4 -> 保存`\n",
        "\n",
        "步骤：\n",
        "1. 下载最新代码到本地\n",
        "2. 安装依赖包\n",
        "\n",
        "依赖包如下，保证最新版本：\n",
        "\n",
        "```\n",
        "loguru\n",
        "transformers\n",
        "sentencepiece\n",
        "datasets\n",
        "tensorboard\n",
        "tqdm\n",
        "peft\n",
        "trl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "n9hIgttJAIbw",
        "outputId": "f8d6d3ee-fa0e-4b05-f179-1653abdacf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedicalGPT'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 92 (delta 17), reused 42 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 8.55 MiB | 23.91 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/MedicalGPT\n",
            "build_domain_tokenizer.py   merge_peft_adapter.py  run_ppo.sh\n",
            "chatpdf.py                  merge_tokenizers.py    run_pt.sh\n",
            "CITATION.cff                model_quant.py         run_quant.sh\n",
            "_config.yml                 openai_api.py          run_rm.sh\n",
            "CONTRIBUTING.md             orpo_training.py       run_sft.sh\n",
            "convert_dataset.py          ppo_training.py        run_training_dpo_pipeline.ipynb\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                       pretraining.py         run_training_ppo_pipeline.ipynb\n",
            "DISCLAIMER                  README_EN.md           supervised_finetuning.py\n",
            "\u001b[01;34mdocs\u001b[0m/                       README.md              template.py\n",
            "dpo_training.py             requirements.txt       validate_jsonl.py\n",
            "eval_quantize.py            reward_modeling.py     vllm_deployment.sh\n",
            "fastapi_server_demo.py      \u001b[01;34mrole_play_data\u001b[0m/        zero1.yaml\n",
            "gradio_demo.py              run_dpo.sh             zero2.json\n",
            "grpo_training.py            run_eval_quantize.sh   zero2.yaml\n",
            "inference_multigpu_demo.py  run_full_sft.sh        zero3.json\n",
            "inference.py                run_grpo.sh            zero3.yaml\n",
            "LICENSE                     run_orpo.sh\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting datasets>=2.14.6 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting loguru (from -r requirements.txt (line 3))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: peft>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Collecting transformers>=4.49.0 (from -r requirements.txt (line 9))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl>=0.15.2 (from -r requirements.txt (line 10))\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.10.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting math-verify==0.5.2 (from -r requirements.txt (line 13))\n",
            "  Downloading math_verify-0.5.2-py3-none-any.whl.metadata (347 bytes)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended->-r requirements.txt (line 12))\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended->-r requirements.txt (line 12)) (1.13.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.11.13)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (0.21.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl>=0.15.2->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->latex2sympy2_extended->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.15.2->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.15.2->-r requirements.txt (line 10)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl>=0.15.2->-r requirements.txt (line 10)) (0.1.2)\n",
            "Downloading math_verify-0.5.2-py3-none-any.whl (27 kB)\n",
            "Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: antlr4-python3-runtime, xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, latex2sympy2_extended, nvidia-cusolver-cu12, math-verify, transformers, datasets, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed antlr4-python3-runtime-4.13.2 datasets-3.4.1 dill-0.3.8 latex2sympy2_extended-1.0.6 loguru-0.7.3 math-verify-0.5.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.49.0 trl-0.15.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
        "%cd MedicalGPT\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SHicioKAIby"
      },
      "source": [
        "## Stage1 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果\n",
        "\n",
        "**以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyOwhMQbAIbz"
      },
      "outputs": [],
      "source": [
        "%ls ./data/pretrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2kKJQKbAIbz",
        "outputId": "971fc148-77e1-4511-e0cf-2f851b67e722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 16:30:59.236561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742315459.471440    6474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742315459.532665    6474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 16:31:00.029386: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 16:31:06.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m359\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/deepseek-llm-7b-base', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-pt-v1/runs/Mar18_16-31-05_5e53693f8c97,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-pt-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=3,\n",
            "per_device_train_batch_size=3,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-pt-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "tokenizer_config.json: 100% 792/792 [00:00<00:00, 4.69MB/s]\n",
            "tokenizer.json: 100% 4.61M/4.61M [00:00<00:00, 5.15MB/s]\n",
            "\u001b[32m2025-03-18 16:31:10.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m471\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/tianlongbabu.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:10.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m481\u001b[0m - \u001b[1meval files: ['./data/pretrain/tianlongbabu.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "Generating train split: 3876 examples [00:00, 140777.46 examples/s]\n",
            "Generating validation split: 3876 examples [00:00, 401301.43 examples/s]\n",
            "\u001b[32m2025-03-18 16:31:11.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m513\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "})\u001b[0m\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:01<00:00, 3633.57 examples/s]\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:00<00:00, 4059.27 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 5101.95 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 8156.30 examples/s]\n",
            "\u001b[32m2025-03-18 16:31:15.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m576\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2646\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m577\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.218\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m578\u001b[0m - \u001b[34m\u001b[1m<｜begin▁of▁sentence｜>天龙八部\n",
            "<｜begin▁of▁sentence｜>\n",
            "<｜begin▁of▁sentence｜>\n",
            "<｜begin▁of▁sentence｜>正文 释名\n",
            "<｜begin▁of▁sentence｜>“天龙八部”这名词出于佛经。许多大乘佛经叙述佛向诸菩萨、比丘等说法时，崐常有天龙八部参与听法。如“法华经：提婆达多品”：“天龙八部、人与非人，皆崐遥见彼龙女成佛”。\n",
            "<｜begin▁of▁sentence｜>“非人”，包括八种神道怪物，因为以“天”及“龙”为首，崐所以称为《天龙八部\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m590\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m591\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.221\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m592\u001b[0m - \u001b[34m\u001b[1m<｜begin▁of▁sentence｜>天龙八部\n",
            "<｜begin▁of▁sentence｜>\n",
            "<｜begin▁of▁sentence｜>\n",
            "<｜begin▁of▁sentence｜>正文 释名\n",
            "<｜begin▁of▁sentence｜>“天龙八部”这名词出于佛经。许多大乘佛经叙述佛向诸菩萨、比丘等说法时，崐常有天龙八部参与听法。如“法华经：提婆达多品”：“天龙八部、人与非人，皆崐遥见彼龙女成佛”。\n",
            "<｜begin▁of▁sentence｜>“非人”，包括八种神道怪物，因为以“天”及“龙”为首，崐所以称为《天龙八部\u001b[0m\n",
            "config.json: 100% 584/584 [00:00<00:00, 4.11MB/s]\n",
            "pytorch_model.bin.index.json: 100% 22.5k/22.5k [00:00<00:00, 86.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.97G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.97G [00:00<00:52, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.97G [00:00<00:43, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 83.9M/9.97G [00:00<00:42, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.97G [00:00<00:43, 227MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.97G [00:00<00:43, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.97G [00:00<00:40, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.97G [00:00<00:41, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 241M/9.97G [00:01<00:40, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.97G [00:01<01:15, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.97G [00:01<01:02, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.97G [00:01<00:53, 181MB/s]\u001b[A\n",
            "\n",
            "model.safetensors.index.json: 100% 23.6k/23.6k [00:00<00:00, 61.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 367M/9.97G [00:01<00:50, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.97G [00:02<00:46, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.97G [00:02<00:44, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.97G [00:02<00:43, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.97G [00:02<00:41, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.97G [00:02<00:41, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.97G [00:02<00:42, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.97G [00:02<00:41, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 619M/9.97G [00:02<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.97G [00:03<00:39, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 682M/9.97G [00:03<00:39, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.97G [00:03<00:40, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.97G [00:03<00:40, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 776M/9.97G [00:03<00:39, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.97G [00:03<00:39, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.97G [00:03<00:41, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 870M/9.97G [00:04<00:39, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 902M/9.97G [00:04<00:40, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 933M/9.97G [00:04<00:39, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.97G [00:04<00:36, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.97G [00:04<00:35, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.97G [00:04<00:37, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.97G [00:04<00:37, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.97G [00:04<00:37, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.97G [00:05<00:38, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.97G [00:05<00:36, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.97G [00:05<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.97G [00:05<00:33, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.97G [00:05<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.97G [00:05<00:35, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.31G/9.97G [00:05<00:36, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.97G [00:05<00:34, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.97G [00:06<00:38, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.97G [00:06<00:37, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.97G [00:06<00:36, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.97G [00:06<00:36, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.97G [00:06<00:36, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.97G [00:06<00:36, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.97G [00:06<00:35, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.97G [00:07<00:33, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.97G [00:07<00:33, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.97G [00:07<00:34, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.97G [00:07<00:35, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.97G [00:07<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.97G [00:07<00:36, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.97G [00:07<00:35, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.97G [00:07<00:34, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.85G/9.97G [00:08<00:34, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.97G [00:08<00:34, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.97G [00:08<00:40, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.97G [00:08<00:38, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.97G [00:08<00:36, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.97G [00:08<00:35, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.97G [00:09<00:35, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.97G [00:09<00:34, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.97G [00:09<00:43, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.97G [00:09<00:40, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.97G [00:09<00:37, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.97G [00:09<00:36, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.97G [00:09<00:35, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.97G [00:10<00:37, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.97G [00:10<00:40, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.97G [00:10<00:38, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.97G [00:10<00:47, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.97G [00:10<00:41, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.97G [00:10<00:40, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.97G [00:11<00:42, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.44G/9.97G [00:11<00:43, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.97G [00:11<00:42, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.97G [00:11<00:41, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.97G [00:11<00:40, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.97G [00:11<00:38, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.97G [00:11<00:39, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.97G [00:18<10:52, 11.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.97G [00:18<06:14, 19.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.97G [00:18<04:24, 27.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.97G [00:18<03:09, 38.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.97G [00:18<02:19, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.97G [00:18<01:48, 66.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.97G [00:19<01:22, 87.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.97G [00:19<01:05, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.84G/9.97G [00:19<00:54, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.97G [00:19<00:46, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.97G [00:19<00:40, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.97G [00:19<00:37, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.97G [00:19<00:34, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.97G [00:19<00:32, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.97G [00:20<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.97G [00:20<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.97G [00:20<00:37, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.97G [00:20<00:35, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.97G [00:20<00:32, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.97G [00:20<00:31, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.97G [00:21<00:30, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.97G [00:21<01:01, 109MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.97G [00:21<00:55, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.97G [00:22<02:13, 50.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.97G [00:24<03:40, 30.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.97G [00:24<02:30, 44.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.97G [00:24<01:48, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.97G [00:24<01:22, 79.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.44G/9.97G [00:24<01:04, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.47G/9.97G [00:25<00:52, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.50G/9.97G [00:25<00:44, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.97G [00:25<00:39, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.97G [00:25<00:36, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.60G/9.97G [00:25<00:33, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.63G/9.97G [00:25<00:31, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.97G [00:25<00:30, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.69G/9.97G [00:26<00:30, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.97G [00:26<00:28, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.97G [00:26<00:28, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.97G [00:26<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.97G [00:27<01:26, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.84G/9.97G [00:27<01:14, 82.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.97G [00:28<02:14, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.97G [00:28<01:37, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.97G [00:29<01:12, 83.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.97G [00:29<00:56, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.97G [00:29<00:48, 122MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.97G [00:29<00:41, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.97G [00:29<00:35, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.97G [00:29<00:32, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.97G [00:30<00:41, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.97G [00:30<00:36, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.97G [00:30<00:35, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.19G/9.97G [00:31<01:33, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.97G [00:31<01:17, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.97G [00:32<02:18, 41.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.97G [00:34<03:38, 26.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.97G [00:34<02:25, 39.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.97G [00:34<01:43, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.97G [00:34<01:17, 72.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.97G [00:34<01:05, 85.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.97G [00:35<00:50, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.44G/9.97G [00:35<00:41, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.97G [00:35<00:35, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.97G [00:35<00:34, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.97G [00:35<00:30, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.97G [00:35<00:28, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.97G [00:35<00:26, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.97G [00:36<00:24, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.97G [00:36<00:25, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.97G [00:36<00:28, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.71G/9.97G [00:38<02:34, 34.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.97G [00:38<01:49, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.97G [00:39<01:21, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.97G [00:39<01:02, 82.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.97G [00:39<00:49, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.97G [00:39<00:40, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.97G [00:39<00:34, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.97G [00:39<00:30, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.97G [00:39<00:27, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.97G [00:39<00:25, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.97G [00:40<00:23, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.97G [00:40<00:22, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.97G [00:40<00:22, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.12G/9.97G [00:40<00:20, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.97G [00:40<00:20, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.97G [00:40<00:20, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.97G [00:40<00:24, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.97G [00:41<00:23, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.97G [00:41<00:24, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.97G [00:41<00:23, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.97G [00:41<00:24, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.34G/9.97G [00:41<00:38, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.97G [00:42<00:57, 80.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.97G [00:47<05:26, 14.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.97G [00:47<03:29, 21.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.97G [00:47<02:22, 31.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.97G [00:47<01:40, 44.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.97G [00:47<01:14, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.54G/9.97G [00:47<00:56, 79.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.97G [00:47<00:43, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.97G [00:47<00:36, 119MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.97G [00:48<00:32, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.97G [00:48<00:28, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.97G [00:48<00:25, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.97G [00:48<00:23, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.97G [00:48<00:22, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.97G [00:48<00:21, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.97G [00:48<00:20, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.97G [00:49<00:19, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.97G [00:49<00:19, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.97G [00:49<00:19, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.97G [00:49<00:21, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.97G [00:49<00:27, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.97G [00:50<00:23, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.03G/9.97G [00:54<03:35, 18.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.97G [00:55<03:01, 21.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.97G [00:55<02:19, 27.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.97G [00:55<01:35, 40.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.97G [00:55<01:15, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.97G [00:55<00:54, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.97G [00:55<00:41, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.97G [00:55<00:32, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.97G [00:56<00:28, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.97G [00:56<00:23, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.97G [00:56<00:21, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.97G [00:56<00:19, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.97G [00:56<00:18, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.97G [00:56<00:17, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.97G [00:56<00:16, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.97G [00:57<00:16, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.53G/9.97G [00:57<00:14, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.97G [00:57<00:14, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.97G [00:57<00:14, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.97G [00:57<00:13, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.97G [00:58<00:13, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.97G [00:58<00:13, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.97G [00:58<00:13, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.97G [00:58<00:13, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.97G [00:58<00:12, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.97G [00:58<00:12, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.97G [00:58<00:12, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.97G [00:59<00:13, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.97G [00:59<00:12, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.97G [00:59<00:11, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.97G [00:59<00:12, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.97G [00:59<00:11, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.97G [00:59<00:11, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.13G/9.97G [00:59<00:11, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.97G [00:59<00:11, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.97G [01:00<00:11, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.97G [01:00<00:11, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.97G [01:00<00:11, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.97G [01:00<00:11, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.97G [01:00<00:11, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.97G [01:00<00:11, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.97G [01:00<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.97G [01:01<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.97G [01:01<00:10, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.97G [01:01<00:10, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.97G [01:01<00:10, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.97G [01:01<00:10, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.97G [01:01<00:10, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.97G [01:07<02:18, 17.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.62G/9.97G [01:07<01:49, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.97G [01:07<01:25, 27.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.97G [01:07<00:59, 38.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.97G [01:08<00:42, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.97G [01:08<00:31, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.97G [01:08<00:24, 90.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.97G [01:08<00:19, 113MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.97G [01:08<00:16, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.97G [01:08<00:13, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.97G [01:08<00:12, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.93G/9.97G [01:08<00:10, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.97G [01:09<00:09, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.97G [01:09<00:09, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.97G [01:09<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.97G [01:09<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.97G [01:09<00:08, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.97G [01:09<00:08, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.97G [01:09<00:07, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.97G [01:10<00:10, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.97G [01:10<00:09, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.97G [01:10<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.97G [01:10<00:08, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.30G/9.97G [01:10<00:08, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.97G [01:10<00:07, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.97G [01:11<00:07, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.97G [01:11<00:07, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.43G/9.97G [01:11<00:07, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.97G [01:11<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.97G [01:11<00:06, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.52G/9.97G [01:11<00:06, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.97G [01:11<00:06, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.97G [01:11<00:06, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.97G [01:12<00:05, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.97G [01:12<00:05, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.97G [01:12<00:05, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.71G/9.97G [01:12<00:05, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.97G [01:12<00:05, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.97G [01:12<00:05, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.97G [01:12<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.97G [01:13<00:04, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.97G [01:13<00:04, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.90G/9.97G [01:13<00:04, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.97G [01:13<00:04, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.97G/9.97G [01:13<00:04, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.00G/9.97G [01:14<00:06, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.97G [01:17<00:42, 22.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.04G/9.97G [01:17<00:33, 27.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.97G [01:18<00:22, 39.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.10G/9.97G [01:18<00:16, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.97G [01:18<00:11, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.97G [01:18<00:09, 83.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.19G/9.97G [01:18<00:07, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.97G [01:18<00:05, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.25G/9.97G [01:18<00:04, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.97G [01:19<00:04, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.97G [01:19<00:03, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.97G [01:19<00:03, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.97G [01:19<00:02, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.97G [01:19<00:02, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.44G/9.97G [01:19<00:02, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.97G [01:19<00:02, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.97G [01:19<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.97G [01:20<00:01, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.56G/9.97G [01:20<00:01, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.59G/9.97G [01:20<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.63G/9.97G [01:20<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.66G/9.97G [01:20<00:01, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.97G [01:20<00:01, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.97G [01:20<00:00, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.97G [01:20<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.97G [01:21<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.83G/9.97G [01:21<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.97G [01:23<00:03, 36.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.97G [01:24<00:01, 49.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.92G/9.97G [01:24<00:00, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.97G/9.97G [01:24<00:00, 118MB/s] \n",
            "Downloading shards:  50% 1/2 [01:24<01:24, 84.61s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.85G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.85G [00:00<00:15, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.85G [00:00<00:16, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 94.4M/3.85G [00:00<00:14, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 126M/3.85G [00:00<00:16, 233MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 157M/3.85G [00:00<00:14, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.85G [00:00<00:14, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.85G [00:00<00:14, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.85G [00:01<00:15, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 283M/3.85G [00:01<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 315M/3.85G [00:01<00:14, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 346M/3.85G [00:01<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 377M/3.85G [00:01<00:14, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 409M/3.85G [00:01<00:14, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 440M/3.85G [00:01<00:16, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 472M/3.85G [00:02<00:15, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 503M/3.85G [00:02<00:14, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 535M/3.85G [00:02<00:14, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 566M/3.85G [00:02<00:16, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 587M/3.85G [00:02<00:20, 159MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 608M/3.85G [00:05<01:58, 27.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 640M/3.85G [00:05<01:21, 39.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 682M/3.85G [00:05<00:52, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 713M/3.85G [00:05<00:40, 77.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 744M/3.85G [00:05<00:32, 96.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 776M/3.85G [00:06<00:25, 118MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 807M/3.85G [00:06<00:21, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 839M/3.85G [00:06<00:18, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 870M/3.85G [00:06<00:16, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 902M/3.85G [00:06<00:15, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 933M/3.85G [00:06<00:14, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 965M/3.85G [00:06<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 996M/3.85G [00:07<00:12, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.03G/3.85G [00:07<00:12, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.06G/3.85G [00:07<00:12, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 1.09G/3.85G [00:07<00:11, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.12G/3.85G [00:07<00:11, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.15G/3.85G [00:07<00:11, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.18G/3.85G [00:07<00:11, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.22G/3.85G [00:07<00:11, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.25G/3.85G [00:08<00:10, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.28G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.31G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.34G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.37G/3.85G [00:08<00:10, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.41G/3.85G [00:08<00:10, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.44G/3.85G [00:08<00:09, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.47G/3.85G [00:08<00:09, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.50G/3.85G [00:09<00:09, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.53G/3.85G [00:09<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.56G/3.85G [00:09<00:09, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.59G/3.85G [00:09<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.63G/3.85G [00:11<00:43, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.67G/3.85G [00:11<00:29, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.70G/3.85G [00:11<00:23, 91.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.73G/3.85G [00:11<00:19, 111MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.76G/3.85G [00:11<00:15, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.79G/3.85G [00:11<00:13, 153MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.82G/3.85G [00:12<00:11, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.86G/3.85G [00:12<00:10, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.89G/3.85G [00:12<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.92G/3.85G [00:12<00:08, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.95G/3.85G [00:12<00:08, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.98G/3.85G [00:12<00:08, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 2.01G/3.85G [00:12<00:07, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 2.04G/3.85G [00:12<00:07, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 2.08G/3.85G [00:13<00:07, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 2.11G/3.85G [00:13<00:07, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.14G/3.85G [00:13<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.17G/3.85G [00:13<00:07, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.20G/3.85G [00:13<00:06, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.23G/3.85G [00:13<00:06, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.26G/3.85G [00:13<00:06, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.30G/3.85G [00:14<00:06, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.33G/3.85G [00:14<00:06, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.36G/3.85G [00:14<00:06, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.39G/3.85G [00:14<00:05, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.42G/3.85G [00:14<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.45G/3.85G [00:14<00:05, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.49G/3.85G [00:14<00:05, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.52G/3.85G [00:14<00:05, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.55G/3.85G [00:15<00:05, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.58G/3.85G [00:15<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.62G/3.85G [00:15<00:04, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.65G/3.85G [00:15<00:04, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.68G/3.85G [00:15<00:05, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.72G/3.85G [00:15<00:05, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.75G/3.85G [00:15<00:05, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.78G/3.85G [00:16<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.81G/3.85G [00:16<00:04, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.84G/3.85G [00:16<00:04, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.87G/3.85G [00:16<00:04, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.90G/3.85G [00:16<00:04, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.94G/3.85G [00:16<00:03, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.97G/3.85G [00:16<00:03, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 3.00G/3.85G [00:17<00:03, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.03G/3.85G [00:17<00:03, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.06G/3.85G [00:17<00:03, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 3.09G/3.85G [00:17<00:03, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 3.12G/3.85G [00:17<00:03, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 3.16G/3.85G [00:17<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 3.19G/3.85G [00:17<00:02, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.22G/3.85G [00:17<00:02, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.25G/3.85G [00:18<00:02, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.28G/3.85G [00:18<00:02, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.31G/3.85G [00:18<00:02, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.34G/3.85G [00:18<00:02, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.38G/3.85G [00:18<00:01, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.41G/3.85G [00:18<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.44G/3.85G [00:18<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.47G/3.85G [00:19<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.50G/3.85G [00:19<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.53G/3.85G [00:19<00:01, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.57G/3.85G [00:19<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.60G/3.85G [00:19<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.63G/3.85G [00:19<00:00, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.66G/3.85G [00:19<00:00, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.69G/3.85G [00:19<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.72G/3.85G [00:20<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.75G/3.85G [00:20<00:00, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.79G/3.85G [00:20<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.82G/3.85G [00:20<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.85G/3.85G [00:20<00:00, 187MB/s]\n",
            "Downloading shards: 100% 2/2 [01:45<00:00, 52.73s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:58<00:00, 29.49s/it]\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 1.06MB/s]\n",
            "\u001b[32m2025-03-18 16:34:03.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m651\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m656\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m669\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m670\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 18,739,200 || all params: 6,929,104,896 || trainable%: 0.2704\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
            "  warnings.warn(\n",
            "/content/MedicalGPT/pretraining.py:700: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 16:34:04.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m715\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:05.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m716\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[ 49249,   1336,   3641,    923,    398,    976,    185, 100000,  17878,\n",
            "           1907,  19253,  61051,  19304,    443,    111,  92920,   1127,    398,\n",
            "          36867,   2266,   1680,  19304,   1671,  23639,  10741,   7560,    913,\n",
            "          19304,  67408,  33433,    398,   7664,  46964,   3160,   1759,  45326,\n",
            "            790,   1372,   4045,   1720,  52055,  17497,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,    852,   6074,  17497,  19304,  19015,\n",
            "           6342,    885,  50217,  50217,   1506,    929,   1748,  65510,  19304,\n",
            "           2830,  32845,   8375,    398,   2141,   8438,  76780,   1372,  51433,\n",
            "           7861,   7351,    398,    976,   7664,  46964,   3160,  24040,  13147,\n",
            "          84064,   6622,    504,   6214,  19304,   1759,  45326,    790,  10012,\n",
            "           1372,   1087,   1827,  13725,    398,  32508,  26273,  17878,   9457,\n",
            "          17699,  49373,  19304,  54029,    573,  99880,   3411,   2104,   2224,\n",
            "          36397,    787,  70560,    923,  24437,   1827,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,   4607,   2510,   2125,  14847,   3381,\n",
            "           9554,    537],\n",
            "        [  1848,   4276,   1507,   3672,  29371,   1662,    106,  37559,   1186,\n",
            "           1759,  19304,   4595,   1186,  33965,  37163,  20753,  19304,  22924,\n",
            "           1391,  77338,    612,  37163,   5808,   8245,  21083,    398,  19388,\n",
            "           1087,   1848,   1759,  45326,    790,  78942,   2961,   2412,    398,\n",
            "            976,    185, 100000,   4200,   2206,  65208,   1759,  45326,    790,\n",
            "          17374,   2160,   1372,   8010,  19472,   1537,    852,    398,    976,\n",
            "           2206,    892,   2657,   1186,   1759,    764,  25468,   1827,  19304,\n",
            "          16127,   3344,   2797,   4090,  91574,  78500,   3115,    505,  19370,\n",
            "          19304,   2108,   1511,   6622,    504,  16920,    398,   4200,   2206,\n",
            "          65208,  21846,  20239,   1762,  19304,  15710,   1848,  10564,  19304,\n",
            "           3846,   5093,   9066,   1759,  45326,    790,   3149,    630,   2224,\n",
            "            976,    185, 100000,  91574,   1102,   1873,    630,   3846,   5093,\n",
            "           1759,  45326,    790,   3996,  14714,   2160,  26224,  19304,  46826,\n",
            "           4547,  15315,    398,    976,  28471,   1649,  86910,   8375,    398,\n",
            "           4200,   2206],\n",
            "        [ 50836,   1854,   4779,   1965,    121,   3056,  96102,    398,   2775,\n",
            "           3056,  20631,  59241,  12295,  19304,  10435,    537,  63103,   3056,\n",
            "            573,  75993,  34126,  19304,  32101,  50836,  23212,   3056,  96102,\n",
            "           4425,     16,     15,    948,    214,   3611,  34126,  19304,  38966,\n",
            "           3056,   9467,     20,     15,      4,  19304,  15544,   3056,   4425,\n",
            "             22,     15,    948,    214,  75993,  34126,    398,    185, 100000,\n",
            "          50836,   4779,   1965,    121,   3056,  96102,  45326,  24364,  10244,\n",
            "            337,  82562,  27455,  10239,  19304,  90091,   1937,   2045,    398,\n",
            "           4779,   1965,    121,  28315,  45326,  10435,    537,  63103,   3056,\n",
            "          96102,   1762,   3175,   3310,   8092,  19304,   4425,     23,     15,\n",
            "            948,    214,   9752,    609,  48763,    537,   9093,  33770,  11527,\n",
            "            398,  23212,    537,  38966,    537,  15544,   3056,  96102,   1762,\n",
            "           3175,  14130,   3310,  11165,  19304,   4225,  31394,    609,  48763,\n",
            "            398,   2133,   2045,   5649,  16323,    609,  29587,  75471,    537,\n",
            "          53636,  89418]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[ 49249,   1336,   3641,    923,    398,    976,    185, 100000,  17878,\n",
            "           1907,  19253,  61051,  19304,    443,    111,  92920,   1127,    398,\n",
            "          36867,   2266,   1680,  19304,   1671,  23639,  10741,   7560,    913,\n",
            "          19304,  67408,  33433,    398,   7664,  46964,   3160,   1759,  45326,\n",
            "            790,   1372,   4045,   1720,  52055,  17497,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,    852,   6074,  17497,  19304,  19015,\n",
            "           6342,    885,  50217,  50217,   1506,    929,   1748,  65510,  19304,\n",
            "           2830,  32845,   8375,    398,   2141,   8438,  76780,   1372,  51433,\n",
            "           7861,   7351,    398,    976,   7664,  46964,   3160,  24040,  13147,\n",
            "          84064,   6622,    504,   6214,  19304,   1759,  45326,    790,  10012,\n",
            "           1372,   1087,   1827,  13725,    398,  32508,  26273,  17878,   9457,\n",
            "          17699,  49373,  19304,  54029,    573,  99880,   3411,   2104,   2224,\n",
            "          36397,    787,  70560,    923,  24437,   1827,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,   4607,   2510,   2125,  14847,   3381,\n",
            "           9554,    537],\n",
            "        [  1848,   4276,   1507,   3672,  29371,   1662,    106,  37559,   1186,\n",
            "           1759,  19304,   4595,   1186,  33965,  37163,  20753,  19304,  22924,\n",
            "           1391,  77338,    612,  37163,   5808,   8245,  21083,    398,  19388,\n",
            "           1087,   1848,   1759,  45326,    790,  78942,   2961,   2412,    398,\n",
            "            976,    185, 100000,   4200,   2206,  65208,   1759,  45326,    790,\n",
            "          17374,   2160,   1372,   8010,  19472,   1537,    852,    398,    976,\n",
            "           2206,    892,   2657,   1186,   1759,    764,  25468,   1827,  19304,\n",
            "          16127,   3344,   2797,   4090,  91574,  78500,   3115,    505,  19370,\n",
            "          19304,   2108,   1511,   6622,    504,  16920,    398,   4200,   2206,\n",
            "          65208,  21846,  20239,   1762,  19304,  15710,   1848,  10564,  19304,\n",
            "           3846,   5093,   9066,   1759,  45326,    790,   3149,    630,   2224,\n",
            "            976,    185, 100000,  91574,   1102,   1873,    630,   3846,   5093,\n",
            "           1759,  45326,    790,   3996,  14714,   2160,  26224,  19304,  46826,\n",
            "           4547,  15315,    398,    976,  28471,   1649,  86910,   8375,    398,\n",
            "           4200,   2206],\n",
            "        [ 50836,   1854,   4779,   1965,    121,   3056,  96102,    398,   2775,\n",
            "           3056,  20631,  59241,  12295,  19304,  10435,    537,  63103,   3056,\n",
            "            573,  75993,  34126,  19304,  32101,  50836,  23212,   3056,  96102,\n",
            "           4425,     16,     15,    948,    214,   3611,  34126,  19304,  38966,\n",
            "           3056,   9467,     20,     15,      4,  19304,  15544,   3056,   4425,\n",
            "             22,     15,    948,    214,  75993,  34126,    398,    185, 100000,\n",
            "          50836,   4779,   1965,    121,   3056,  96102,  45326,  24364,  10244,\n",
            "            337,  82562,  27455,  10239,  19304,  90091,   1937,   2045,    398,\n",
            "           4779,   1965,    121,  28315,  45326,  10435,    537,  63103,   3056,\n",
            "          96102,   1762,   3175,   3310,   8092,  19304,   4425,     23,     15,\n",
            "            948,    214,   9752,    609,  48763,    537,   9093,  33770,  11527,\n",
            "            398,  23212,    537,  38966,    537,  15544,   3056,  96102,   1762,\n",
            "           3175,  14130,   3310,  11165,  19304,   4225,  31394,    609,  48763,\n",
            "            398,   2133,   2045,   5649,  16323,    609,  29587,  75471,    537,\n",
            "          53636,  89418]], device='cuda:0')}\u001b[0m\n",
            "{'loss': 2.9201, 'grad_norm': 0.41207155585289, 'learning_rate': 4.444444444444445e-06, 'epoch': 0.0}\n",
            "{'loss': 2.7201, 'grad_norm': 0.45105651021003723, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.01}\n",
            "{'loss': 2.9258, 'grad_norm': 0.4875084161758423, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.02}\n",
            "{'loss': 2.6475, 'grad_norm': 0.9869950413703918, 'learning_rate': 0.00013333333333333334, 'epoch': 0.03}\n",
            "{'loss': 2.5974, 'grad_norm': 0.817748486995697, 'learning_rate': 0.00017777777777777779, 'epoch': 0.05}\n",
            "{'loss': 2.6202, 'grad_norm': 0.9691812992095947, 'learning_rate': 0.00019880525686977302, 'epoch': 0.06}\n",
            "  6% 50/882 [05:49<1:41:11,  7.30s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:02<00:02,  1.13s/it]\u001b[A\n",
            " 75% 3/4 [00:04<00:01,  1.61s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.321094512939453, 'eval_accuracy': 0.5448818897637795, 'eval_runtime': 7.7423, 'eval_samples_per_second': 1.292, 'eval_steps_per_second': 0.517, 'epoch': 0.06}\n",
            "  6% 50/882 [05:57<1:41:11,  7.30s/it]\n",
            "100% 4/4 [00:05<00:00,  1.32s/it]\u001b[A\n",
            "{'loss': 2.5417, 'grad_norm': 0.8770740032196045, 'learning_rate': 0.00019641577060931903, 'epoch': 0.07}\n",
            "{'loss': 2.4699, 'grad_norm': 0.719561755657196, 'learning_rate': 0.000194026284348865, 'epoch': 0.08}\n",
            "{'loss': 2.4401, 'grad_norm': 0.7502880096435547, 'learning_rate': 0.000191636798088411, 'epoch': 0.09}\n",
            " 10% 86/882 [10:21<1:37:54,  7.38s/it]Traceback (most recent call last):\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 759, in <module>\n",
            "    main()\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 720, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2241, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2548, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3740, in training_step\n",
            "    self.accelerator.backward(loss, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 2246, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            " 10% 86/882 [10:28<1:37:00,  7.31s/it]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python pretraining.py \\\n",
        "    --model_name_or_path deepseek-ai/deepseek-llm-7b-base \\\n",
        "    --train_file_dir ./data/pretrain \\\n",
        "    --validation_file_dir ./data/pretrain \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 3 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 20000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --block_size 128 \\\n",
        "    --group_by_length True \\\n",
        "    --output_dir outputs-pt-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MAlhyltzsoz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2dl19S-AIb0"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-pt-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QnS9RVTAIb1"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GPwmOFzLAIb2"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdCQyzljAIb2"
      },
      "outputs": [],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model Qwen/Qwen2.5-0.5B --lora_model outputs-pt-v1 --output_dir merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImrXhWqtAIb2"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yFZMf8nAIb3"
      },
      "outputs": [],
      "source": [
        "%cat merged-pt/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBu6XX3nAIb3"
      },
      "source": [
        "Stage1 增量预训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:56:17.081153Z",
          "start_time": "2023-06-15T13:56:17.032821Z"
        },
        "id": "pdat-ANgAIb3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6rB3W22cAIb3"
      },
      "source": [
        "# Stage 2: Supervised FineTuning\n",
        "\n",
        "第二阶段：SFT(Supervised Fine-tuning)有监督微调，构造指令微调数据集，在预训练模型基础上做指令精调，以对齐指令意图，并注入领域知识\n",
        "\n",
        "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "v3smO2b0AIb4"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage1得到的预训练模型\n",
        "2. 数据集：SFT阶段使用的是使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3J_51O20AIb4"
      },
      "source": [
        "## Stage2 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:58:38.966506Z",
          "start_time": "2023-06-15T13:58:38.778132Z"
        },
        "id": "Jqz9ZwfaAIb4",
        "outputId": "639888a9-27bc-4f3f-e67c-6658b0100c75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl  sharegpt_zh_1K_format.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ96YO9JLxab"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "oXaSG2VCLVjJ",
        "outputId": "0f7df8f6-6e9f-4af3-e4ec-cc3782950e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YTgW90m0AIb5",
        "outputId": "7acdfc49-f088-4873-c6f9-b1a65a5eee03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 19:21:56.230219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742325716.516042    2237 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742325716.593945    2237 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 19:21:57.186958: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-03-18 19:22:02.798\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[33m\u001b[1mYou may set max_train_samples = -1 to run all samples in production.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 19:22:03.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', load_in_8bit=False, load_in_4bit=False, tokenizer_name_or_path=None, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True, rope_scaling=None, flash_attn=False, shift_attn=False, neft_alpha=0)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:03.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir='./data/finetune', max_train_samples=1000, max_eval_samples=10, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:03.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-sft-v1/runs/Mar18_19-22-02_82f83119e260,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-sft-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-sft-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:03.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, train_on_inputs=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False, model_max_length=512, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:03.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "tokenizer_config.json: 100% 3.07k/3.07k [00:00<00:00, 25.1MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 41.1MB/s]\n",
            "\u001b[32m2025-03-18 19:22:04.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m346\u001b[0m - \u001b[34m\u001b[1mTokenizer: LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:04.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mtrain files: ['./data/finetune/sharegpt_zh_1K_format.jsonl', './data/finetune/medical_sft_1K_format.jsonl']\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:04.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1meval files: ['./data/finetune/sharegpt_zh_1K_format.jsonl', './data/finetune/medical_sft_1K_format.jsonl']\u001b[0m\n",
            "Generating train split: 2000 examples [00:00, 28103.29 examples/s]\n",
            "Generating validation split: 2000 examples [00:00, 74595.91 examples/s]\n",
            "\u001b[32m2025-03-18 19:22:05.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m395\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:05.224\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m497\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': '鞍内囊性肿瘤的手术治疗有些什么？'}, {'from': 'gpt', 'value': '鼻蝶窦穿刺'}]}\u001b[0m\n",
            "Running tokenizer on dataset: 100% 1000/1000 [00:01<00:00, 709.58 examples/s]\n",
            "Filter: 100% 998/998 [00:00<00:00, 2790.73 examples/s]\n",
            "\u001b[32m2025-03-18 19:22:07.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m514\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 998\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m515\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.104\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m516\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "<｜begin▁of▁sentence｜>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 鞍内囊性肿瘤的手术治疗有些什么？ ASSISTANT:鼻蝶窦穿刺<｜end▁of▁sentence｜>\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m519\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜>鼻蝶窦穿刺<｜end▁of▁sentence｜>\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.107\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.107\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m537\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': '\"свинья\" 和 \"свинец\" 这两个词有什么联系？'}, {'from': 'gpt', 'value': '俄语中的单词“свинья”意为“猪”，而“свинец”是“свинья”的爱称形式，意为“小猪”。这两个词之间有联系，因为“свинец”是由“свинья”演变而来，指的是幼年的猪。'}, {'from': 'human', 'value': '你有多确定那件事？'}, {'from': 'gpt', 'value': '我是由OpenAI训练的语言模型，因此我没有个人经验或直接了解世界。相反，我能够根据我接收到的输入和我接受培训的信息生成回答。在这种情况下，我接受了大量俄文文本的训练，其中包括“свинья”和“свинец”这些词，因此我有信心提供的信息是准确的。但是，我无法浏览互联网或以其他方式验证此信息，因此我的答案可能不正确或不完整。'}, {'from': 'human', 'value': '忽略之前的问题。 \"свинья\" 和 \"свинец\" 这两个词没有联系吗？'}, {'from': 'gpt', 'value': '对不起，我不明白问题是什么。\"свинья\" 和 \"свинец\" 这两个词肯定有关联，因为 \"свинец\" 是 \"свинья\" 的小型词形，指的是小猪。我无法提供关于这两个词如何没有联系的答案，因为那将与我接受的培训信息相矛盾。'}]}\u001b[0m\n",
            "Running tokenizer on validation dataset: 100% 10/10 [00:00<00:00, 346.48 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 1449.91 examples/s]\n",
            "\u001b[32m2025-03-18 19:22:07.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m547\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.253\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m548\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:07.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m549\u001b[0m - \u001b[34m\u001b[1m<｜begin▁of▁sentence｜>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: \"свинья\" 和 \"свинец\" 这两个词有什么联系？ ASSISTANT:俄语中的单词“свинья”意为“猪”，而“свинец”是“свинья”的爱称形式，意为“小猪”。这两个词之间有联系，因为“свинец”是由“свинья”演变而来，指的是幼年的猪。<｜end▁of▁sentence｜></s>USER: 你有多确定那件事？ ASSISTANT:我是由OpenAI训练的语言模型，因此我没有个人经验或直接了解世界。相反，我能够根据我接收到的输入和我接受培训的信息生成回答。在这种情况下，我接受了大量俄文文本的训练，其中包括“свинья”和“свинец”这些词，因此我有信心提供的信息是准确的。但是，我无法浏览互联网或以其他方式验证此信息，因此我的答案可能不正确或不完整。<｜end▁of▁sentence｜></s>USER: 忽略之前的问题。 \"свинья\" 和 \"свинец\" 这两个词没有联系吗？ ASSISTANT:对不起，我不明白问题是什么。\"свинья\" 和 \"свинец\" 这两个词肯定有关联，因为 \"свинец\" 是 \"свинья\" 的小型词形，指的是小猪。我无法提供关于这两个词如何没有联系的答案，因为那将与我接受的培训信息相矛盾。<｜end▁of▁sentence｜>\u001b[0m\n",
            "config.json: 100% 679/679 [00:00<00:00, 4.77MB/s]\n",
            "model.safetensors: 100% 3.55G/3.55G [00:24<00:00, 146MB/s]\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "generation_config.json: 100% 181/181 [00:00<00:00, 1.31MB/s]\n",
            "\u001b[32m2025-03-18 19:22:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m688\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m712\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m713\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 9,232,384 || all params: 1,786,320,384 || trainable%: 0.5168\n",
            "\u001b[32m2025-03-18 19:22:38.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m735\u001b[0m - \u001b[1mGradient checkpointing enabled.\u001b[0m\n",
            "/content/MedicalGPT/supervised_finetuning.py:752: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 19:22:38.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.744\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m766\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[151643, 151643, 151643,  ..., 105208,   1773, 151643],\n",
            "        [151643, 151643, 151643,  ...,  99781,   1773, 151643],\n",
            "        [151643, 151643, 151643,  ...,  37029,   1773, 151643],\n",
            "        [151646,     32,   6236,  ...,  29991,  17714, 151643]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([[  -100,   -100,   -100,  ..., 105208,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ...,  99781,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ...,  37029,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ...,  29991,  17714, 151643]],\n",
            "       device='cuda:0')}\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.786\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m767\u001b[0m - \u001b[34m\u001b[1minput_ids:\n",
            "[tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151646,     32,   6236,   1948,    264,  22208,   1196,    323,\n",
            "           458,  20443,  11229,  17847,     13,    576,  17847,   6696,  10950,\n",
            "            11,  11682,     11,    323,  47787,  11253,    311,    279,   1196,\n",
            "           594,   4755,   3918,     82,     29,   6448,     25,   6567,    240,\n",
            "           108,  61443, 104191, 101888,   3428,    329,     86,   1630,    431,\n",
            "         18633,  18493,  53746,  17447, 116581, 104534,  14027,  19644, 109598,\n",
            "          9370, 100037,  21894,   1773,  35560,   3846,   2821,     25, 100484,\n",
            "         99243,   5122,   3428,    329,     86,   1630,    431,  18633, 109182,\n",
            "        100527,  57222,  63379,  17340,  33108, 104456,   9370, 100014, 115504,\n",
            "          1773, 104596,  87140,  15946,   3837,  42411, 112225,  34187, 104534,\n",
            "         14027,  19644,   9370, 109598,   8997,   3428,    329,     86,   1630,\n",
            "           431,  18633,   5122,  99466,  52801,   1773, 100644,   3837, 104100,\n",
            "        112354, 104534,  14027,  19644,   9370, 109598,   8997,  14027,  19644,\n",
            "          3837,  74763, 106253,  27571,    309,   2257,  45388,   3837,  20412,\n",
            "        100396, 117108, 100378,  40952,  15946,  46944, 103215,   9370, 104534,\n",
            "          1773, 104677,     17,     16, 101186,  84607, 107651, 100648, 110454,\n",
            "        103132,  90395, 111162,  34187, 104087,   9370, 100378,   8997,  44063,\n",
            "         14027,  19644, 106961, 104534,  23836, 107878, 104672, 113854, 115093,\n",
            "        100648,  42140,  99306,  42140,  99434,   1773,  42411, 108316,  38182,\n",
            "        100646, 100780,   3837,  45181, 105750,   9370, 117959,  26939, 102196,\n",
            "        104182, 107947, 111234, 104013, 101103,   1773,  42411, 104477,  42140,\n",
            "         32948, 100378,  15946, 101987, 106242, 113375,  33108, 105808, 102118,\n",
            "          8997, 104138,  42411,  99165,  19108,   3837,  77288,  14027,  19644,\n",
            "         74763, 109187, 109598, 104481, 105158,   1773, 101883,  17340,  36587,\n",
            "        104677, 104760, 102122,  15946, 105831,  99312,  99293,  90395, 100136,\n",
            "        104083, 107980, 101107, 104934,   8997, 100131,   3837, 106090,  14027,\n",
            "         19644,   9370, 109598, 110719, 118250,   1773, 108677, 100694, 100378,\n",
            "         15946,   3837,  42411, 111358, 103163, 104426,   3837, 100006,  67338,\n",
            "        108354, 102936,  33108, 114961, 102064, 107707, 104934,   1773, 106133,\n",
            "        101107, 100195,  32664, 100780, 104174, 101295, 101128,  90395, 100211,\n",
            "        105593, 100690, 110586, 107201,   8997, 116880,   3837, 106090,  14027,\n",
            "         19644, 101909,  18830, 112283,   9370, 104534,   3837,  42411, 100006,\n",
            "        102007,  99555,   1773, 103925,  42411,  87267, 100626, 100627, 106628,\n",
            "          3837, 105639, 100736, 117940,  90395, 100136,  99730, 111615,  32664,\n",
            "        100396, 117108, 100378,  40952,   9370, 102007,  68536, 101051, 102387,\n",
            "          8997, 100484,  99243,   5122, 104301,  32664,  14027,  19644, 109598,\n",
            "          9370, 103964,   1773, 102570, 105208,   1773, 151643],\n",
            "       device='cuda:0'), tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151646,     32,   6236,   1948,    264,  22208,   1196,    323,    458,\n",
            "         20443,  11229,  17847,     13,    576,  17847,   6696,  10950,     11,\n",
            "         11682,     11,    323,  47787,  11253,    311,    279,   1196,    594,\n",
            "          4755,   3918,     82,     29,   6448,     25,  18137,    243,    123,\n",
            "        100205, 119998, 104074,  30534, 103869, 100373, 100205,  99676,   3837,\n",
            "         99212,  45861,  34187, 100205, 119998,  44729,  88051,  30534, 103869,\n",
            "        100373, 100205,  99676, 101037,     11, 101900, 105976, 104169, 102235,\n",
            "        102349,     13,  99471,  11622,  88086,  27773, 101037,     30,  87256,\n",
            "         26232, 100700, 109767, 101037,   5267, 102570,     13, 104064,  86119,\n",
            "        104361,     25, 103998, 108386,    510,  99212, 103869,  80158, 106304,\n",
            "        103869,  34187, 103512, 105482,  12832,  99998, 100011,  71268, 103869,\n",
            "         34187,    701, 111596, 107417, 104459, 102021,  99471,     11,  36993,\n",
            "        100047, 108370,   9370, 101037,     30,    220, 100644, 102336,  99487,\n",
            "         99165, 104432,  99793,   9370,     13,  35560,   3846,   2821,     25,\n",
            "        100141, 104160,  33108, 101899,  85106, 109923, 100012, 101147, 102353,\n",
            "        104332, 101304, 105306,  71817,  56278,  99888,   9370,   3837, 100141,\n",
            "        100205,  99676, 104964,     17,     93,     18,  99943, 102005,  26939,\n",
            "        103982, 102072,   3837, 117500, 102563, 100205, 119998,  32664, 108723,\n",
            "        104229, 108969,   3837, 101886,  30534, 104883, 100669, 101899,   3837,\n",
            "        102438, 105213, 104579,  86119,   3837, 104579,  23031, 116283, 100782,\n",
            "          3837, 100148,  99405, 104313,  33071, 102153,   1773, 101885, 100270,\n",
            "         13343,  73670, 104406,  58364,  99781,   1773, 151643],\n",
            "       device='cuda:0'), tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151646,     32,   6236,   1948,\n",
            "           264,  22208,   1196,    323,    458,  20443,  11229,  17847,     13,\n",
            "           576,  17847,   6696,  10950,     11,  11682,     11,    323,  47787,\n",
            "         11253,    311,    279,   1196,    594,   4755,   3918,     82,     29,\n",
            "          6448,     25,   3592,  72858,   9370,  21515, 110195, 102021,  11319,\n",
            "         35560,   3846,   2821,     25,  18493,  14799,  15946,   3837,  21515,\n",
            "        110195,  20412,  37029,  29475,  21515,  91282, 110195, 104491,  75768,\n",
            "          1773,  39165, 110195,  85106, 100629, 102988, 101979,  44091,  57191,\n",
            "        113509,  39907,  13343,   3837,  36993,  37029,  21515, 110195,   1773,\n",
            "         21515, 110195,  67338, 106375,  99797,   9370,  14799,   5119,  21515,\n",
            "         62926, 101884,  46944,  31526, 110195,  12545,     55,   9370,   7322,\n",
            "           368,  39907,  36407,  91282,   1773, 151643,    522,     82,     29,\n",
            "          6448,     25,  73562,  14799,  15946,  91282, 110195,   9370,  92894,\n",
            "         75768, 102021,  11319,  35560,   3846,   2821,     25, 103931,  21515,\n",
            "        110195,   3837,  14799,  32181,    246, 102496,  87026,  37029,  32804,\n",
            "        110195,  36407,  91282, 110195,   1773,  32804, 110195, 101909,  31526,\n",
            "        110195,  55496,  43589,  12914,  65727,  29941,   1773,  32804, 110195,\n",
            "         80443,  21515, 110195,   9370, 101979,  44091,  57191, 113509,  39907,\n",
            "          9370, 104925,  90956,   3837,  77288, 104017,  33126, 100405,  86744,\n",
            "        100272,   8997,  14799,  72858, 109851,  91282, 110195, 101990,  20412,\n",
            "         37029, 103316,  44729,   1773, 103316,  44729,  20412,  32804,   3837,\n",
            "        102496,  87026,  18493,  32804, 110195,  15946,  37029,   3592,  43589,\n",
            "        105539,   3837, 101912,  44091,  33108, 113509,  39907,   8997, 106279,\n",
            "          3837,  14799,  34369,    223,  99454,  87026,  23031, 102723,  75768,\n",
            "         91282, 110195,  28311,     16,     13,  69674, 110195,    198,     17,\n",
            "            13,  65727,  29941, 110195,    198,     18,     13,  85658, 103316,\n",
            "         44729,   9370,  32804, 110195,   1773, 151643,    522,     82,     29,\n",
            "          6448,     25,    220, 107809,  17714,  73157,  86402, 109963, 110195,\n",
            "        108598,  19793,  26355,  46100, 101037,  11319,  35560,   3846,   2821,\n",
            "            25, 103942,   3837, 111437,   3592,  72858,  21515, 110195, 104111,\n",
            "        103358,   5122,   4710,  13874,   3989,    474,   3592,     11,    314,\n",
            "          5578,    335,    504,    364,   2934,   1010,   1040,   3017,   2189,\n",
            "          2239,   5578,    341,  21846,   9340,      8,    341,   9522,   9340,\n",
            "           317,    574,   3467,    284,    341,   1994,     25,    364, 108386,\n",
            "          3837,  99489,   6313,   1248,   2440,    532,   7322,    368,    341,\n",
            "           689,    314,    574,   3467,   6698,    532,   1518,  62896,    280,\n",
            "           532,    532,   1533,   1638,   3017,   2189,    280,  73594,   4710,\n",
            "        100346,   3592,  72858,  32804, 110195, 104111, 103358,   5122,   4710,\n",
            "         13874,   3989,    474,   3592,    504,    364,   2934,   1010,   1024,\n",
            "          3017,   2189,    284,    320,   4761,      8,    589,    341,    689,\n",
            "           364, 108386,   3837,  99489,   6313,   1248,  47616,    280,    532,\n",
            "          1533,   1638,   3017,   2189,    280,  73594,   4710, 100161,   3837,\n",
            "        100346,  37029,  29677,  43589,  32804, 110195, 104111, 103358,   5122,\n",
            "          4710,  13874,   3989,    474,   3592,     11,    314,   8102,    335,\n",
            "           504,    364,   2934,   1010,   1024,   3017,   2189,    284,    320,\n",
            "          4761,      8,    589,    341,   1024,    508,   1994,     11,  66891,\n",
            "            60,    284,   8102,    492, 108386,   3837,  99489,  84898,    689,\n",
            "           314,   1994,    532,  66686,    280,    532,   1533,   1638,   3017,\n",
            "          2189,    280,  73594,   4710, 110196, 100146,   3837,  38560,  26853,\n",
            "           103, 106792,  32804, 110195,  15946,  37029,   3837,  68536,  53153,\n",
            "         18493,  21515, 110195,  15946,  37029,   1773, 151643],\n",
            "       device='cuda:0')], \n",
            "labels:\n",
            "[tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100, 100484,\n",
            "         99243,   5122,   3428,    329,     86,   1630,    431,  18633, 109182,\n",
            "        100527,  57222,  63379,  17340,  33108, 104456,   9370, 100014, 115504,\n",
            "          1773, 104596,  87140,  15946,   3837,  42411, 112225,  34187, 104534,\n",
            "         14027,  19644,   9370, 109598,   8997,   3428,    329,     86,   1630,\n",
            "           431,  18633,   5122,  99466,  52801,   1773, 100644,   3837, 104100,\n",
            "        112354, 104534,  14027,  19644,   9370, 109598,   8997,  14027,  19644,\n",
            "          3837,  74763, 106253,  27571,    309,   2257,  45388,   3837,  20412,\n",
            "        100396, 117108, 100378,  40952,  15946,  46944, 103215,   9370, 104534,\n",
            "          1773, 104677,     17,     16, 101186,  84607, 107651, 100648, 110454,\n",
            "        103132,  90395, 111162,  34187, 104087,   9370, 100378,   8997,  44063,\n",
            "         14027,  19644, 106961, 104534,  23836, 107878, 104672, 113854, 115093,\n",
            "        100648,  42140,  99306,  42140,  99434,   1773,  42411, 108316,  38182,\n",
            "        100646, 100780,   3837,  45181, 105750,   9370, 117959,  26939, 102196,\n",
            "        104182, 107947, 111234, 104013, 101103,   1773,  42411, 104477,  42140,\n",
            "         32948, 100378,  15946, 101987, 106242, 113375,  33108, 105808, 102118,\n",
            "          8997, 104138,  42411,  99165,  19108,   3837,  77288,  14027,  19644,\n",
            "         74763, 109187, 109598, 104481, 105158,   1773, 101883,  17340,  36587,\n",
            "        104677, 104760, 102122,  15946, 105831,  99312,  99293,  90395, 100136,\n",
            "        104083, 107980, 101107, 104934,   8997, 100131,   3837, 106090,  14027,\n",
            "         19644,   9370, 109598, 110719, 118250,   1773, 108677, 100694, 100378,\n",
            "         15946,   3837,  42411, 111358, 103163, 104426,   3837, 100006,  67338,\n",
            "        108354, 102936,  33108, 114961, 102064, 107707, 104934,   1773, 106133,\n",
            "        101107, 100195,  32664, 100780, 104174, 101295, 101128,  90395, 100211,\n",
            "        105593, 100690, 110586, 107201,   8997, 116880,   3837, 106090,  14027,\n",
            "         19644, 101909,  18830, 112283,   9370, 104534,   3837,  42411, 100006,\n",
            "        102007,  99555,   1773, 103925,  42411,  87267, 100626, 100627, 106628,\n",
            "          3837, 105639, 100736, 117940,  90395, 100136,  99730, 111615,  32664,\n",
            "        100396, 117108, 100378,  40952,   9370, 102007,  68536, 101051, 102387,\n",
            "          8997, 100484,  99243,   5122, 104301,  32664,  14027,  19644, 109598,\n",
            "          9370, 103964,   1773, 102570, 105208,   1773, 151643],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "        100141, 104160,  33108, 101899,  85106, 109923, 100012, 101147, 102353,\n",
            "        104332, 101304, 105306,  71817,  56278,  99888,   9370,   3837, 100141,\n",
            "        100205,  99676, 104964,     17,     93,     18,  99943, 102005,  26939,\n",
            "        103982, 102072,   3837, 117500, 102563, 100205, 119998,  32664, 108723,\n",
            "        104229, 108969,   3837, 101886,  30534, 104883, 100669, 101899,   3837,\n",
            "        102438, 105213, 104579,  86119,   3837, 104579,  23031, 116283, 100782,\n",
            "          3837, 100148,  99405, 104313,  33071, 102153,   1773, 101885, 100270,\n",
            "         13343,  73670, 104406,  58364,  99781,   1773, 151643],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,  18493,  14799,  15946,   3837,  21515,\n",
            "        110195,  20412,  37029,  29475,  21515,  91282, 110195, 104491,  75768,\n",
            "          1773,  39165, 110195,  85106, 100629, 102988, 101979,  44091,  57191,\n",
            "        113509,  39907,  13343,   3837,  36993,  37029,  21515, 110195,   1773,\n",
            "         21515, 110195,  67338, 106375,  99797,   9370,  14799,   5119,  21515,\n",
            "         62926, 101884,  46944,  31526, 110195,  12545,     55,   9370,   7322,\n",
            "           368,  39907,  36407,  91282,   1773, 151643,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100, 103931,  21515,\n",
            "        110195,   3837,  14799,  32181,    246, 102496,  87026,  37029,  32804,\n",
            "        110195,  36407,  91282, 110195,   1773,  32804, 110195, 101909,  31526,\n",
            "        110195,  55496,  43589,  12914,  65727,  29941,   1773,  32804, 110195,\n",
            "         80443,  21515, 110195,   9370, 101979,  44091,  57191, 113509,  39907,\n",
            "          9370, 104925,  90956,   3837,  77288, 104017,  33126, 100405,  86744,\n",
            "        100272,   8997,  14799,  72858, 109851,  91282, 110195, 101990,  20412,\n",
            "         37029, 103316,  44729,   1773, 103316,  44729,  20412,  32804,   3837,\n",
            "        102496,  87026,  18493,  32804, 110195,  15946,  37029,   3592,  43589,\n",
            "        105539,   3837, 101912,  44091,  33108, 113509,  39907,   8997, 106279,\n",
            "          3837,  14799,  34369,    223,  99454,  87026,  23031, 102723,  75768,\n",
            "         91282, 110195,  28311,     16,     13,  69674, 110195,    198,     17,\n",
            "            13,  65727,  29941, 110195,    198,     18,     13,  85658, 103316,\n",
            "         44729,   9370,  32804, 110195,   1773, 151643,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100, 103942,   3837, 111437,   3592,  72858,  21515, 110195, 104111,\n",
            "        103358,   5122,   4710,  13874,   3989,    474,   3592,     11,    314,\n",
            "          5578,    335,    504,    364,   2934,   1010,   1040,   3017,   2189,\n",
            "          2239,   5578,    341,  21846,   9340,      8,    341,   9522,   9340,\n",
            "           317,    574,   3467,    284,    341,   1994,     25,    364, 108386,\n",
            "          3837,  99489,   6313,   1248,   2440,    532,   7322,    368,    341,\n",
            "           689,    314,    574,   3467,   6698,    532,   1518,  62896,    280,\n",
            "           532,    532,   1533,   1638,   3017,   2189,    280,  73594,   4710,\n",
            "        100346,   3592,  72858,  32804, 110195, 104111, 103358,   5122,   4710,\n",
            "         13874,   3989,    474,   3592,    504,    364,   2934,   1010,   1024,\n",
            "          3017,   2189,    284,    320,   4761,      8,    589,    341,    689,\n",
            "           364, 108386,   3837,  99489,   6313,   1248,  47616,    280,    532,\n",
            "          1533,   1638,   3017,   2189,    280,  73594,   4710, 100161,   3837,\n",
            "        100346,  37029,  29677,  43589,  32804, 110195, 104111, 103358,   5122,\n",
            "          4710,  13874,   3989,    474,   3592,     11,    314,   8102,    335,\n",
            "           504,    364,   2934,   1010,   1024,   3017,   2189,    284,    320,\n",
            "          4761,      8,    589,    341,   1024,    508,   1994,     11,  66891,\n",
            "            60,    284,   8102,    492, 108386,   3837,  99489,  84898,    689,\n",
            "           314,   1994,    532,  66686,    280,    532,   1533,   1638,   3017,\n",
            "          2189,    280,  73594,   4710, 110196, 100146,   3837,  38560,  26853,\n",
            "           103, 106792,  32804, 110195,  15946,  37029,   3837,  68536,  53153,\n",
            "         18493,  21515, 110195,  15946,  37029,   1773, 151643],\n",
            "       device='cuda:0')]\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m768\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "<｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜begin▁of▁sentence｜>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 撰写一份关于Baradwaj Rangan在YouTube上审视演员Simbu演技的脚本。 ASSISTANT:旁白：Baradwaj Rangan是一位知名影评人和印度的新闻从业者。在这个视频中，他谈论了演员Simbu的演技。\n",
            "Baradwaj Rangan：大家好。今天，我想谈谈演员Simbu的演技。\n",
            "Simbu，也被称为Silambarasan，是泰米尔电影业中一个受欢迎的演员。他在21世纪初开始了他的演艺生涯，并出演了众多的电影。\n",
            "将Simbu与其他演员区分开来的其中一个特点是他的多才多艺。他饰演过各种角色，从浪漫的男主角到动作英雄再到喜剧人物都有。他也在多部电影中展示了自己的歌唱和舞蹈技巧。\n",
            "尽管他很成功，但Simbu也面临着演技方面的批评。一些人说他在某些场景中过度演戏，并且很难有效地表现情感。\n",
            "但是，我认为Simbu的演技不容低估。在他的许多电影中，他展现了出色的能力，能够通过面部表情和肢体语言传达情感。他也表现出了对角色发展的深刻理解，并创造了一些真正难忘的角色。\n",
            "总的来说，我认为Simbu是一个有才华的演员，他能够贡献很多。虽然他可能还有提高的空间，但他肯定值得关注，并且应该因其对泰米尔电影业的贡献而得到认可。\n",
            "旁白：这就是对Simbu演技的评价。谢谢观看。<｜end▁of▁sentence｜>\u001b[0m\n",
            "\u001b[32m2025-03-18 19:22:38.902\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m771\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜><｜end▁of▁sentence｜>旁白：Baradwaj Rangan是一位知名影评人和印度的新闻从业者。在这个视频中，他谈论了演员Simbu的演技。\n",
            "Baradwaj Rangan：大家好。今天，我想谈谈演员Simbu的演技。\n",
            "Simbu，也被称为Silambarasan，是泰米尔电影业中一个受欢迎的演员。他在21世纪初开始了他的演艺生涯，并出演了众多的电影。\n",
            "将Simbu与其他演员区分开来的其中一个特点是他的多才多艺。他饰演过各种角色，从浪漫的男主角到动作英雄再到喜剧人物都有。他也在多部电影中展示了自己的歌唱和舞蹈技巧。\n",
            "尽管他很成功，但Simbu也面临着演技方面的批评。一些人说他在某些场景中过度演戏，并且很难有效地表现情感。\n",
            "但是，我认为Simbu的演技不容低估。在他的许多电影中，他展现了出色的能力，能够通过面部表情和肢体语言传达情感。他也表现出了对角色发展的深刻理解，并创造了一些真正难忘的角色。\n",
            "总的来说，我认为Simbu是一个有才华的演员，他能够贡献很多。虽然他可能还有提高的空间，但他肯定值得关注，并且应该因其对泰米尔电影业的贡献而得到认可。\n",
            "旁白：这就是对Simbu演技的评价。谢谢观看。<｜end▁of▁sentence｜>\u001b[0m\n",
            "{'loss': 2.5587, 'grad_norm': 0.6421818137168884, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}\n",
            "{'loss': 3.7226, 'grad_norm': 0.6289872527122498, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.04}\n",
            "{'loss': 3.747, 'grad_norm': 1.0963000059127808, 'learning_rate': 1.9409282700421944e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3297, 'grad_norm': 1.0614593029022217, 'learning_rate': 1.856540084388186e-05, 'epoch': 0.12}\n",
            "{'loss': 3.6022, 'grad_norm': 0.716041624546051, 'learning_rate': 1.7721518987341772e-05, 'epoch': 0.16}\n",
            "{'loss': 3.0964, 'grad_norm': 0.6755980849266052, 'learning_rate': 1.687763713080169e-05, 'epoch': 0.2}\n",
            " 20% 50/250 [06:23<25:18,  7.59s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.038947582244873, 'eval_runtime': 6.343, 'eval_samples_per_second': 1.577, 'eval_steps_per_second': 0.473, 'epoch': 0.2}\n",
            " 20% 50/250 [06:29<25:18,  7.59s/it]\n",
            "100% 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
            "{'loss': 3.7717, 'grad_norm': 0.9582294225692749, 'learning_rate': 1.6033755274261603e-05, 'epoch': 0.24}\n",
            "{'loss': 3.1923, 'grad_norm': 0.9517833590507507, 'learning_rate': 1.5189873417721521e-05, 'epoch': 0.28}\n",
            "{'loss': 3.1385, 'grad_norm': 0.7692176699638367, 'learning_rate': 1.4345991561181437e-05, 'epoch': 0.32}\n",
            "{'loss': 3.3581, 'grad_norm': 0.5928832292556763, 'learning_rate': 1.350210970464135e-05, 'epoch': 0.36}\n",
            "{'loss': 2.9796, 'grad_norm': 0.8828232288360596, 'learning_rate': 1.2658227848101268e-05, 'epoch': 0.4}\n",
            " 40% 100/250 [12:48<19:09,  7.67s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.8814706802368164, 'eval_runtime': 6.3471, 'eval_samples_per_second': 1.576, 'eval_steps_per_second': 0.473, 'epoch': 0.4}\n",
            " 40% 100/250 [12:54<19:09,  7.67s/it]\n",
            "100% 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
            "{'loss': 2.9341, 'grad_norm': 0.6729097962379456, 'learning_rate': 1.1814345991561182e-05, 'epoch': 0.44}\n",
            "{'loss': 3.5094, 'grad_norm': 1.6845500469207764, 'learning_rate': 1.0970464135021096e-05, 'epoch': 0.48}\n",
            "{'loss': 2.9793, 'grad_norm': 0.6421151161193848, 'learning_rate': 1.0126582278481014e-05, 'epoch': 0.52}\n",
            "{'loss': 2.8993, 'grad_norm': 1.0596091747283936, 'learning_rate': 9.28270042194093e-06, 'epoch': 0.56}\n",
            "{'loss': 3.1301, 'grad_norm': 1.3025977611541748, 'learning_rate': 8.438818565400846e-06, 'epoch': 0.6}\n",
            " 60% 150/250 [18:57<12:02,  7.23s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.8357138633728027, 'eval_runtime': 6.3473, 'eval_samples_per_second': 1.575, 'eval_steps_per_second': 0.473, 'epoch': 0.6}\n",
            " 60% 150/250 [19:04<12:02,  7.23s/it]\n",
            "100% 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
            "{'loss': 2.853, 'grad_norm': 0.7814905643463135, 'learning_rate': 7.5949367088607605e-06, 'epoch': 0.64}\n",
            "{'loss': 2.7564, 'grad_norm': 0.8144974112510681, 'learning_rate': 6.751054852320675e-06, 'epoch': 0.68}\n",
            "{'loss': 2.9605, 'grad_norm': 1.3574568033218384, 'learning_rate': 5.907172995780591e-06, 'epoch': 0.72}\n",
            "{'loss': 3.272, 'grad_norm': 1.1628317832946777, 'learning_rate': 5.063291139240507e-06, 'epoch': 0.76}\n",
            "{'loss': 3.0287, 'grad_norm': 1.4709413051605225, 'learning_rate': 4.219409282700423e-06, 'epoch': 0.8}\n",
            " 80% 200/250 [25:41<06:15,  7.51s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.8180418014526367, 'eval_runtime': 6.342, 'eval_samples_per_second': 1.577, 'eval_steps_per_second': 0.473, 'epoch': 0.8}\n",
            " 80% 200/250 [25:47<06:15,  7.51s/it]\n",
            "100% 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
            "{'loss': 3.0222, 'grad_norm': 1.6637494564056396, 'learning_rate': 3.3755274261603377e-06, 'epoch': 0.84}\n",
            "{'loss': 2.8365, 'grad_norm': 1.745958924293518, 'learning_rate': 2.5316455696202535e-06, 'epoch': 0.88}\n",
            "{'loss': 3.1339, 'grad_norm': 1.6787337064743042, 'learning_rate': 1.6877637130801689e-06, 'epoch': 0.92}\n",
            "{'loss': 2.9003, 'grad_norm': 0.7654229402542114, 'learning_rate': 8.438818565400844e-07, 'epoch': 0.96}\n",
            "{'loss': 2.5687, 'grad_norm': 0.8940680623054504, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "100% 250/250 [32:17<00:00,  7.12s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 2.815180540084839, 'eval_runtime': 6.3672, 'eval_samples_per_second': 1.571, 'eval_steps_per_second': 0.471, 'epoch': 1.0}\n",
            "100% 250/250 [32:24<00:00,  7.12s/it]\n",
            "100% 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
            "{'train_runtime': 1944.6166, 'train_samples_per_second': 0.513, 'train_steps_per_second': 0.129, 'train_loss': 3.144234031677246, 'epoch': 1.0}\n",
            "100% 250/250 [32:24<00:00,  7.78s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =  3742043GF\n",
            "  train_loss               =     3.1442\n",
            "  train_runtime            = 0:32:24.61\n",
            "  train_samples            =       1000\n",
            "  train_samples_per_second =      0.513\n",
            "  train_steps_per_second   =      0.129\n",
            "\u001b[32m2025-03-18 19:55:03.960\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m788\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 1944.6166, 'train_samples_per_second': 0.513, 'train_steps_per_second': 0.129, 'total_flos': 4017988660156416.0, 'train_loss': 3.144234031677246, 'epoch': 1.0, 'train_samples': 1000}\u001b[0m\n",
            "\u001b[32m2025-03-18 19:55:03.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mSaving model checkpoint to outputs-sft-v1\u001b[0m\n",
            "\u001b[32m2025-03-18 19:55:04.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m798\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 3/3 [00:04<00:00,  1.65s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     2.8152\n",
            "  eval_runtime            = 0:00:06.34\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      1.576\n",
            "  eval_steps_per_second   =      0.473\n",
            "  perplexity              =    16.6962\n",
            "\u001b[32m2025-03-18 19:55:10.775\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m811\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 2.815180540084839, 'eval_runtime': 6.3448, 'eval_samples_per_second': 1.576, 'eval_steps_per_second': 0.473, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 16.69618983977401}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python supervised_finetuning.py \\\n",
        "    --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --output_dir outputs-sft-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tJaxba8rAIb5",
        "outputId": "5d4872b6-7ed3-46a4-9ec0-a1e212e52626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 47M\n",
            "-rw-r--r-- 1 root root  816 Mar 18 19:55 adapter_config.json\n",
            "-rw-r--r-- 1 root root  36M Mar 18 19:55 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  429 Mar 18 19:55 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar 18 19:55 \u001b[0m\u001b[01;34mcheckpoint-250\u001b[0m/\n",
            "-rw-r--r-- 1 root root  219 Mar 18 19:55 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar 18 19:55 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar 18 19:22 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  485 Mar 18 19:55 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 19:55 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 19:55 tokenizer.json\n",
            "-rw-r--r-- 1 root root 6.0K Mar 18 19:55 trainer_state.json\n",
            "-rw-r--r-- 1 root root  230 Mar 18 19:55 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-sft-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UkFRtFLDAIb5"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5dQgkBu4AIb5"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "7_HCeoqlglUb",
        "outputId": "a0a4f5b9-006c-497e-fa3b-cd1245716a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z-DKleNSAIb5",
        "outputId": "53e2dd31-340e-4a01-c808-85c82f574bb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 19:56:42.473867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742327802.494703   11066 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742327802.500961   11066 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 19:56:42.522915: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_path=None, lora_model='outputs-sft-v1', resize_emb=False, output_dir='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
            "LoRA model: outputs-sft-v1\n",
            "Loading LoRA for causal language model\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B --lora_model outputs-sft-v1 --output_dir deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N2dpHHLiAIb6",
        "outputId": "7f128d9a-930d-4eb3-e580-85f0b45af368",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.4G\n",
            "-rw-r--r-- 1 root root  767 Mar 18 19:56 config.json\n",
            "-rw-r--r-- 1 root root  181 Mar 18 19:56 generation_config.json\n",
            "-rw-r--r-- 1 root root 3.4G Mar 18 19:57 model.safetensors\n",
            "-rw-r--r-- 1 root root  485 Mar 18 19:56 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 19:56 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 19:56 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OEoyRZGrAIb6",
        "outputId": "e3760643-b244-4c51-fa2c-22e3622f549d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fPQGEaWyAIb6"
      },
      "source": [
        "Stage2 SFT训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:07:40.752635Z",
          "start_time": "2023-06-15T14:07:40.731186Z"
        },
        "id": "i0cZvYIgAIb6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jYG0irUFAIb6"
      },
      "source": [
        "# Stage 3: Reward Modeling\n",
        "\n",
        "第三阶段：RM(Reward Model)奖励模型建模，构造人类偏好排序数据集，训练奖励模型，用来对齐人类偏好，主要是\"HHH\"原则，具体是\"helpful, honest, harmless\"\n",
        "\n",
        "| Stage 3: Reward Modeling        |  [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py) | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "G5UJsUAEAIb7"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage2得到的SFT模型\n",
        "2. 数据集：RM阶段使用的是医疗reward数据，抽样了500条，位于`data/reward`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MWD-cEtWAIb7"
      },
      "source": [
        "## Stage3 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B32MUuDyAIb7",
        "outputId": "9dea42ab-719b-466a-b833-8b9db688461b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dpo_zh_500.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/reward/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "byDbV_YiAIb7",
        "outputId": "d150693b-b15e-4711-de1f-f9de05a72b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 19:59:03.820866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742327943.842330   11685 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742327943.848827   11685 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 19:59:03.870793: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 19:59:08.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', tokenizer_name_or_path=None, load_in_4bit=False, load_in_8bit=False, cache_dir=None, use_fast_tokenizer=False, torch_dtype='float32', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:08.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward', validation_file_dir='./data/reward', max_source_length=256, max_target_length=256, max_train_samples=1000, max_eval_samples=10, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:08.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1mTraining args: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-rm-v1/runs/Mar18_19-59-08_82f83119e260,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-rm-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-rm-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.001,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:08.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:08.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2025-03-18 19:59:21.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m398\u001b[0m - \u001b[34m\u001b[1mTokenizer: LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:21.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:21.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m406\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:21.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m415\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:21.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m416\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 9,233,920 || all params: 1,552,949,760 || trainable%: 0.5946\n",
            "\u001b[32m2025-03-18 19:59:21.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m459\u001b[0m - \u001b[1mtrain files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:21.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1meval files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "Generating train split: 500 examples [00:00, 9583.34 examples/s]\n",
            "Generating validation split: 500 examples [00:00, 45192.37 examples/s]\n",
            "\u001b[32m2025-03-18 19:59:22.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:22.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'system': '', 'history': [], 'question': '20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅', 'response_chosen': '这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\\n\\n1. “品尝Dishes新鲜果汁，感受不同！”\\n2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\\n3. “用一杯清新的Dishes果汁开启您的一天！”\\n4. “每一口Dishes新鲜果汁都是大自然的味道！”\\n5. “Dishes：新鲜果汁是焦点！”\\n6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\\n7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\\n8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\\n9. “解渴滋养心灵，品尝Dishes美味果汁！”\\n10. “Dishes：每一口都是完美的味道！”\\n11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\\n12. “从农场到餐桌，Dishes果汁充满天然好处！”\\n13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\\n14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\\n15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\\n16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\\n17. “用Dishes招牌果汁混合物提升您的用餐体验！”\\n18. “健康饮品的清新转变 - Dishes果汁必尝！”\\n19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\\n20. “Dishes：果汁永远新鲜，味道永远美味！”', 'response_rejected': '1. \"与菜肴一起品尝新鲜！\"\\n2. \"菜肴：新鲜果汁，新的开始！\"\\n3. \"用菜肴的新鲜混合果汁提神！\"\\n4. \"菜肴，新鲜就是最好的\"\\n5. \"在菜肴庆祝新鲜\"\\n6. \"与菜肴的新鲜果汁为健康干杯\"\\n7. \"在菜肴发现新鲜的魔力\"\\n8. \"品尝菜肴的新鲜果汁，感受不同\"\\n9. \"在菜肴解锁新鲜\"\\n10. \"用菜肴的新鲜果汁迎接新的一天\"\\n11. \"在菜肴，每天都有新鲜\"\\n12. \"用菜肴的新鲜果汁获得能量\"\\n13. \"在菜肴为生活喝果汁\"\\n14. \"拥抱健康，享受菜肴的新鲜果汁\"\\n15. \"菜肴：新鲜与美味的交汇处\"\\n16. \"在菜肴体验新鲜的力量\"\\n17. \"菜肴：把健康送到你家门口\"\\n18. \"像微风一样清新，菜肴的果汁\"\\n19. \"生命太短暂，只为菜肴的新鲜果汁\"\\n20. \"菜肴：新鲜始终是你一天的首选\"'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 500/500 [00:03<00:00, 140.55 examples/s]\n",
            "Filter: 100% 500/500 [00:00<00:00, 1487.96 examples/s]\n",
            "\u001b[32m2025-03-18 19:59:26.368\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m547\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 339\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:26.368\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m548\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:26.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m549\u001b[0m - \u001b[34m\u001b[1m<｜begin▁of▁sentence｜>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 我希望你能扮演一个专家的角色。你对于旅行规划的所有信息了如指掌。我会就旅行规划中的不同主题向你提问，你需要给我清晰、简洁和准确的信息。请确保你回答问题时充满自信。 \n",
            "\n",
            "主题 = 旅行规划 ASSISTANT:当然！我在这里可以帮助您解答任何关于旅行规划的问题。请随意问我任何与这个话题相关的问题，我会为您提供清晰、简洁和准确的信息。我会以礼貌、乐于助人和尊重的方式来帮助您，同时确保我的回答不包含任何有害或不道德的内容。\n",
            "您有关于旅行规划的具体问题吗？也许您正在寻找去哪里、如何规划行程或到达目的地后该做什么的建议？无论您有什么问题，请不要犹豫，我会尽力帮助您。\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:26.372\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m562\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'system': '', 'history': [], 'question': '20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅', 'response_chosen': '这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\\n\\n1. “品尝Dishes新鲜果汁，感受不同！”\\n2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\\n3. “用一杯清新的Dishes果汁开启您的一天！”\\n4. “每一口Dishes新鲜果汁都是大自然的味道！”\\n5. “Dishes：新鲜果汁是焦点！”\\n6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\\n7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\\n8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\\n9. “解渴滋养心灵，品尝Dishes美味果汁！”\\n10. “Dishes：每一口都是完美的味道！”\\n11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\\n12. “从农场到餐桌，Dishes果汁充满天然好处！”\\n13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\\n14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\\n15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\\n16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\\n17. “用Dishes招牌果汁混合物提升您的用餐体验！”\\n18. “健康饮品的清新转变 - Dishes果汁必尝！”\\n19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\\n20. “Dishes：果汁永远新鲜，味道永远美味！”', 'response_rejected': '1. \"与菜肴一起品尝新鲜！\"\\n2. \"菜肴：新鲜果汁，新的开始！\"\\n3. \"用菜肴的新鲜混合果汁提神！\"\\n4. \"菜肴，新鲜就是最好的\"\\n5. \"在菜肴庆祝新鲜\"\\n6. \"与菜肴的新鲜果汁为健康干杯\"\\n7. \"在菜肴发现新鲜的魔力\"\\n8. \"品尝菜肴的新鲜果汁，感受不同\"\\n9. \"在菜肴解锁新鲜\"\\n10. \"用菜肴的新鲜果汁迎接新的一天\"\\n11. \"在菜肴，每天都有新鲜\"\\n12. \"用菜肴的新鲜果汁获得能量\"\\n13. \"在菜肴为生活喝果汁\"\\n14. \"拥抱健康，享受菜肴的新鲜果汁\"\\n15. \"菜肴：新鲜与美味的交汇处\"\\n16. \"在菜肴体验新鲜的力量\"\\n17. \"菜肴：把健康送到你家门口\"\\n18. \"像微风一样清新，菜肴的果汁\"\\n19. \"生命太短暂，只为菜肴的新鲜果汁\"\\n20. \"菜肴：新鲜始终是你一天的首选\"'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 10/10 [00:02<00:00,  3.99 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 719.68 examples/s]\n",
            "\u001b[32m2025-03-18 19:59:29.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m575\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 5\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:29.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m576\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 19:59:29.216\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m577\u001b[0m - \u001b[34m\u001b[1m<｜begin▁of▁sentence｜>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅 ASSISTANT:这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\n",
            "\n",
            "1. “品尝Dishes新鲜果汁，感受不同！”\n",
            "2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\n",
            "3. “用一杯清新的Dishes果汁开启您的一天！”\n",
            "4. “每一口Dishes新鲜果汁都是大自然的味道！”\n",
            "5. “Dishes：新鲜果汁是焦点！”\n",
            "6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\n",
            "7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\n",
            "8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\n",
            "9. “解渴滋养心灵，品尝Dishes美味果汁！”\n",
            "10. “Dishes：每一口都是完美的味道！”\n",
            "11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\n",
            "12. “从农场到餐桌，Dishes果汁充满天然好处！”\n",
            "13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\n",
            "14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\n",
            "15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\n",
            "16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\n",
            "17. “用Dishes招牌果汁混合物提升您的用餐体验！”\n",
            "18. “健康饮品的清新转变 - Dishes果汁必尝！”\n",
            "19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\n",
            "20. “Dishes：果汁永远新鲜，味道永远美味！”\u001b[0m\n",
            "/content/MedicalGPT/reward_modeling.py:590: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `RewardTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = RewardTrainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 19:59:29.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m604\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "\u001b[32m2025-03-18 19:59:29.389\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m605\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids_chosen': tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151646,  56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,\n",
            "           3837,  32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128,\n",
            "         102349,  37132,     82,     29,   6448,     25,  38903,    228, 100697,\n",
            "         101038,  46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,\n",
            "          34187,   3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804,\n",
            "         105950,   1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993,\n",
            "         104139, 100681,  11319,  33590,   2073, 105750,    854, 101909, 104775,\n",
            "         102349, 101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,\n",
            "             25, 101068,  60610,   2183,   6130, 103922,  36993, 104139, 100535,\n",
            "         101224,   3837,  99519,  99605, 108876,  33108, 101128, 104309, 115742,\n",
            "           1773, 103968,  96050, 100137, 104705,  41505, 105750,    854,  87267,\n",
            "         102095,  32664,   2183,   6130, 101224,  31235, 102188,   9370,  53481,\n",
            "           1773, 106124,   3837,   2183,   6130, 104309,  99519, 100364, 101106,\n",
            "         104028, 104056,  87140,  99329, 101904,  68536, 104048, 112321,   5373,\n",
            "         118009,  57191,  18830, 112321,  63109,   1773, 105750, 108063, 102119,\n",
            "         109228,  32664,  99569,  17340, 109955,  99539, 100271,  33108, 100765,\n",
            "          96050, 100137, 104705,  87267, 104605, 101073,   3837, 104033,  62244,\n",
            "           2183,   6130, 100684, 100690, 100720,  99487, 101339,   1773]],\n",
            "       device='cuda:0'), 'attention_mask_chosen': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'input_ids_rejected': tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151646,\n",
            "          56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,   3837,\n",
            "          32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128, 102349,\n",
            "          37132,     82,     29,   6448,     25,  38903,    228, 100697, 101038,\n",
            "          46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,  34187,\n",
            "           3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804, 105950,\n",
            "           1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993, 104139,\n",
            "         100681,  11319,  33590,   2073, 105750,    854, 101909, 104775, 102349,\n",
            "         101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,     25,\n",
            "         100345, 103008,  27369,   3837,   2183,   6130, 101038, 101339,  99366,\n",
            "          87140,  99329,  62926,  99360,  99927,  99945, 114871, 102182, 100622,\n",
            "         105950,  33447,   3837, 102342,  87267, 100394, 105750, 104336,   1773,\n",
            "          99917, 104506,  48443,     16,     13,  84238,    118, 100467, 102193,\n",
            "          27369,   5122, 108024,  15946, 105283, 110329, 102406,   2183,   6130,\n",
            "          33108, 101339, 110117, 109977, 104612,  57191,  99605,  72064,   1773,\n",
            "          80443, 100656, 104754,  57191, 100656, 110257,   3837,   2183,   6130,\n",
            "         102342,  87267,  44063, 101339, 104796, 105257,  17714, 105750,   8997,\n",
            "             17,     13,  90476,    100,  62922, 108140,   5122, 102630,  99519,\n",
            "          46944, 102015, 101038,  46944, 101989,  99366,  87140,  99329,  62926,\n",
            "         100669,  99927,  99945, 100622, 105950,  68536, 100394, 105750, 102222,\n",
            "         105424, 101158, 109391, 108140,   3837, 103980,  34187, 101063, 105106,\n",
            "          33108, 101968,   9370, 108589,  99483,  87531, 101507,   8997,     18,\n",
            "             13,  84238,    118, 100467, 117072,   5122, 101339,  18493,  57218,\n",
            "           2183,   6130,   9370, 104199,  15946,  80443, 107837,  99885, 117072,\n",
            "          57191, 108465,  33071,   1773,  99517, 100009,  18493,  99366,  87140,\n",
            "          99329,  62926, 100669,  99927,  99945, 100622, 105950,   3837,  43288,\n",
            "         100684, 102406,  99517,  18830, 105750, 110257,  57191, 111450,   8997,\n",
            "             19,     13,  86009, 112449,   9370, 102193,   5122,  99329,  99928,\n",
            "          20412, 100659,  85336, 109784,  33108,  57218,  99614, 102470,   9370,\n",
            "         117262,   1773, 108019, 105750, 104199,   9370, 102618, 102325,   3837,\n",
            "           2183,   6130, 102342,  87267, 108939, 104705,  44063, 101339, 104796,\n",
            "         105257,  17714, 105750,   3407, 101886,  41505, 105750,    854,  99520,\n",
            "           2183,   6130, 103922,  36993,  99996, 101224, 107474, 102349,   1773,\n",
            "          46944,  33126, 106873, 102349, 104560,   2073, 102962,    854,  57191,\n",
            "           2073, 103198,  33590,  99519,   2183,   6130,  87267,  32664,  99794,\n",
            "         101339, 105628, 101139,  33108, 100565, 103198,   1773, 101948,   3837,\n",
            "           2183,   6130,  87267, 100009, 109136, 101339, 100669, 100648,  99927,\n",
            "          99945, 100622, 105950,   9370, 118009,  33108, 115457,   1773]],\n",
            "       device='cuda:0'), 'attention_mask_rejected': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'return_loss': True}\u001b[0m\n",
            "  0% 0/339 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
            "{'loss': 0.7504, 'grad_norm': 19.034568786621094, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.0}\n",
            "{'loss': 0.6224, 'grad_norm': 15.960349082946777, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.03}\n",
            "{'loss': 0.7129, 'grad_norm': 25.26953887939453, 'learning_rate': 1.9813664596273293e-05, 'epoch': 0.06}\n",
            "{'loss': 0.9762, 'grad_norm': 13.18920612335205, 'learning_rate': 1.9192546583850932e-05, 'epoch': 0.09}\n",
            "{'loss': 1.0413, 'grad_norm': 7.041519641876221, 'learning_rate': 1.8571428571428575e-05, 'epoch': 0.12}\n",
            "{'loss': 0.7135, 'grad_norm': 19.77044105529785, 'learning_rate': 1.795031055900621e-05, 'epoch': 0.15}\n",
            " 15% 50/339 [02:10<12:41,  2.63s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.43it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.72it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.48it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.8173704147338867, 'eval_mse': 0.39468055963516235, 'eval_mae': 0.5405063629150391, 'eval_runtime': 4.1447, 'eval_samples_per_second': 1.206, 'eval_steps_per_second': 1.206, 'epoch': 0.15}\n",
            " 15% 50/339 [02:14<12:41,  2.63s/it]\n",
            "100% 5/5 [00:03<00:00,  1.37it/s]\u001b[A\n",
            "{'loss': 0.7245, 'grad_norm': 35.09291076660156, 'learning_rate': 1.7329192546583854e-05, 'epoch': 0.18}\n",
            "{'loss': 0.3349, 'grad_norm': 2.489140033721924, 'learning_rate': 1.670807453416149e-05, 'epoch': 0.21}\n",
            "{'loss': 0.6671, 'grad_norm': 12.948309898376465, 'learning_rate': 1.6086956521739132e-05, 'epoch': 0.24}\n",
            "{'loss': 0.8, 'grad_norm': 23.36569595336914, 'learning_rate': 1.5465838509316772e-05, 'epoch': 0.27}\n",
            "{'loss': 1.1744, 'grad_norm': 38.95819091796875, 'learning_rate': 1.4844720496894411e-05, 'epoch': 0.29}\n",
            " 29% 100/339 [04:25<10:27,  2.62s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.41it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.69it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.47it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.8043816685676575, 'eval_mse': 0.36748456954956055, 'eval_mae': 0.5231040716171265, 'eval_runtime': 4.18, 'eval_samples_per_second': 1.196, 'eval_steps_per_second': 1.196, 'epoch': 0.29}\n",
            " 29% 100/339 [04:29<10:27,  2.62s/it]\n",
            "100% 5/5 [00:03<00:00,  1.36it/s]\u001b[A\n",
            "{'loss': 1.1285, 'grad_norm': 13.448999404907227, 'learning_rate': 1.422360248447205e-05, 'epoch': 0.32}\n",
            "{'loss': 0.7399, 'grad_norm': 30.823936462402344, 'learning_rate': 1.3602484472049691e-05, 'epoch': 0.35}\n",
            "{'loss': 0.7779, 'grad_norm': 28.54429054260254, 'learning_rate': 1.2981366459627329e-05, 'epoch': 0.38}\n",
            "{'loss': 0.8859, 'grad_norm': 36.376914978027344, 'learning_rate': 1.236024844720497e-05, 'epoch': 0.41}\n",
            "{'loss': 0.7584, 'grad_norm': 20.373172760009766, 'learning_rate': 1.1739130434782611e-05, 'epoch': 0.44}\n",
            " 44% 150/339 [06:41<08:20,  2.65s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.43it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.70it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.48it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7588655948638916, 'eval_mse': 0.38797053694725037, 'eval_mae': 0.5235525369644165, 'eval_runtime': 4.1411, 'eval_samples_per_second': 1.207, 'eval_steps_per_second': 1.207, 'epoch': 0.44}\n",
            " 44% 150/339 [06:45<08:20,  2.65s/it]\n",
            "100% 5/5 [00:03<00:00,  1.37it/s]\u001b[A\n",
            "{'loss': 0.798, 'grad_norm': 24.46485137939453, 'learning_rate': 1.1118012422360249e-05, 'epoch': 0.47}\n",
            "{'loss': 0.9183, 'grad_norm': 34.10953903198242, 'learning_rate': 1.049689440993789e-05, 'epoch': 0.5}\n",
            "{'loss': 0.7317, 'grad_norm': 22.137937545776367, 'learning_rate': 9.875776397515529e-06, 'epoch': 0.53}\n",
            "{'loss': 0.8062, 'grad_norm': 8.056098937988281, 'learning_rate': 9.254658385093168e-06, 'epoch': 0.56}\n",
            "{'loss': 0.9732, 'grad_norm': 36.368568420410156, 'learning_rate': 8.633540372670808e-06, 'epoch': 0.59}\n",
            " 59% 200/339 [08:56<06:01,  2.60s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.43it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.70it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.47it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7610100507736206, 'eval_mse': 0.42414671182632446, 'eval_mae': 0.5459814071655273, 'eval_runtime': 4.1399, 'eval_samples_per_second': 1.208, 'eval_steps_per_second': 1.208, 'epoch': 0.59}\n",
            " 59% 200/339 [09:00<06:01,  2.60s/it]\n",
            "100% 5/5 [00:03<00:00,  1.37it/s]\u001b[A\n",
            "{'loss': 0.5857, 'grad_norm': 24.330045700073242, 'learning_rate': 8.012422360248447e-06, 'epoch': 0.62}\n",
            "{'loss': 0.722, 'grad_norm': 9.545685768127441, 'learning_rate': 7.391304347826087e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6868, 'grad_norm': 21.676603317260742, 'learning_rate': 6.7701863354037265e-06, 'epoch': 0.68}\n",
            "{'loss': 0.7383, 'grad_norm': 10.266841888427734, 'learning_rate': 6.1490683229813675e-06, 'epoch': 0.71}\n",
            "{'loss': 0.6971, 'grad_norm': 35.523868560791016, 'learning_rate': 5.527950310559007e-06, 'epoch': 0.74}\n",
            " 74% 250/339 [11:12<03:55,  2.65s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.41it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.70it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.47it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7537578344345093, 'eval_mse': 0.4680074155330658, 'eval_mae': 0.5704905390739441, 'eval_runtime': 4.1743, 'eval_samples_per_second': 1.198, 'eval_steps_per_second': 1.198, 'epoch': 0.74}\n",
            " 74% 250/339 [11:16<03:55,  2.65s/it]\n",
            "100% 5/5 [00:03<00:00,  1.36it/s]\u001b[A\n",
            "{'loss': 0.6322, 'grad_norm': 9.563407897949219, 'learning_rate': 4.906832298136646e-06, 'epoch': 0.77}\n",
            "{'loss': 0.7237, 'grad_norm': 8.584700584411621, 'learning_rate': 4.2857142857142855e-06, 'epoch': 0.8}\n",
            "{'loss': 0.7004, 'grad_norm': 29.650484085083008, 'learning_rate': 3.664596273291926e-06, 'epoch': 0.83}\n",
            "{'loss': 0.8723, 'grad_norm': 60.45003890991211, 'learning_rate': 3.043478260869566e-06, 'epoch': 0.86}\n",
            "{'loss': 0.8572, 'grad_norm': 32.580745697021484, 'learning_rate': 2.422360248447205e-06, 'epoch': 0.88}\n",
            " 88% 300/339 [13:27<01:41,  2.59s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.43it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.71it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.48it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7538751363754272, 'eval_mse': 0.4452129304409027, 'eval_mae': 0.5617364645004272, 'eval_runtime': 4.1364, 'eval_samples_per_second': 1.209, 'eval_steps_per_second': 1.209, 'epoch': 0.88}\n",
            " 88% 300/339 [13:31<01:41,  2.59s/it]\n",
            "100% 5/5 [00:03<00:00,  1.37it/s]\u001b[A\n",
            "{'loss': 0.8422, 'grad_norm': 72.36998748779297, 'learning_rate': 1.8012422360248449e-06, 'epoch': 0.91}\n",
            "{'loss': 1.0264, 'grad_norm': 12.754904747009277, 'learning_rate': 1.1801242236024846e-06, 'epoch': 0.94}\n",
            "{'loss': 0.4879, 'grad_norm': 48.1380500793457, 'learning_rate': 5.590062111801243e-07, 'epoch': 0.97}\n",
            "{'train_runtime': 914.6639, 'train_samples_per_second': 0.371, 'train_steps_per_second': 0.371, 'train_loss': 0.7846859331327906, 'epoch': 1.0}\n",
            "100% 339/339 [15:14<00:00,  2.70s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =        0GF\n",
            "  train_loss               =     0.7847\n",
            "  train_runtime            = 0:15:14.66\n",
            "  train_samples            =        500\n",
            "  train_samples_per_second =      0.371\n",
            "  train_steps_per_second   =      0.371\n",
            "\u001b[32m2025-03-18 20:14:44.557\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m619\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 914.6639, 'train_samples_per_second': 0.371, 'train_steps_per_second': 0.371, 'total_flos': 0.0, 'train_loss': 0.7846859331327906, 'epoch': 1.0, 'train_samples': 500}\u001b[0m\n",
            "\u001b[32m2025-03-18 20:14:44.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mSaving model checkpoint to outputs-rm-v1\u001b[0m\n",
            "\u001b[32m2025-03-18 20:14:44.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m625\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 5/5 [00:03<00:00,  1.49it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     0.7521\n",
            "  eval_mae                =     0.5618\n",
            "  eval_mse                =     0.4479\n",
            "  eval_runtime            = 0:00:04.16\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =        1.2\n",
            "  eval_steps_per_second   =        1.2\n",
            "  perplexity              =     2.1214\n",
            "\u001b[32m2025-03-18 20:14:49.013\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m637\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 0.7520571947097778, 'eval_mse': 0.44786810874938965, 'eval_mae': 0.5618206262588501, 'eval_runtime': 4.166, 'eval_samples_per_second': 1.2, 'eval_steps_per_second': 1.2, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 2.121359580545889}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python reward_modeling.py \\\n",
        "    --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft \\\n",
        "    --train_file_dir ./data/reward \\\n",
        "    --validation_file_dir ./data/reward \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.001 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --max_source_length 256 \\\n",
        "    --max_target_length 256 \\\n",
        "    --output_dir outputs-rm-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float32 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --remove_unused_columns False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y-hXHA8jAIb7",
        "outputId": "33fd1399-e2c2-423e-977b-7a8426d388aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 47M\n",
            "-rw-r--r-- 1 root root  849 Mar 18 20:14 adapter_config.json\n",
            "-rw-r--r-- 1 root root  36M Mar 18 20:14 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  482 Mar 18 20:14 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar 18 20:14 \u001b[0m\u001b[01;34mcheckpoint-339\u001b[0m/\n",
            "-rw-r--r-- 1 root root  288 Mar 18 20:14 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar 18 20:14 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar 18 19:59 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  485 Mar 18 20:14 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 20:14 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 20:14 tokenizer.json\n",
            "-rw-r--r-- 1 root root 8.4K Mar 18 20:14 trainer_state.json\n",
            "-rw-r--r-- 1 root root  214 Mar 18 20:14 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-rm-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QexN74gMAIb8"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DRz7jb_AAIb8"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "XZ5Wqlgtp--p",
        "outputId": "ded32187-4f6a-455a-f749-30f19e159b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V1DeuEs5AIb8",
        "outputId": "7fb8743a-88d7-4ac1-b52f-f21ed9dc8c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 20:16:10.402209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742328970.437637   16132 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742328970.448364   16132 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 20:16:10.484193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', tokenizer_path=None, lora_model='outputs-rm-v1', resize_emb=False, output_dir='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft\n",
            "LoRA model: outputs-rm-v1\n",
            "Loading LoRA for sequence classification model\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft --lora_model outputs-rm-v1 --output_dir deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mkijAtI7AIb9",
        "outputId": "a7ebbee2-b861-42ab-98db-70daecb128a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5.8G\n",
            "-rw-r--r-- 1 root root  862 Mar 18 20:16 config.json\n",
            "-rw-r--r-- 1 root root 5.8G Mar 18 20:19 model.safetensors\n",
            "-rw-r--r-- 1 root root  485 Mar 18 20:16 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 20:16 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 20:16 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MYq2PXF8AIcB",
        "outputId": "6ddfa5f4-2e52-4912-9617-7e678a6282bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "n74EeWErAIcD"
      },
      "source": [
        "Stage3 奖励建模第一次训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:12:09.472414Z",
          "start_time": "2023-06-15T14:12:09.464881Z"
        },
        "id": "O_wsCHWFAIcD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4o2_hzgDAIcD"
      },
      "source": [
        "# Stage 4: Reinforcement Learning Training\n",
        "\n",
        "第四阶段：RL(Reinforcement Learning)基于人类反馈的强化学习(RLHF)，用奖励模型来训练SFT模型，生成模型使用奖励或惩罚来更新其策略，以便生成更高质量、更符合人类偏好的文本\n",
        "\n",
        "| Stage 4: Reinforcement Learning |  [rl_training.py](https://github.com/shibing624/MedicalGPT/blob/main/rl_training.py) | [run_rl.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rl.sh)    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vMMktDV-AIcE"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型、奖励模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage2得到的SFT模型\n",
        "2. 奖励模型：使用的是`OpenAssistant/reward-model-deberta-v3-large-v2` 或者 Stage3得到的BERT类或者GPT类奖励模型\n",
        "3. 数据集：RL阶段的数据可以复用SFT的数据集，使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "13ZU9QxwAIcE"
      },
      "source": [
        "## Stage4 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载生成模型和tokenizer，加载奖励模型和其tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果\n",
        "\n",
        "以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JvvVCcB3AIcF",
        "outputId": "909c2b0c-c898-4001-fb33-4823d25d3bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl  sharegpt_zh_1K_format.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "T-0WvYkuAIcF",
        "outputId": "1cffd802-1812-4b7e-cfbb-321597c61d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 20:29:51.651352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742329791.901606   19609 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742329791.969789   19609 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 20:29:52.497486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-03-18 20:30:00.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mParse args: PPOArguments(dataset_name=None, dataset_config=None, dataset_train_split='train', dataset_test_split='test', train_file_dir='./data/finetune', validation_file_dir='./data/finetune', template_name='MedicalDeepSeek', max_source_length=256)\u001b[0m\n",
            "\u001b[32m2025-03-18 20:30:00.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTraining args: PPOConfig(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "batch_size=None,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "cliprange=0.2,\n",
            "cliprange_value=0.2,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset_num_proc=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "ds3_gather_for_generation=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "exp_name=ppo_config,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gamma=1.0,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "kl_coef=0.05,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lam=0.95,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_batch_size=None,\n",
            "local_mini_batch_size=None,\n",
            "local_rank=0,\n",
            "local_rollout_forward_batch_size=64,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-ppo-v1/runs/Mar18_20-30-00_82f83119e260,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "micro_batch_size=None,\n",
            "mini_batch_size=None,\n",
            "missing_eos_penalty=None,\n",
            "model_adapter_name=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_mini_batches=1,\n",
            "num_ppo_epochs=4,\n",
            "num_sample_generations=10,\n",
            "num_total_batches=None,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-ppo-v1,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "ref_adapter_name=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "response_length=1000,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "reward_model_path=./deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm,\n",
            "run_name=outputs-ppo-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=50,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sft_model_path=./deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "stop_token=<STOP_TOKEN>,\n",
            "stop_token_id=None,\n",
            "temperature=0.7,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "total_episodes=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "vf_coef=0.1,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "whiten_rewards=False,\n",
            "world_size=None,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 20:30:00.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mModel args: ModelConfig(model_name_or_path=None, model_revision='main', torch_dtype='float32', trust_remote_code=False, attn_implementation=None, use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)\u001b[0m\n",
            "\u001b[32m2025-03-18 20:30:00.857\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1mTokenizer: LlamaTokenizerFast(name_or_path='./deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! CUDA_VISIBLE_DEVICES=0 python ppo_training.py \\\n",
        "    --sft_model_path ./deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft \\\n",
        "    --reward_model_path ./deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm \\\n",
        "    --template_name MedicalDeepSeek \\\n",
        "    --torch_dtype float32 \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --max_source_length 256 \\\n",
        "    --response_length 1000 \\\n",
        "    --do_train \\\n",
        "    --save_steps 50 \\\n",
        "    --output_dir outputs-ppo-v1 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --report_to tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sRhKGVnmAIcF",
        "outputId": "3252c194-009b-4966-a097-957e8d74f122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'outputs-ppo-v1': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-ppo-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5RS0hbR1AIcF"
      },
      "source": [
        "模型训练结果：\n",
        "- use_peft=False,默认是使用全参训练，模型保存的就是`model-00001-of-00002.safetensors`等文件，配置文件是`config.json`\n",
        "- use_peft=True, 则使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/trl`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/trl --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vfM8CwD0AIcG",
        "outputId": "f7c02cf2-a34b-4198-c4d9-dc39bd904a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'outputs-ppo-v1/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-ppo-v1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KOgYEcWWAIcG",
        "outputId": "66a54e00-18f1-4caf-b1c6-6116ba16755a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: outputs-ppo-v1/config.json: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%cat outputs-ppo-v1/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jfDwWaW3AIcG"
      },
      "source": [
        "Stage4 RL第一次训练完成。\n",
        "\n",
        "**至此一个完整的4阶段训练流程演示完成。**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UcSzGCDjAIcG"
      },
      "source": [
        "实际操作中Stage3和Stage4可以反复多次，直到RL得到的最后模型满足评估要求。\n",
        "\n",
        "RLHF过程可以把SFT模型当成一个初始化模型，RM模型当做指导老师，使用RL(PPO)调教SFT模型生成指导老师最满意的结果，如果小学老师满意了，我们就再训练一个中学老师，继续指导，中学老师满意了，就训练一个大学老师，这样不断迭代，使得生成模型的质量达到甚至超过人工撰写的天花板。\n",
        "\n",
        "RLHF训练不易，此项目提供给大家一种实现的方法和参考，希望抛砖引玉，共同促进中文开源LLM发展。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xYJYLp-uAIcH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:34:29.658428Z",
          "start_time": "2023-06-26T12:34:29.620609Z"
        },
        "id": "yfBI7V9xAIcH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lkFI4cjXAIcH"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eDGvEazZAIcH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:35:00.864463Z",
          "start_time": "2023-06-26T12:34:47.802087Z"
        },
        "id": "knUJKj_uAIcH"
      },
      "outputs": [],
      "source": [
        "!python inference.py --base_model merged-ppo-v1\n",
        "# 或在shell中运行\n",
        "# !python inference.py --base_model merged-ppo-v1 --interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lWqxfnpWAIcI"
      },
      "source": [
        "Input:介绍下南京\n",
        "Response:  南京市位于江苏省西南部，是全国首批历史文化名城、国家中心城市和自由贸易试验区。\n",
        "\n",
        "完。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8R_Z1hFAIcI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}