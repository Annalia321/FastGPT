{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annalia321/FastGPT/blob/main/run_training_ppo_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gCUwyevcAIbo"
      },
      "source": [
        "# Training Pipeline\n",
        "[run_training_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "uPkkiUgMAIbr"
      },
      "source": [
        "# Stage 1: Continue Pretraining\n",
        "\n",
        "ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æœ¬æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒGPTæ¨¡å‹ï¼Œä»¥é€‚é…é¢†åŸŸæ•°æ®åˆ†å¸ƒ\n",
        "\n",
        "æ³¨æ„ï¼š\n",
        "1. æ­¤é˜¶æ®µæ˜¯å¯é€‰çš„ï¼Œå¦‚æœä½ æ²¡æœ‰æµ·é‡é¢†åŸŸæ–‡æœ¬ï¼Œå¯ä»¥è·³è¿‡æ­¤é˜¶æ®µï¼Œç›´æ¥è¿›è¡ŒSFTé˜¶æ®µçš„æœ‰ç›‘ç£å¾®è°ƒ\n",
        "2. æˆ‘å®éªŒå‘ç°ï¼šåšé¢†åŸŸçŸ¥è¯†æ³¨å…¥ï¼ŒSFTæ¯”PTæ›´é«˜æ•ˆï¼Œä¹Ÿå¯ä»¥è·³è¿‡PTé˜¶æ®µ\n",
        "\n",
        "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KagKbMn0AIbu"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Qwen/Qwen2.5-0.5B\n",
        "2. æ•°æ®é›†ï¼šPTé˜¶æ®µä½¿ç”¨çš„æ˜¯ä¸­æ–‡å¤©é¾™å…«éƒ¨å°è¯´éƒ¨åˆ†æ–‡æœ¬å’Œè‹±æ–‡ä¹¦ç±éƒ¨åˆ†æ–‡æœ¬ï¼Œä½äº`data/pretrain`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyS69_1SAIbv"
      },
      "source": [
        "## é…ç½®è¿è¡Œç¯å¢ƒ\n",
        "\n",
        "æœ¬åœ°æ‰§è¡Œå¯æ³¨é‡Šä»¥ä¸‹é…ç½®ç¯å¢ƒçš„å‘½ä»¤ï¼Œcolabæ‰§è¡Œè¦æ‰“å¼€æ³¨é‡Šï¼Œç”¨äºé…ç½®ç¯å¢ƒ\n",
        "\n",
        "colabå»ºè®®ä½¿ç”¨T4 GPUè®­ç»ƒï¼Œè®¾ç½®æ–¹å¼ï¼š`ä»£ç æ‰§è¡Œç¨‹åº -> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ -> è¿è¡Œæ—¶ç±»å‹ï¼šPython3ï¼Œç¡¬ä»¶åŠ é€Ÿå™¨ï¼šGPUï¼ŒGPUç±»å‹ï¼šT4 -> ä¿å­˜`\n",
        "\n",
        "æ­¥éª¤ï¼š\n",
        "1. ä¸‹è½½æœ€æ–°ä»£ç åˆ°æœ¬åœ°\n",
        "2. å®‰è£…ä¾èµ–åŒ…\n",
        "\n",
        "ä¾èµ–åŒ…å¦‚ä¸‹ï¼Œä¿è¯æœ€æ–°ç‰ˆæœ¬ï¼š\n",
        "\n",
        "```\n",
        "loguru\n",
        "transformers\n",
        "sentencepiece\n",
        "datasets\n",
        "tensorboard\n",
        "tqdm\n",
        "peft\n",
        "trl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "n9hIgttJAIbw",
        "outputId": "0d638874-e889-4609-a20b-406adbffed1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedicalGPT'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 92 (delta 17), reused 42 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 8.55 MiB | 14.96 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/MedicalGPT\n",
            "build_domain_tokenizer.py   merge_peft_adapter.py  run_ppo.sh\n",
            "chatpdf.py                  merge_tokenizers.py    run_pt.sh\n",
            "CITATION.cff                model_quant.py         run_quant.sh\n",
            "_config.yml                 openai_api.py          run_rm.sh\n",
            "CONTRIBUTING.md             orpo_training.py       run_sft.sh\n",
            "convert_dataset.py          ppo_training.py        run_training_dpo_pipeline.ipynb\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/                       pretraining.py         run_training_ppo_pipeline.ipynb\n",
            "DISCLAIMER                  README_EN.md           supervised_finetuning.py\n",
            "\u001b[01;34mdocs\u001b[0m/                       README.md              template.py\n",
            "dpo_training.py             requirements.txt       validate_jsonl.py\n",
            "eval_quantize.py            reward_modeling.py     vllm_deployment.sh\n",
            "fastapi_server_demo.py      \u001b[01;34mrole_play_data\u001b[0m/        zero1.yaml\n",
            "gradio_demo.py              run_dpo.sh             zero2.json\n",
            "grpo_training.py            run_eval_quantize.sh   zero2.yaml\n",
            "inference_multigpu_demo.py  run_full_sft.sh        zero3.json\n",
            "inference.py                run_grpo.sh            zero3.yaml\n",
            "LICENSE                     run_orpo.sh\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting datasets>=2.14.6 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting loguru (from -r requirements.txt (line 3))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: peft>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Collecting transformers>=4.49.0 (from -r requirements.txt (line 9))\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl>=0.15.2 (from -r requirements.txt (line 10))\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.10.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting math-verify==0.5.2 (from -r requirements.txt (line 13))\n",
            "  Downloading math_verify-0.5.2-py3-none-any.whl.metadata (347 bytes)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended->-r requirements.txt (line 12))\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from latex2sympy2_extended->-r requirements.txt (line 12)) (1.13.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.11.13)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (0.21.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl>=0.15.2->-r requirements.txt (line 10)) (13.9.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.14.6->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->latex2sympy2_extended->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.15.2->-r requirements.txt (line 10)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.15.2->-r requirements.txt (line 10)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl>=0.15.2->-r requirements.txt (line 10)) (0.1.2)\n",
            "Downloading math_verify-0.5.2-py3-none-any.whl (27 kB)\n",
            "Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: antlr4-python3-runtime, xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, loguru, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, latex2sympy2_extended, nvidia-cusolver-cu12, math-verify, transformers, datasets, trl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed antlr4-python3-runtime-4.13.2 datasets-3.4.1 dill-0.3.8 latex2sympy2_extended-1.0.6 loguru-0.7.3 math-verify-0.5.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.49.0 trl-0.15.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
        "%cd MedicalGPT\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SHicioKAIby"
      },
      "source": [
        "## Stage1 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
        "\n",
        "**ä»¥ä¸‹å‚æ•°å¯ä»¥æ ¹æ®ä½ çš„GPUå®é™…æƒ…å†µä¿®æ”¹ï¼Œå½“å‰å‚æ•°æ˜¯æ ¹æ®Colabçš„T4å•å¡GPUï¼ˆ16GBæ˜¾å­˜ï¼‰é…ç½®çš„**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyOwhMQbAIbz"
      },
      "outputs": [],
      "source": [
        "%ls ./data/pretrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "U2kKJQKbAIbz",
        "outputId": "971fc148-77e1-4511-e0cf-2f851b67e722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 16:30:59.236561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742315459.471440    6474 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742315459.532665    6474 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 16:31:00.029386: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 16:31:06.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m359\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/deepseek-llm-7b-base', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-pt-v1/runs/Mar18_16-31-05_5e53693f8c97,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-pt-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=3,\n",
            "per_device_train_batch_size=3,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-pt-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:06.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "tokenizer_config.json: 100% 792/792 [00:00<00:00, 4.69MB/s]\n",
            "tokenizer.json: 100% 4.61M/4.61M [00:00<00:00, 5.15MB/s]\n",
            "\u001b[32m2025-03-18 16:31:10.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m471\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/tianlongbabu.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:10.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m481\u001b[0m - \u001b[1meval files: ['./data/pretrain/tianlongbabu.txt', './data/pretrain/en_article_tail500.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "Generating train split: 3876 examples [00:00, 140777.46 examples/s]\n",
            "Generating validation split: 3876 examples [00:00, 401301.43 examples/s]\n",
            "\u001b[32m2025-03-18 16:31:11.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m513\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "})\u001b[0m\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:01<00:00, 3633.57 examples/s]\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:00<00:00, 4059.27 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 5101.95 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 8156.30 examples/s]\n",
            "\u001b[32m2025-03-18 16:31:15.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m576\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2646\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m577\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.218\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m578\u001b[0m - \u001b[34m\u001b[1m<ï½œbeginâ–ofâ–sentenceï½œ>å¤©é¾™å…«éƒ¨\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>æ­£æ–‡ é‡Šå\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>â€œå¤©é¾™å…«éƒ¨â€è¿™åè¯å‡ºäºä½›ç»ã€‚è®¸å¤šå¤§ä¹˜ä½›ç»å™è¿°ä½›å‘è¯¸è©è¨ã€æ¯”ä¸˜ç­‰è¯´æ³•æ—¶ï¼Œå´å¸¸æœ‰å¤©é¾™å…«éƒ¨å‚ä¸å¬æ³•ã€‚å¦‚â€œæ³•åç»ï¼šæå©†è¾¾å¤šå“â€ï¼šâ€œå¤©é¾™å…«éƒ¨ã€äººä¸éäººï¼Œçš†å´é¥è§å½¼é¾™å¥³æˆä½›â€ã€‚\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>â€œéäººâ€ï¼ŒåŒ…æ‹¬å…«ç§ç¥é“æ€ªç‰©ï¼Œå› ä¸ºä»¥â€œå¤©â€åŠâ€œé¾™â€ä¸ºé¦–ï¼Œå´æ‰€ä»¥ç§°ä¸ºã€Šå¤©é¾™å…«éƒ¨\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m590\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m591\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 16:31:15.221\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m592\u001b[0m - \u001b[34m\u001b[1m<ï½œbeginâ–ofâ–sentenceï½œ>å¤©é¾™å…«éƒ¨\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>æ­£æ–‡ é‡Šå\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>â€œå¤©é¾™å…«éƒ¨â€è¿™åè¯å‡ºäºä½›ç»ã€‚è®¸å¤šå¤§ä¹˜ä½›ç»å™è¿°ä½›å‘è¯¸è©è¨ã€æ¯”ä¸˜ç­‰è¯´æ³•æ—¶ï¼Œå´å¸¸æœ‰å¤©é¾™å…«éƒ¨å‚ä¸å¬æ³•ã€‚å¦‚â€œæ³•åç»ï¼šæå©†è¾¾å¤šå“â€ï¼šâ€œå¤©é¾™å…«éƒ¨ã€äººä¸éäººï¼Œçš†å´é¥è§å½¼é¾™å¥³æˆä½›â€ã€‚\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>â€œéäººâ€ï¼ŒåŒ…æ‹¬å…«ç§ç¥é“æ€ªç‰©ï¼Œå› ä¸ºä»¥â€œå¤©â€åŠâ€œé¾™â€ä¸ºé¦–ï¼Œå´æ‰€ä»¥ç§°ä¸ºã€Šå¤©é¾™å…«éƒ¨\u001b[0m\n",
            "config.json: 100% 584/584 [00:00<00:00, 4.11MB/s]\n",
            "pytorch_model.bin.index.json: 100% 22.5k/22.5k [00:00<00:00, 86.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.97G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.97G [00:00<00:52, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.97G [00:00<00:43, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 83.9M/9.97G [00:00<00:42, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 115M/9.97G [00:00<00:43, 227MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.97G [00:00<00:43, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.97G [00:00<00:40, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.97G [00:00<00:41, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 241M/9.97G [00:01<00:40, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.97G [00:01<01:15, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.97G [00:01<01:02, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.97G [00:01<00:53, 181MB/s]\u001b[A\n",
            "\n",
            "model.safetensors.index.json: 100% 23.6k/23.6k [00:00<00:00, 61.9MB/s]\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 367M/9.97G [00:01<00:50, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.97G [00:02<00:46, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.97G [00:02<00:44, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 461M/9.97G [00:02<00:43, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.97G [00:02<00:41, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.97G [00:02<00:41, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.97G [00:02<00:42, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.97G [00:02<00:41, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 619M/9.97G [00:02<00:39, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.97G [00:03<00:39, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 682M/9.97G [00:03<00:39, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.97G [00:03<00:40, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.97G [00:03<00:40, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 776M/9.97G [00:03<00:39, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.97G [00:03<00:39, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.97G [00:03<00:41, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 870M/9.97G [00:04<00:39, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 902M/9.97G [00:04<00:40, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 933M/9.97G [00:04<00:39, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.97G [00:04<00:36, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.97G [00:04<00:35, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.97G [00:04<00:37, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.97G [00:04<00:37, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.97G [00:04<00:37, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.97G [00:05<00:38, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.97G [00:05<00:36, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.97G [00:05<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.97G [00:05<00:33, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.97G [00:05<00:34, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.97G [00:05<00:35, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.31G/9.97G [00:05<00:36, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.97G [00:05<00:34, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.97G [00:06<00:38, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.97G [00:06<00:37, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.97G [00:06<00:36, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.97G [00:06<00:36, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.97G [00:06<00:36, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.97G [00:06<00:36, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.97G [00:06<00:35, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.97G [00:07<00:33, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.97G [00:07<00:33, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.97G [00:07<00:34, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.97G [00:07<00:35, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.97G [00:07<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.97G [00:07<00:36, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.97G [00:07<00:35, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.97G [00:07<00:34, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.85G/9.97G [00:08<00:34, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.97G [00:08<00:34, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.97G [00:08<00:40, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.97G [00:08<00:38, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.97G [00:08<00:36, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.97G [00:08<00:35, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.97G [00:09<00:35, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.97G [00:09<00:34, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.97G [00:09<00:43, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.97G [00:09<00:40, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.97G [00:09<00:37, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.97G [00:09<00:36, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.97G [00:09<00:35, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.97G [00:10<00:37, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.97G [00:10<00:40, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.97G [00:10<00:38, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.97G [00:10<00:47, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.97G [00:10<00:41, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.97G [00:10<00:40, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.97G [00:11<00:42, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.44G/9.97G [00:11<00:43, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.97G [00:11<00:42, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.97G [00:11<00:41, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.97G [00:11<00:40, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.97G [00:11<00:38, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.97G [00:11<00:39, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.97G [00:18<10:52, 11.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.97G [00:18<06:14, 19.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.97G [00:18<04:24, 27.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.97G [00:18<03:09, 38.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.97G [00:18<02:19, 51.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.97G [00:18<01:48, 66.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.97G [00:19<01:22, 87.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.97G [00:19<01:05, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.84G/9.97G [00:19<00:54, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.97G [00:19<00:46, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.97G [00:19<00:40, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.97G [00:19<00:37, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.97G [00:19<00:34, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.97G [00:19<00:32, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.97G [00:20<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.97G [00:20<00:31, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.97G [00:20<00:37, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.97G [00:20<00:35, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.97G [00:20<00:32, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.97G [00:20<00:31, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.97G [00:21<00:30, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.97G [00:21<01:01, 109MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.97G [00:21<00:55, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.97G [00:22<02:13, 50.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.97G [00:24<03:40, 30.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.97G [00:24<02:30, 44.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.97G [00:24<01:48, 60.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.97G [00:24<01:22, 79.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.44G/9.97G [00:24<01:04, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.47G/9.97G [00:25<00:52, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.50G/9.97G [00:25<00:44, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.97G [00:25<00:39, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.97G [00:25<00:36, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.60G/9.97G [00:25<00:33, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.63G/9.97G [00:25<00:31, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.97G [00:25<00:30, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.69G/9.97G [00:26<00:30, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.97G [00:26<00:28, 221MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.97G [00:26<00:28, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.97G [00:26<00:28, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.97G [00:27<01:26, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.84G/9.97G [00:27<01:14, 82.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.97G [00:28<02:14, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.97G [00:28<01:37, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.97G [00:29<01:12, 83.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.97G [00:29<00:56, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.97G [00:29<00:48, 122MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.97G [00:29<00:41, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.97G [00:29<00:35, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.97G [00:29<00:32, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.97G [00:30<00:41, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.97G [00:30<00:36, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.97G [00:30<00:35, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.19G/9.97G [00:31<01:33, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.97G [00:31<01:17, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.97G [00:32<02:18, 41.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.97G [00:34<03:38, 26.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.97G [00:34<02:25, 39.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.97G [00:34<01:43, 54.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.97G [00:34<01:17, 72.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.97G [00:34<01:05, 85.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.97G [00:35<00:50, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.44G/9.97G [00:35<00:41, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.97G [00:35<00:35, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.97G [00:35<00:34, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.97G [00:35<00:30, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.97G [00:35<00:28, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.97G [00:35<00:26, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.97G [00:36<00:24, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.97G [00:36<00:25, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.97G [00:36<00:28, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.71G/9.97G [00:38<02:34, 34.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.97G [00:38<01:49, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.97G [00:39<01:21, 63.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.97G [00:39<01:02, 82.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.97G [00:39<00:49, 104MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.97G [00:39<00:40, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.97G [00:39<00:34, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.97G [00:39<00:30, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.97G [00:39<00:27, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.97G [00:39<00:25, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.97G [00:40<00:23, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.97G [00:40<00:22, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.97G [00:40<00:22, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.12G/9.97G [00:40<00:20, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.97G [00:40<00:20, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.97G [00:40<00:20, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.97G [00:40<00:24, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.97G [00:41<00:23, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.97G [00:41<00:24, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.97G [00:41<00:23, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.97G [00:41<00:24, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.34G/9.97G [00:41<00:38, 121MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.97G [00:42<00:57, 80.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.97G [00:47<05:26, 14.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.97G [00:47<03:29, 21.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.97G [00:47<02:22, 31.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.97G [00:47<01:40, 44.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.97G [00:47<01:14, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.54G/9.97G [00:47<00:56, 79.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.97G [00:47<00:43, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.97G [00:47<00:36, 119MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.97G [00:48<00:32, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.97G [00:48<00:28, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.97G [00:48<00:25, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.97G [00:48<00:23, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.97G [00:48<00:22, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.97G [00:48<00:21, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.97G [00:48<00:20, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.97G [00:49<00:19, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.97G [00:49<00:19, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.97G [00:49<00:19, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.97G [00:49<00:21, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.97G [00:49<00:27, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.97G [00:50<00:23, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.03G/9.97G [00:54<03:35, 18.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.97G [00:55<03:01, 21.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.97G [00:55<02:19, 27.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.97G [00:55<01:35, 40.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.97G [00:55<01:15, 50.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.97G [00:55<00:54, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.97G [00:55<00:41, 91.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.97G [00:55<00:32, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.97G [00:56<00:28, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.97G [00:56<00:23, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.97G [00:56<00:21, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.97G [00:56<00:19, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.97G [00:56<00:18, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.97G [00:56<00:17, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.97G [00:56<00:16, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.97G [00:57<00:16, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.53G/9.97G [00:57<00:14, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.97G [00:57<00:14, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.97G [00:57<00:14, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.97G [00:57<00:14, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.97G [00:57<00:13, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.97G [00:58<00:13, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.97G [00:58<00:13, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.97G [00:58<00:13, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.97G [00:58<00:13, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.97G [00:58<00:12, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.97G [00:58<00:12, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.97G [00:58<00:12, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.97G [00:59<00:13, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.97G [00:59<00:12, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.97G [00:59<00:11, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.97G [00:59<00:12, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.97G [00:59<00:11, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.97G [00:59<00:11, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.13G/9.97G [00:59<00:11, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.97G [00:59<00:11, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.97G [01:00<00:11, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.97G [01:00<00:11, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.97G [01:00<00:11, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.97G [01:00<00:11, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.97G [01:00<00:11, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.97G [01:00<00:11, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.97G [01:00<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.97G [01:01<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.97G [01:01<00:10, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.97G [01:01<00:10, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.97G [01:01<00:10, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.97G [01:01<00:10, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.97G [01:01<00:10, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.97G [01:07<02:18, 17.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.62G/9.97G [01:07<01:49, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.97G [01:07<01:25, 27.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.97G [01:07<00:59, 38.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.97G [01:08<00:42, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.97G [01:08<00:31, 71.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.97G [01:08<00:24, 90.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.97G [01:08<00:19, 113MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.97G [01:08<00:16, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.97G [01:08<00:13, 153MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.97G [01:08<00:12, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.93G/9.97G [01:08<00:10, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.97G [01:09<00:09, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.97G [01:09<00:09, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.97G [01:09<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.97G [01:09<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.97G [01:09<00:08, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.97G [01:09<00:08, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.97G [01:09<00:07, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.97G [01:10<00:10, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.97G [01:10<00:09, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.97G [01:10<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.97G [01:10<00:08, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.30G/9.97G [01:10<00:08, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.97G [01:10<00:07, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.97G [01:11<00:07, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.97G [01:11<00:07, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.43G/9.97G [01:11<00:07, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.97G [01:11<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.97G [01:11<00:06, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.52G/9.97G [01:11<00:06, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.97G [01:11<00:06, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.97G [01:11<00:06, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.97G [01:12<00:05, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.97G [01:12<00:05, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.97G [01:12<00:05, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.71G/9.97G [01:12<00:05, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.97G [01:12<00:05, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.97G [01:12<00:05, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.97G [01:12<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.97G [01:13<00:04, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.97G [01:13<00:04, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.90G/9.97G [01:13<00:04, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.97G [01:13<00:04, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.97G/9.97G [01:13<00:04, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.00G/9.97G [01:14<00:06, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.97G [01:17<00:42, 22.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.04G/9.97G [01:17<00:33, 27.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.97G [01:18<00:22, 39.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.10G/9.97G [01:18<00:16, 53.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.97G [01:18<00:11, 71.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.97G [01:18<00:09, 83.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.19G/9.97G [01:18<00:07, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.97G [01:18<00:05, 128MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.25G/9.97G [01:18<00:04, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.97G [01:19<00:04, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.97G [01:19<00:03, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.97G [01:19<00:03, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.97G [01:19<00:02, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.97G [01:19<00:02, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.44G/9.97G [01:19<00:02, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.97G [01:19<00:02, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.97G [01:19<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.97G [01:20<00:01, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.56G/9.97G [01:20<00:01, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.59G/9.97G [01:20<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.63G/9.97G [01:20<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.66G/9.97G [01:20<00:01, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.97G [01:20<00:01, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.97G [01:20<00:00, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.97G [01:20<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.97G [01:21<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.83G/9.97G [01:21<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.97G [01:23<00:03, 36.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.97G [01:24<00:01, 49.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.92G/9.97G [01:24<00:00, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.97G/9.97G [01:24<00:00, 118MB/s] \n",
            "Downloading shards:  50% 1/2 [01:24<01:24, 84.61s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.85G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.85G [00:00<00:15, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.85G [00:00<00:16, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 94.4M/3.85G [00:00<00:14, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 126M/3.85G [00:00<00:16, 233MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 157M/3.85G [00:00<00:14, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.85G [00:00<00:14, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.85G [00:00<00:14, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.85G [00:01<00:15, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 283M/3.85G [00:01<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 315M/3.85G [00:01<00:14, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 346M/3.85G [00:01<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 377M/3.85G [00:01<00:14, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 409M/3.85G [00:01<00:14, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 440M/3.85G [00:01<00:16, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 472M/3.85G [00:02<00:15, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 503M/3.85G [00:02<00:14, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 535M/3.85G [00:02<00:14, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 566M/3.85G [00:02<00:16, 197MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 587M/3.85G [00:02<00:20, 159MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 608M/3.85G [00:05<01:58, 27.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 640M/3.85G [00:05<01:21, 39.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 682M/3.85G [00:05<00:52, 59.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 713M/3.85G [00:05<00:40, 77.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 744M/3.85G [00:05<00:32, 96.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 776M/3.85G [00:06<00:25, 118MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 807M/3.85G [00:06<00:21, 139MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 839M/3.85G [00:06<00:18, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 870M/3.85G [00:06<00:16, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 902M/3.85G [00:06<00:15, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 933M/3.85G [00:06<00:14, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 965M/3.85G [00:06<00:13, 218MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 996M/3.85G [00:07<00:12, 225MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.03G/3.85G [00:07<00:12, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.06G/3.85G [00:07<00:12, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 1.09G/3.85G [00:07<00:11, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.12G/3.85G [00:07<00:11, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.15G/3.85G [00:07<00:11, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.18G/3.85G [00:07<00:11, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.22G/3.85G [00:07<00:11, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.25G/3.85G [00:08<00:10, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.28G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.31G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.34G/3.85G [00:08<00:10, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.37G/3.85G [00:08<00:10, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.41G/3.85G [00:08<00:10, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.44G/3.85G [00:08<00:09, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.47G/3.85G [00:08<00:09, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.50G/3.85G [00:09<00:09, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.53G/3.85G [00:09<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.56G/3.85G [00:09<00:09, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.59G/3.85G [00:09<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.63G/3.85G [00:11<00:43, 50.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.67G/3.85G [00:11<00:29, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.70G/3.85G [00:11<00:23, 91.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.73G/3.85G [00:11<00:19, 111MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.76G/3.85G [00:11<00:15, 132MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.79G/3.85G [00:11<00:13, 153MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.82G/3.85G [00:12<00:11, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.86G/3.85G [00:12<00:10, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.89G/3.85G [00:12<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.92G/3.85G [00:12<00:08, 222MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.95G/3.85G [00:12<00:08, 221MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.98G/3.85G [00:12<00:08, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 2.01G/3.85G [00:12<00:07, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 2.04G/3.85G [00:12<00:07, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 2.08G/3.85G [00:13<00:07, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 2.11G/3.85G [00:13<00:07, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.14G/3.85G [00:13<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.17G/3.85G [00:13<00:07, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.20G/3.85G [00:13<00:06, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.23G/3.85G [00:13<00:06, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.26G/3.85G [00:13<00:06, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.30G/3.85G [00:14<00:06, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.33G/3.85G [00:14<00:06, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.36G/3.85G [00:14<00:06, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.39G/3.85G [00:14<00:05, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.42G/3.85G [00:14<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.45G/3.85G [00:14<00:05, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.49G/3.85G [00:14<00:05, 250MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.52G/3.85G [00:14<00:05, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.55G/3.85G [00:15<00:05, 224MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.58G/3.85G [00:15<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.62G/3.85G [00:15<00:04, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.65G/3.85G [00:15<00:04, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.68G/3.85G [00:15<00:05, 217MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.72G/3.85G [00:15<00:05, 199MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.75G/3.85G [00:15<00:05, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.78G/3.85G [00:16<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.81G/3.85G [00:16<00:04, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.84G/3.85G [00:16<00:04, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.87G/3.85G [00:16<00:04, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.90G/3.85G [00:16<00:04, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.94G/3.85G [00:16<00:03, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.97G/3.85G [00:16<00:03, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 3.00G/3.85G [00:17<00:03, 215MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.03G/3.85G [00:17<00:03, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.06G/3.85G [00:17<00:03, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 3.09G/3.85G [00:17<00:03, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 3.12G/3.85G [00:17<00:03, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 3.16G/3.85G [00:17<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 3.19G/3.85G [00:17<00:02, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.22G/3.85G [00:17<00:02, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.25G/3.85G [00:18<00:02, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.28G/3.85G [00:18<00:02, 240MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.31G/3.85G [00:18<00:02, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.34G/3.85G [00:18<00:02, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.38G/3.85G [00:18<00:01, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.41G/3.85G [00:18<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.44G/3.85G [00:18<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.47G/3.85G [00:19<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.50G/3.85G [00:19<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.53G/3.85G [00:19<00:01, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.57G/3.85G [00:19<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.60G/3.85G [00:19<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.63G/3.85G [00:19<00:00, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.66G/3.85G [00:19<00:00, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.69G/3.85G [00:19<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.72G/3.85G [00:20<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.75G/3.85G [00:20<00:00, 238MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.79G/3.85G [00:20<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.82G/3.85G [00:20<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.85G/3.85G [00:20<00:00, 187MB/s]\n",
            "Downloading shards: 100% 2/2 [01:45<00:00, 52.73s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:58<00:00, 29.49s/it]\n",
            "generation_config.json: 100% 121/121 [00:00<00:00, 1.06MB/s]\n",
            "\u001b[32m2025-03-18 16:34:03.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m651\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m656\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m669\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:03.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m670\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 18,739,200 || all params: 6,929,104,896 || trainable%: 0.2704\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py:658: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
            "  warnings.warn(\n",
            "/content/MedicalGPT/pretraining.py:700: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 16:34:04.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m715\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-03-18 16:34:05.038\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m716\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[ 49249,   1336,   3641,    923,    398,    976,    185, 100000,  17878,\n",
            "           1907,  19253,  61051,  19304,    443,    111,  92920,   1127,    398,\n",
            "          36867,   2266,   1680,  19304,   1671,  23639,  10741,   7560,    913,\n",
            "          19304,  67408,  33433,    398,   7664,  46964,   3160,   1759,  45326,\n",
            "            790,   1372,   4045,   1720,  52055,  17497,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,    852,   6074,  17497,  19304,  19015,\n",
            "           6342,    885,  50217,  50217,   1506,    929,   1748,  65510,  19304,\n",
            "           2830,  32845,   8375,    398,   2141,   8438,  76780,   1372,  51433,\n",
            "           7861,   7351,    398,    976,   7664,  46964,   3160,  24040,  13147,\n",
            "          84064,   6622,    504,   6214,  19304,   1759,  45326,    790,  10012,\n",
            "           1372,   1087,   1827,  13725,    398,  32508,  26273,  17878,   9457,\n",
            "          17699,  49373,  19304,  54029,    573,  99880,   3411,   2104,   2224,\n",
            "          36397,    787,  70560,    923,  24437,   1827,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,   4607,   2510,   2125,  14847,   3381,\n",
            "           9554,    537],\n",
            "        [  1848,   4276,   1507,   3672,  29371,   1662,    106,  37559,   1186,\n",
            "           1759,  19304,   4595,   1186,  33965,  37163,  20753,  19304,  22924,\n",
            "           1391,  77338,    612,  37163,   5808,   8245,  21083,    398,  19388,\n",
            "           1087,   1848,   1759,  45326,    790,  78942,   2961,   2412,    398,\n",
            "            976,    185, 100000,   4200,   2206,  65208,   1759,  45326,    790,\n",
            "          17374,   2160,   1372,   8010,  19472,   1537,    852,    398,    976,\n",
            "           2206,    892,   2657,   1186,   1759,    764,  25468,   1827,  19304,\n",
            "          16127,   3344,   2797,   4090,  91574,  78500,   3115,    505,  19370,\n",
            "          19304,   2108,   1511,   6622,    504,  16920,    398,   4200,   2206,\n",
            "          65208,  21846,  20239,   1762,  19304,  15710,   1848,  10564,  19304,\n",
            "           3846,   5093,   9066,   1759,  45326,    790,   3149,    630,   2224,\n",
            "            976,    185, 100000,  91574,   1102,   1873,    630,   3846,   5093,\n",
            "           1759,  45326,    790,   3996,  14714,   2160,  26224,  19304,  46826,\n",
            "           4547,  15315,    398,    976,  28471,   1649,  86910,   8375,    398,\n",
            "           4200,   2206],\n",
            "        [ 50836,   1854,   4779,   1965,    121,   3056,  96102,    398,   2775,\n",
            "           3056,  20631,  59241,  12295,  19304,  10435,    537,  63103,   3056,\n",
            "            573,  75993,  34126,  19304,  32101,  50836,  23212,   3056,  96102,\n",
            "           4425,     16,     15,    948,    214,   3611,  34126,  19304,  38966,\n",
            "           3056,   9467,     20,     15,      4,  19304,  15544,   3056,   4425,\n",
            "             22,     15,    948,    214,  75993,  34126,    398,    185, 100000,\n",
            "          50836,   4779,   1965,    121,   3056,  96102,  45326,  24364,  10244,\n",
            "            337,  82562,  27455,  10239,  19304,  90091,   1937,   2045,    398,\n",
            "           4779,   1965,    121,  28315,  45326,  10435,    537,  63103,   3056,\n",
            "          96102,   1762,   3175,   3310,   8092,  19304,   4425,     23,     15,\n",
            "            948,    214,   9752,    609,  48763,    537,   9093,  33770,  11527,\n",
            "            398,  23212,    537,  38966,    537,  15544,   3056,  96102,   1762,\n",
            "           3175,  14130,   3310,  11165,  19304,   4225,  31394,    609,  48763,\n",
            "            398,   2133,   2045,   5649,  16323,    609,  29587,  75471,    537,\n",
            "          53636,  89418]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[ 49249,   1336,   3641,    923,    398,    976,    185, 100000,  17878,\n",
            "           1907,  19253,  61051,  19304,    443,    111,  92920,   1127,    398,\n",
            "          36867,   2266,   1680,  19304,   1671,  23639,  10741,   7560,    913,\n",
            "          19304,  67408,  33433,    398,   7664,  46964,   3160,   1759,  45326,\n",
            "            790,   1372,   4045,   1720,  52055,  17497,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,    852,   6074,  17497,  19304,  19015,\n",
            "           6342,    885,  50217,  50217,   1506,    929,   1748,  65510,  19304,\n",
            "           2830,  32845,   8375,    398,   2141,   8438,  76780,   1372,  51433,\n",
            "           7861,   7351,    398,    976,   7664,  46964,   3160,  24040,  13147,\n",
            "          84064,   6622,    504,   6214,  19304,   1759,  45326,    790,  10012,\n",
            "           1372,   1087,   1827,  13725,    398,  32508,  26273,  17878,   9457,\n",
            "          17699,  49373,  19304,  54029,    573,  99880,   3411,   2104,   2224,\n",
            "          36397,    787,  70560,    923,  24437,   1827,   2224,    976,   4200,\n",
            "          15839,   1759,  45326,    790,   4607,   2510,   2125,  14847,   3381,\n",
            "           9554,    537],\n",
            "        [  1848,   4276,   1507,   3672,  29371,   1662,    106,  37559,   1186,\n",
            "           1759,  19304,   4595,   1186,  33965,  37163,  20753,  19304,  22924,\n",
            "           1391,  77338,    612,  37163,   5808,   8245,  21083,    398,  19388,\n",
            "           1087,   1848,   1759,  45326,    790,  78942,   2961,   2412,    398,\n",
            "            976,    185, 100000,   4200,   2206,  65208,   1759,  45326,    790,\n",
            "          17374,   2160,   1372,   8010,  19472,   1537,    852,    398,    976,\n",
            "           2206,    892,   2657,   1186,   1759,    764,  25468,   1827,  19304,\n",
            "          16127,   3344,   2797,   4090,  91574,  78500,   3115,    505,  19370,\n",
            "          19304,   2108,   1511,   6622,    504,  16920,    398,   4200,   2206,\n",
            "          65208,  21846,  20239,   1762,  19304,  15710,   1848,  10564,  19304,\n",
            "           3846,   5093,   9066,   1759,  45326,    790,   3149,    630,   2224,\n",
            "            976,    185, 100000,  91574,   1102,   1873,    630,   3846,   5093,\n",
            "           1759,  45326,    790,   3996,  14714,   2160,  26224,  19304,  46826,\n",
            "           4547,  15315,    398,    976,  28471,   1649,  86910,   8375,    398,\n",
            "           4200,   2206],\n",
            "        [ 50836,   1854,   4779,   1965,    121,   3056,  96102,    398,   2775,\n",
            "           3056,  20631,  59241,  12295,  19304,  10435,    537,  63103,   3056,\n",
            "            573,  75993,  34126,  19304,  32101,  50836,  23212,   3056,  96102,\n",
            "           4425,     16,     15,    948,    214,   3611,  34126,  19304,  38966,\n",
            "           3056,   9467,     20,     15,      4,  19304,  15544,   3056,   4425,\n",
            "             22,     15,    948,    214,  75993,  34126,    398,    185, 100000,\n",
            "          50836,   4779,   1965,    121,   3056,  96102,  45326,  24364,  10244,\n",
            "            337,  82562,  27455,  10239,  19304,  90091,   1937,   2045,    398,\n",
            "           4779,   1965,    121,  28315,  45326,  10435,    537,  63103,   3056,\n",
            "          96102,   1762,   3175,   3310,   8092,  19304,   4425,     23,     15,\n",
            "            948,    214,   9752,    609,  48763,    537,   9093,  33770,  11527,\n",
            "            398,  23212,    537,  38966,    537,  15544,   3056,  96102,   1762,\n",
            "           3175,  14130,   3310,  11165,  19304,   4225,  31394,    609,  48763,\n",
            "            398,   2133,   2045,   5649,  16323,    609,  29587,  75471,    537,\n",
            "          53636,  89418]], device='cuda:0')}\u001b[0m\n",
            "{'loss': 2.9201, 'grad_norm': 0.41207155585289, 'learning_rate': 4.444444444444445e-06, 'epoch': 0.0}\n",
            "{'loss': 2.7201, 'grad_norm': 0.45105651021003723, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.01}\n",
            "{'loss': 2.9258, 'grad_norm': 0.4875084161758423, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.02}\n",
            "{'loss': 2.6475, 'grad_norm': 0.9869950413703918, 'learning_rate': 0.00013333333333333334, 'epoch': 0.03}\n",
            "{'loss': 2.5974, 'grad_norm': 0.817748486995697, 'learning_rate': 0.00017777777777777779, 'epoch': 0.05}\n",
            "{'loss': 2.6202, 'grad_norm': 0.9691812992095947, 'learning_rate': 0.00019880525686977302, 'epoch': 0.06}\n",
            "  6% 50/882 [05:49<1:41:11,  7.30s/it]Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:02<00:02,  1.13s/it]\u001b[A\n",
            " 75% 3/4 [00:04<00:01,  1.61s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 2.321094512939453, 'eval_accuracy': 0.5448818897637795, 'eval_runtime': 7.7423, 'eval_samples_per_second': 1.292, 'eval_steps_per_second': 0.517, 'epoch': 0.06}\n",
            "  6% 50/882 [05:57<1:41:11,  7.30s/it]\n",
            "100% 4/4 [00:05<00:00,  1.32s/it]\u001b[A\n",
            "{'loss': 2.5417, 'grad_norm': 0.8770740032196045, 'learning_rate': 0.00019641577060931903, 'epoch': 0.07}\n",
            "{'loss': 2.4699, 'grad_norm': 0.719561755657196, 'learning_rate': 0.000194026284348865, 'epoch': 0.08}\n",
            "{'loss': 2.4401, 'grad_norm': 0.7502880096435547, 'learning_rate': 0.000191636798088411, 'epoch': 0.09}\n",
            " 10% 86/882 [10:21<1:37:54,  7.38s/it]Traceback (most recent call last):\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 759, in <module>\n",
            "    main()\n",
            "  File \"/content/MedicalGPT/pretraining.py\", line 720, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2241, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2548, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 3740, in training_step\n",
            "    self.accelerator.backward(loss, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\", line 2246, in backward\n",
            "    loss.backward(**kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 626, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 823, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            " 10% 86/882 [10:28<1:37:00,  7.31s/it]\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python pretraining.py \\\n",
        "    --model_name_or_path deepseek-ai/deepseek-llm-7b-base \\\n",
        "    --train_file_dir ./data/pretrain \\\n",
        "    --validation_file_dir ./data/pretrain \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 3 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 20000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --block_size 128 \\\n",
        "    --group_by_length True \\\n",
        "    --output_dir outputs-pt-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2dl19S-AIb0"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-pt-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QnS9RVTAIb1"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.safetensors`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GPwmOFzLAIb2"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdCQyzljAIb2"
      },
      "outputs": [],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model Qwen/Qwen2.5-0.5B --lora_model outputs-pt-v1 --output_dir merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImrXhWqtAIb2"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yFZMf8nAIb3"
      },
      "outputs": [],
      "source": [
        "%cat merged-pt/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBu6XX3nAIb3"
      },
      "source": [
        "Stage1 å¢é‡é¢„è®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:56:17.081153Z",
          "start_time": "2023-06-15T13:56:17.032821Z"
        },
        "id": "pdat-ANgAIb3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6rB3W22cAIb3"
      },
      "source": [
        "# Stage 2: Supervised FineTuning\n",
        "\n",
        "ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾ï¼Œå¹¶æ³¨å…¥é¢†åŸŸçŸ¥è¯†\n",
        "\n",
        "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "v3smO2b0AIb4"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Qwen/Qwen2.5-0.5B æˆ–è€… Stage1å¾—åˆ°çš„é¢„è®­ç»ƒæ¨¡å‹\n",
        "2. æ•°æ®é›†ï¼šSFTé˜¶æ®µä½¿ç”¨çš„æ˜¯ä½¿ç”¨çš„æ˜¯Belleçš„1åƒæ¡æŠ½æ ·æ•°æ®ï¼Œä½äº`data/finetune`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3J_51O20AIb4"
      },
      "source": [
        "## Stage2 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:58:38.966506Z",
          "start_time": "2023-06-15T13:58:38.778132Z"
        },
        "id": "Jqz9ZwfaAIb4",
        "outputId": "d6a91c3a-4597-4d22-c71d-349d758a1eb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl  sharegpt_zh_1K_format.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aQ96YO9JLxab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "oXaSG2VCLVjJ",
        "outputId": "0f7df8f6-6e9f-4af3-e4ec-cc3782950e77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YTgW90m0AIb5",
        "outputId": "323c2339-4ba6-4d51-d8ae-416df2a98e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 17:02:38.514005: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742317358.544369   14623 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742317358.550842   14623 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 17:02:38.572134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-03-18 17:02:41.652\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[33m\u001b[1mYou may set max_train_samples = -1 to run all samples in production.\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 17:02:41.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m309\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', load_in_8bit=False, load_in_4bit=False, tokenizer_name_or_path=None, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True, rope_scaling=None, flash_attn=False, shift_attn=False, neft_alpha=0)\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:41.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m310\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir='./data/finetune', max_train_samples=1000, max_eval_samples=10, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1)\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:41.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-sft-v1/runs/Mar18_17-02-41_5e53693f8c97,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-sft-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-sft-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:41.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m312\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, train_on_inputs=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False, model_max_length=512, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:41.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m313\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "tokenizer_config.json: 100% 3.07k/3.07k [00:00<00:00, 15.7MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 15.4MB/s]\n",
            "\u001b[32m2025-03-18 17:02:44.827\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m346\u001b[0m - \u001b[34m\u001b[1mTokenizer: LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<ï½œbeginâ–ofâ–sentenceï½œ>', 'eos_token': '<ï½œendâ–ofâ–sentenceï½œ>', 'pad_token': '<ï½œendâ–ofâ–sentenceï½œ>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<ï½œendâ–ofâ–sentenceï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<ï½œUserï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151645: AddedToken(\"<ï½œAssistantï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151646: AddedToken(\"<ï½œbeginâ–ofâ–sentenceï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:44.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m374\u001b[0m - \u001b[1mtrain files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:44.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m379\u001b[0m - \u001b[1meval files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
            "Generating train split: 2000 examples [00:00, 17395.09 examples/s]\n",
            "Generating validation split: 2000 examples [00:00, 63873.78 examples/s]\n",
            "\u001b[32m2025-03-18 17:02:45.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m395\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:45.739\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m497\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': 'åšå¹¿å‘Šè€…ã€‚'}, {'from': 'gpt', 'value': 'å½“ç„¶ã€‚ä½œä¸ºå¹¿å‘Šå®¢æˆ·ï¼Œæˆ‘å¦‚ä½•å¸®åŠ©æ‚¨ï¼Ÿæ‚¨å¹¿å‘Šæ´»åŠ¨çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨çš„ç›®æ ‡å—ä¼—æ˜¯ä»€ä¹ˆï¼Ÿè¯·æä¾›æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿä¸ºæ‚¨æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„æ”¯æŒã€‚'}, {'from': 'human', 'value': 'è¯·ä¸ºæˆ‘æ‰¾åˆ°FOMOçš„æ›¿ä»£æ¦‚å¿µï¼Œä»¥ä¾¿æˆ‘å°†å…¶ç”¨ä½œå¹¿å‘Šã€‚\\nä¾‹å¦‚ï¼Œæˆ‘ä¸ºæŸä¸ªå—ä¼—åˆ©ç”¨FOMOæ¥åˆ›é€ ç±»ä¼¼â€œæˆ‘èƒ½æ’é™¤æŸäººå—ï¼Ÿâ€æˆ–â€œæˆ‘èƒ½å˜å¾—æœ‰é˜¶çº§æ„è¯†å—ï¼Ÿâ€ç­‰æ¦‚å¿µã€‚\\næ‚¨éœ€è¦ä¸ºæˆ‘æ‰¾åˆ°FOMOçš„å…¶ä»–æ›¿ä»£æ¦‚å¿µï¼Œè¿™å°†å¯¹æˆ‘åˆ›å»ºå¹¿å‘Šå†…å®¹å¾ˆæœ‰å¸®åŠ©ã€‚'}, {'from': 'gpt', 'value': 'ä»¥ä¸‹æ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µï¼š\\n1. ç´§è¿«æ€§ï¼šåœ¨ä¼˜æƒ æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç´§è¿«æ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¿…é¡»ç«‹åˆ»è¡ŒåŠ¨ï¼Œä»¥å…é”™å¤±æœºä¼šã€‚\\n2. ç‹¬å®¶æ€§ï¼šè®©äººä»¬æ„Ÿåˆ°ä»–ä»¬æ­£åœ¨è´­ä¹°ç‹¬ç‰¹çš„ä¸œè¥¿ï¼Œè€Œè¿™äº›ä¸œè¥¿ä¸æ˜¯æ¯ä¸ªäººéƒ½å¯ä»¥å¾—åˆ°çš„ã€‚\\n3. ç¨€ç¼ºæ€§ï¼šåœ¨ä¿ƒé”€æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç¨€ç¼ºæ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¯ç”¨çš„äº§å“æ•°é‡æœ‰é™ã€‚\\n4. æ–°é²œæ„Ÿï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡æ˜¯æ–°çš„å’Œåˆ›æ–°çš„ï¼Œä»¥åŠå¦‚ä½•ä¸ºäººä»¬çš„ç”Ÿæ´»å¸¦æ¥ç§¯æå˜åŒ–ã€‚\\n5. ç‹¬ç‰¹å¥½å¤„ï¼šçªå‡ºäº§å“æˆ–æœåŠ¡çš„ç‹¬ç‰¹å¥½å¤„ï¼Œä»¥åŠå¦‚ä½•è§£å†³ä½ ç›®æ ‡å—ä¼—çš„ç‰¹å®šé—®é¢˜ã€‚\\nè¿™äº›åªæ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µçš„ä¾‹å­ã€‚é‡è¦çš„æ˜¯ä½ è¦äº†è§£ä½ ç›®æ ‡å—ä¼—å¹¶èƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªä¸ä»–ä»¬å…±é¸£çš„ä¿¡æ¯ã€‚'}, {'from': 'human', 'value': 'Benissimoï¼Œåˆ—å‡ºå…¶ä»–10ä¸ªæ¦‚å¿µã€‚'}, {'from': 'gpt', 'value': 'ä»¥ä¸‹æ˜¯å¦å¤–10ä¸ªå¯ä¾›å¹¿å‘Šæ´»åŠ¨ä½¿ç”¨çš„æ›¿ä»£æ¦‚å¿µï¼š\\n1. ä¾¿åˆ©æ€§ï¼šçªå‡ºäº§å“æˆ–æœåŠ¡å¯ä»¥ä½¿äººä»¬çš„ç”Ÿæ´»æ›´ç®€å•ã€æ›´æ–¹ä¾¿ã€‚\\n2. è´¨é‡ï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡çš„è´¨é‡ï¼Œå¹¶è¯´æ˜å®ƒå¦‚ä½•ä¸ç«äº‰å¯¹æ‰‹ç›¸æ¯”æœ‰æ‰€åŒºåˆ«ã€‚\\n3. æµè¡Œåº¦ï¼šè®©è´­ä¹°è€…æ„Ÿå—åˆ°ä»–ä»¬æ­£åœ¨è´­ä¹°å—æ¬¢è¿çš„ç‰©å“ï¼Œæœ‰å¾ˆå¤šå…¶ä»–äººå·²ç»é€‰æ‹©äº†è¿™ä¸ªäº§å“ã€‚\\n4. èŠ‚çº¦ï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡å¯ä»¥å¸®åŠ©èŠ‚çœé‡‘é’±æˆ–æ—¶é—´ã€‚\\n5. ä¸ªæ€§åŒ–ï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡å¯ä»¥æ ¹æ®äººä»¬çš„å…·ä½“éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–å®šåˆ¶ã€‚\\n6. æ»¡æ„ä¿è¯ï¼šå¼ºè°ƒæ‚¨çš„æ»¡æ„ä¿è¯æ”¿ç­–ï¼Œå¹¶è¯´æ˜è¿™å¯ä»¥ç»™è´­ä¹°è€…å¸¦æ¥å®‰å¿ƒï¼Œå¦‚æœä¸æ»¡æ„å¯ä»¥é€€è´§ã€‚\\n7. æ”¯æŒï¼šå¼ºè°ƒæ‚¨åœ¨é”€å”®å‰åæä¾›çš„æ”¯æŒã€‚\\n8. é€æ˜åº¦ï¼šå¼ºè°ƒæ‚¨çš„é€æ˜åº¦ï¼Œåœ¨æŠ¥ä»·æ–¹é¢è®©äººä»¬æ„Ÿè§‰ä»–ä»¬ç¡®åˆ‡çŸ¥é“è‡ªå·±æ­£åœ¨è´­ä¹°ä»€ä¹ˆã€‚\\n9. è¶‹åŠ¿ï¼šçªæ˜¾äº§å“æˆ–æœåŠ¡ä¸å½“å‰è¶‹åŠ¿ä¿æŒä¸€è‡´ï¼Œå¹¶è¯´æ˜å®ƒå¦‚ä½•æˆä¸ºäººä»¬ç”Ÿæ´»ä¸­çš„æ—¶å°šé™„åŠ å“ã€‚\\n10. ä»·å€¼ï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡çš„ä»·å€¼ï¼Œè¯æ˜è´­ä¹°è€…å¯ä»¥èŠ±è´¹ç›¸åº”çš„ä»·æ ¼è·å¾—å¾ˆå¤šç‰©å“ã€‚\\nè¿™äº›éƒ½æ˜¯å¦å¤–10ä¸ªæ›¿ä»£æ¦‚å¿µï¼Œå¯ä¾›å¹¿å‘Šæ´»åŠ¨ä½¿ç”¨ã€‚å¸Œæœ›è¿™äº›å¯ä»¥ä¸ºä½ æä¾›æ–°çš„çµæ„Ÿï¼Œè®©ä½ æ›´å¥½åœ°åˆ›å»ºä¸‹ä¸€ä¸ªå¹¿å‘Šå†…å®¹ã€‚'}]}\u001b[0m\n",
            "Running tokenizer on dataset: 100% 1000/1000 [00:01<00:00, 701.31 examples/s]\n",
            "Filter: 100% 998/998 [00:00<00:00, 2823.48 examples/s]\n",
            "\u001b[32m2025-03-18 17:02:47.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m514\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 998\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m515\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m516\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "<ï½œbeginâ–ofâ–sentenceï½œ>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: åšå¹¿å‘Šè€…ã€‚ ASSISTANT:å½“ç„¶ã€‚ä½œä¸ºå¹¿å‘Šå®¢æˆ·ï¼Œæˆ‘å¦‚ä½•å¸®åŠ©æ‚¨ï¼Ÿæ‚¨å¹¿å‘Šæ´»åŠ¨çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨çš„ç›®æ ‡å—ä¼—æ˜¯ä»€ä¹ˆï¼Ÿè¯·æä¾›æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿä¸ºæ‚¨æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„æ”¯æŒã€‚<ï½œendâ–ofâ–sentenceï½œ></s>USER: è¯·ä¸ºæˆ‘æ‰¾åˆ°FOMOçš„æ›¿ä»£æ¦‚å¿µï¼Œä»¥ä¾¿æˆ‘å°†å…¶ç”¨ä½œå¹¿å‘Šã€‚\n",
            "ä¾‹å¦‚ï¼Œæˆ‘ä¸ºæŸä¸ªå—ä¼—åˆ©ç”¨FOMOæ¥åˆ›é€ ç±»ä¼¼â€œæˆ‘èƒ½æ’é™¤æŸäººå—ï¼Ÿâ€æˆ–â€œæˆ‘èƒ½å˜å¾—æœ‰é˜¶çº§æ„è¯†å—ï¼Ÿâ€ç­‰æ¦‚å¿µã€‚\n",
            "æ‚¨éœ€è¦ä¸ºæˆ‘æ‰¾åˆ°FOMOçš„å…¶ä»–æ›¿ä»£æ¦‚å¿µï¼Œè¿™å°†å¯¹æˆ‘åˆ›å»ºå¹¿å‘Šå†…å®¹å¾ˆæœ‰å¸®åŠ©ã€‚ ASSISTANT:ä»¥ä¸‹æ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µï¼š\n",
            "1. ç´§è¿«æ€§ï¼šåœ¨ä¼˜æƒ æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç´§è¿«æ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¿…é¡»ç«‹åˆ»è¡ŒåŠ¨ï¼Œä»¥å…é”™å¤±æœºä¼šã€‚\n",
            "2. ç‹¬å®¶æ€§ï¼šè®©äººä»¬æ„Ÿåˆ°ä»–ä»¬æ­£åœ¨è´­ä¹°ç‹¬ç‰¹çš„ä¸œè¥¿ï¼Œè€Œè¿™äº›ä¸œè¥¿ä¸æ˜¯æ¯ä¸ªäººéƒ½å¯ä»¥å¾—åˆ°çš„ã€‚\n",
            "3. ç¨€ç¼ºæ€§ï¼šåœ¨ä¿ƒé”€æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç¨€ç¼ºæ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¯ç”¨çš„äº§å“æ•°é‡æœ‰é™ã€‚\n",
            "4. æ–°é²œæ„Ÿï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡æ˜¯æ–°çš„å’Œåˆ›æ–°çš„ï¼Œä»¥åŠå¦‚ä½•ä¸ºäººä»¬çš„ç”Ÿæ´»å¸¦æ¥ç§¯æå˜åŒ–ã€‚\n",
            "5. ç‹¬ç‰¹å¥½å¤„ï¼šçªå‡ºäº§å“æˆ–æœåŠ¡çš„ç‹¬ç‰¹å¥½å¤„ï¼Œä»¥åŠå¦‚ä½•è§£å†³ä½ ç›®æ ‡å—ä¼—çš„ç‰¹å®šé—®é¢˜ã€‚\n",
            "è¿™äº›åªæ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µçš„ä¾‹å­ã€‚é‡è¦çš„æ˜¯ä½ è¦äº†è§£ä½ ç›®æ ‡å—ä¼—å¹¶èƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªä¸ä»–ä»¬å…±é¸£çš„ä¿¡æ¯ã€‚<ï½œendâ–ofâ–sentenceï½œ>\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m519\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ>å½“ç„¶ã€‚ä½œä¸ºå¹¿å‘Šå®¢æˆ·ï¼Œæˆ‘å¦‚ä½•å¸®åŠ©æ‚¨ï¼Ÿæ‚¨å¹¿å‘Šæ´»åŠ¨çš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿæ‚¨çš„ç›®æ ‡å—ä¼—æ˜¯ä»€ä¹ˆï¼Ÿè¯·æä¾›æ›´å¤šä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿä¸ºæ‚¨æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„æ”¯æŒã€‚<ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ>ä»¥ä¸‹æ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µï¼š\n",
            "1. ç´§è¿«æ€§ï¼šåœ¨ä¼˜æƒ æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç´§è¿«æ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¿…é¡»ç«‹åˆ»è¡ŒåŠ¨ï¼Œä»¥å…é”™å¤±æœºä¼šã€‚\n",
            "2. ç‹¬å®¶æ€§ï¼šè®©äººä»¬æ„Ÿåˆ°ä»–ä»¬æ­£åœ¨è´­ä¹°ç‹¬ç‰¹çš„ä¸œè¥¿ï¼Œè€Œè¿™äº›ä¸œè¥¿ä¸æ˜¯æ¯ä¸ªäººéƒ½å¯ä»¥å¾—åˆ°çš„ã€‚\n",
            "3. ç¨€ç¼ºæ€§ï¼šåœ¨ä¿ƒé”€æ´»åŠ¨å‘¨å›´åˆ›é€ ä¸€ç§ç¨€ç¼ºæ„Ÿï¼Œè®©äººä»¬æ„Ÿåˆ°å¯ç”¨çš„äº§å“æ•°é‡æœ‰é™ã€‚\n",
            "4. æ–°é²œæ„Ÿï¼šå¼ºè°ƒäº§å“æˆ–æœåŠ¡æ˜¯æ–°çš„å’Œåˆ›æ–°çš„ï¼Œä»¥åŠå¦‚ä½•ä¸ºäººä»¬çš„ç”Ÿæ´»å¸¦æ¥ç§¯æå˜åŒ–ã€‚\n",
            "5. ç‹¬ç‰¹å¥½å¤„ï¼šçªå‡ºäº§å“æˆ–æœåŠ¡çš„ç‹¬ç‰¹å¥½å¤„ï¼Œä»¥åŠå¦‚ä½•è§£å†³ä½ ç›®æ ‡å—ä¼—çš„ç‰¹å®šé—®é¢˜ã€‚\n",
            "è¿™äº›åªæ˜¯ä¸€äº›ä½ å¯ä»¥ç”¨äºå¹¿å‘Šæ´»åŠ¨çš„æ›¿ä»£æ¦‚å¿µçš„ä¾‹å­ã€‚é‡è¦çš„æ˜¯ä½ è¦äº†è§£ä½ ç›®æ ‡å—ä¼—å¹¶èƒ½å¤Ÿåˆ›å»ºä¸€ä¸ªä¸ä»–ä»¬å…±é¸£çš„ä¿¡æ¯ã€‚<ï½œendâ–ofâ–sentenceï½œ>\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.645\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.645\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m537\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': 'æ²»ç–—é˜³ç—¿åƒä»€ä¹ˆè¯å‘¢ï¼Ÿï¼Œæ€§ç”Ÿæ´»ä¸€ç›´å¾ˆæ­£å¸¸çš„ï¼Œä½†æ˜¯è¿™æ®µæ—¶é—´æ„Ÿè§‰æ€§æ¬²å˜ä½äº†ï¼Œæœ‰æ—¶å‹ƒèµ·éƒ½æ„Ÿè§‰å¾ˆå›°éš¾ï¼Œè¯•è¿‡è®¸å¤šçš„æ–¹æ³•éƒ½æ²¡æ•ˆæœï¼Œå¬æœ‹å‹è¯´æˆ‘è¿™ç§æƒ…å†µå¯èƒ½ä¼šæ˜¯æ—©æ³„ï¼Œæƒ³çŸ¥é“æ²»ç–—æ—©æ³„çš„è¯ç‰©ï¼Ÿ'}, {'from': 'gpt', 'value': 'ç”·å­æ—©æ³„ã€æ—©æ³„ç—…ç—‡çš„å†æ¬¡å‘ç”Ÿï¼Œå¤šç”±æ£æƒ…çºµæ¬²ï¼Œæˆ–é’å¹´è¯¯çŠ¯æ€§äº¤ï¼Œè‡³å‘½é—¨ç«è¡°ï¼Œç²¾æ°”è™šå¯’ï¼›æˆ–æ€é‡å¿§éƒï¼Œä¼¤æŸå¿ƒè„¾ï¼›æˆ–å› ææƒ§ä¼¤è‚¾ï¼Œä¹Ÿæœ‰å› æ¹¿çƒ­ä¸‹æ³¨ï¼Œå®—ç­‹å¼›è€Œç—¿çš„ã€‚ä½†ä¸»è¦æ˜¯è‚¾é˜³è™šè¡°è€Œç—¿ã€‚è‚¾é˜³ä¸ºé‚£èº«é˜³æ°”ä¹‹æ ¹æœ¬ï¼Œæœ‰æ¸©ç…¦å½¢ä½“ï¼Œè’¸åŒ–æ°´æ¶²ï¼Œå¢è¿›å›´äº§ç”Ÿé•¿å‘è‚²ç­‰åŠŸèƒ½ã€‚è‚¾é˜³è™šè¡°åˆ™æ¸©ç…¦å¤±è´£ï¼Œæ°”åŒ–æ— æƒã€‚å› è€Œå†æ¬¡å‘ç”Ÿç•å¯’è‚¢å†·ï¼Œæ€§æœºèƒ½å‡é€€ã€‚æ•…è§ç”·å­æ—©æ³„ä¸ä¸¾æˆ–ä¸åšï¼Œä¸”ä¼´å‘å¤´æ™•ç›®çœ©ã€‚'}]}\u001b[0m\n",
            "Running tokenizer on validation dataset: 100% 10/10 [00:00<00:00, 698.12 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 1990.27 examples/s]\n",
            "\u001b[32m2025-03-18 17:02:47.796\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m547\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.796\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m548\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 17:02:47.798\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m549\u001b[0m - \u001b[34m\u001b[1m<ï½œbeginâ–ofâ–sentenceï½œ>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: æ²»ç–—é˜³ç—¿åƒä»€ä¹ˆè¯å‘¢ï¼Ÿï¼Œæ€§ç”Ÿæ´»ä¸€ç›´å¾ˆæ­£å¸¸çš„ï¼Œä½†æ˜¯è¿™æ®µæ—¶é—´æ„Ÿè§‰æ€§æ¬²å˜ä½äº†ï¼Œæœ‰æ—¶å‹ƒèµ·éƒ½æ„Ÿè§‰å¾ˆå›°éš¾ï¼Œè¯•è¿‡è®¸å¤šçš„æ–¹æ³•éƒ½æ²¡æ•ˆæœï¼Œå¬æœ‹å‹è¯´æˆ‘è¿™ç§æƒ…å†µå¯èƒ½ä¼šæ˜¯æ—©æ³„ï¼Œæƒ³çŸ¥é“æ²»ç–—æ—©æ³„çš„è¯ç‰©ï¼Ÿ ASSISTANT:ç”·å­æ—©æ³„ã€æ—©æ³„ç—…ç—‡çš„å†æ¬¡å‘ç”Ÿï¼Œå¤šç”±æ£æƒ…çºµæ¬²ï¼Œæˆ–é’å¹´è¯¯çŠ¯æ€§äº¤ï¼Œè‡³å‘½é—¨ç«è¡°ï¼Œç²¾æ°”è™šå¯’ï¼›æˆ–æ€é‡å¿§éƒï¼Œä¼¤æŸå¿ƒè„¾ï¼›æˆ–å› ææƒ§ä¼¤è‚¾ï¼Œä¹Ÿæœ‰å› æ¹¿çƒ­ä¸‹æ³¨ï¼Œå®—ç­‹å¼›è€Œç—¿çš„ã€‚ä½†ä¸»è¦æ˜¯è‚¾é˜³è™šè¡°è€Œç—¿ã€‚è‚¾é˜³ä¸ºé‚£èº«é˜³æ°”ä¹‹æ ¹æœ¬ï¼Œæœ‰æ¸©ç…¦å½¢ä½“ï¼Œè’¸åŒ–æ°´æ¶²ï¼Œå¢è¿›å›´äº§ç”Ÿé•¿å‘è‚²ç­‰åŠŸèƒ½ã€‚è‚¾é˜³è™šè¡°åˆ™æ¸©ç…¦å¤±è´£ï¼Œæ°”åŒ–æ— æƒã€‚å› è€Œå†æ¬¡å‘ç”Ÿç•å¯’è‚¢å†·ï¼Œæ€§æœºèƒ½å‡é€€ã€‚æ•…è§ç”·å­æ—©æ³„ä¸ä¸¾æˆ–ä¸åšï¼Œä¸”ä¼´å‘å¤´æ™•ç›®çœ©ã€‚<ï½œendâ–ofâ–sentenceï½œ>\u001b[0m\n",
            "config.json: 100% 679/679 [00:00<00:00, 4.79MB/s]\n",
            "model.safetensors: 100% 3.55G/3.55G [00:23<00:00, 151MB/s]\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "generation_config.json: 100% 181/181 [00:00<00:00, 1.11MB/s]\n",
            "\u001b[32m2025-03-18 17:03:17.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m688\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:17.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m703\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:17.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m712\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:17.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m713\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 9,232,384 || all params: 1,786,320,384 || trainable%: 0.5168\n",
            "\u001b[32m2025-03-18 17:03:18.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m735\u001b[0m - \u001b[1mGradient checkpointing enabled.\u001b[0m\n",
            "/content/MedicalGPT/supervised_finetuning.py:752: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 17:03:18.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:18.115\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m766\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[151643, 151643, 151643,  ..., 101953, 101899, 151643],\n",
            "        [151646,     32,   6236,  ...,  99898,   1773, 151643],\n",
            "        [151643, 151643, 151643,  ..., 100166,   1773, 151643],\n",
            "        [151643, 151643, 151643,  ..., 110162,  49567, 151643]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0'), 'labels': tensor([[  -100,   -100,   -100,  ..., 101953, 101899, 151643],\n",
            "        [  -100,   -100,   -100,  ...,  99898,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ..., 100166,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ..., 110162,  49567, 151643]],\n",
            "       device='cuda:0')}\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:18.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m767\u001b[0m - \u001b[34m\u001b[1minput_ids:\n",
            "[tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151646,     32,   6236,   1948,    264,  22208,   1196,    323,    458,\n",
            "         20443,  11229,  17847,     13,    576,  17847,   6696,  10950,     11,\n",
            "         11682,     11,    323,  47787,  11253,    311,    279,   1196,    594,\n",
            "          4755,   3918,     82,     29,   6448,     25,  18137,    103,    101,\n",
            "         32108,  33071,  99180,  35551,  45356,  99180,  35551,  99252,   9370,\n",
            "        104650, 101899, 101895,  99245,  11319,  35560,   3846,   2821,     25,\n",
            "         32664,  99769, 100143,  54542,  24968, 120412,  99180, 101953, 101899,\n",
            "        151643], device='cuda:0'), tensor([151646,     32,   6236,   1948,    264,  22208,   1196,    323,    458,\n",
            "         20443,  11229,  17847,     13,    576,  17847,   6696,  10950,     11,\n",
            "         11682,     11,    323,  47787,  11253,    311,    279,   1196,    594,\n",
            "          4755,   3918,     82,     29,   6448,     25,    220, 107809,  11622,\n",
            "         25411,  40814, 101454,  24339, 112672, 100625,  28404,  99678,   9370,\n",
            "        114091, 101037,  11319,  35560,   3846,   2821,     25, 103942,  73670,\n",
            "             0,  32181,    247,  20412, 100625,  28404,  99678,  26940,  77419,\n",
            "         38989,  99858,  25067,   9370, 114091,   3837,  59879,  19360,  51461,\n",
            "           229,  40814,  51463,  48443,  73594,  12669,    198,     55,     25,\n",
            "            16,    198,     51,  74045,   7679,   6222,     79,  38940,  39614,\n",
            "           198,     44,     25,     19,     14,     19,    198,     43,     25,\n",
            "            16,     14,     19,    198,     42,  69856,    198,     48,     25,\n",
            "            16,     14,     19,     28,     16,     17,     15,    198,     89,\n",
            "            17,    760,    434,     17,    434,     17,    362,     17,    272,\n",
            "            17,    760,    272,     17,    272,     17,    425,     17,    362,\n",
            "            17,    760,    479,     17,    479,     17,    479,     17,    362,\n",
            "            17,    760,    425,     17,    425,     17,    425,     17,   1147,\n",
            "            17,   9248,     66,      6,     17,    272,      6,     17,    294,\n",
            "             6,     17,    384,      6,     17,    760,    282,      6,     17,\n",
            "           282,      6,     17,    384,      6,     17,    294,      6,     17,\n",
            "           760,    272,      6,     17,    272,      6,     17,    425,     17,\n",
            "           362,     17,    760,    479,     17,    479,     17,    479,     17,\n",
            "          1147,     17,   9248,     89,     17,    760,    272,     17,    272,\n",
            "            17,    294,     17,    384,     17,    760,    282,     17,    282,\n",
            "            17,    384,     17,    294,     17,    760,    272,     17,    272,\n",
            "            17,    425,     17,    362,     17,    760,    479,     17,    479,\n",
            "            17,    479,     17,   1147,     17,   9248,     89,     17,    760,\n",
            "           434,     17,    434,     17,    362,     17,    272,     17,    760,\n",
            "           272,     17,    272,     17,    425,     17,    362,     17,    760,\n",
            "           479,     17,    479,     17,    479,     17,    362,     17,    760,\n",
            "           425,     17,    425,     17,    425,     17,   1147,     17,   9248,\n",
            "            66,      6,     17,    272,      6,     17,    294,      6,     17,\n",
            "           384,      6,     17,    760,    282,      6,     17,    282,      6,\n",
            "            17,    384,     17,    294,     17,    760,    272,      6,     17,\n",
            "           272,      6,     17,    425,     17,    362,     17,    760,    479,\n",
            "            17,    479,     17,    479,     17,   1147,     17,   9248,  13874,\n",
            "         19324, 100137,  40814, 101454,  24339, 116984,  44063, 114091,  31196,\n",
            "         26939, 100646, 103951,  74220,  15946,   3837, 101912,  99350, 101454,\n",
            "        103951,  57191, 106726,  31548,   3837, 105920, 114091,  73670,  18397,\n",
            "         53222,  57191,  23031, 101454,  20742, 100414, 102703,  99898,   1773,\n",
            "        151643], device='cuda:0'), tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151646,     32,   6236,   1948,    264,  22208,   1196,    323,    458,\n",
            "         20443,  11229,  17847,     13,    576,  17847,   6696,  10950,     11,\n",
            "         11682,     11,    323,  47787,  11253,    311,    279,   1196,    594,\n",
            "          4755,   3918,     82,     29,   6448,     25,  69372,  98749,  98237,\n",
            "         30534, 106637,  35560,   3846,   2821,     25, 106637, 101158, 101042,\n",
            "        108872,  51575, 105080,   3837, 102215,  99795, 102064,   5373, 104564,\n",
            "        102064,  99998,  20074, 100166,   3837,  71268, 101137, 100414,  72881,\n",
            "        102648,  46448,   1773, 106637, 104820,  20412,  60610,  31196,   9370,\n",
            "        100166,   3837, 102119,  17714,  99794,  68862,  31196,  57191,  99553,\n",
            "        102988, 109963,  66017,   8997, 106637,  66558, 118619,  75768,   3837,\n",
            "        100398,  37029, 104339, 108747,  96555, 106637, 106708, 102064,  33108,\n",
            "        109988,  66017,   1773, 101883, 102716, 106637,  99361, 100630,    510,\n",
            "             9,  61991,  99743, 111228, 106637,     25,    220,  75882,  39907,\n",
            "         45181,  31196,   9370, 102198, 100166,  55286,   3837, 104137, 101042,\n",
            "        103991, 108872,   8997,      9,  61991,  99413, 105798, 106637,     25,\n",
            "           220,  75882,  39907,  45181, 106506, 108872,  55286,   3837, 105798,\n",
            "        101042, 101908,  31196, 100166,   8997,      9,    220, 100520, 100040,\n",
            "        102008, 106637,     25,  32181,    247,  86402,  39907,  37029, 108940,\n",
            "        100520, 100040,  32804,  36407, 101042,  31196,   9370, 100166,   1773,\n",
            "        151643], device='cuda:0')], \n",
            "labels:\n",
            "[tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "         32664,  99769, 100143,  54542,  24968, 120412,  99180, 101953, 101899,\n",
            "        151643], device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100, 103942,  73670,\n",
            "             0,  32181,    247,  20412, 100625,  28404,  99678,  26940,  77419,\n",
            "         38989,  99858,  25067,   9370, 114091,   3837,  59879,  19360,  51461,\n",
            "           229,  40814,  51463,  48443,  73594,  12669,    198,     55,     25,\n",
            "            16,    198,     51,  74045,   7679,   6222,     79,  38940,  39614,\n",
            "           198,     44,     25,     19,     14,     19,    198,     43,     25,\n",
            "            16,     14,     19,    198,     42,  69856,    198,     48,     25,\n",
            "            16,     14,     19,     28,     16,     17,     15,    198,     89,\n",
            "            17,    760,    434,     17,    434,     17,    362,     17,    272,\n",
            "            17,    760,    272,     17,    272,     17,    425,     17,    362,\n",
            "            17,    760,    479,     17,    479,     17,    479,     17,    362,\n",
            "            17,    760,    425,     17,    425,     17,    425,     17,   1147,\n",
            "            17,   9248,     66,      6,     17,    272,      6,     17,    294,\n",
            "             6,     17,    384,      6,     17,    760,    282,      6,     17,\n",
            "           282,      6,     17,    384,      6,     17,    294,      6,     17,\n",
            "           760,    272,      6,     17,    272,      6,     17,    425,     17,\n",
            "           362,     17,    760,    479,     17,    479,     17,    479,     17,\n",
            "          1147,     17,   9248,     89,     17,    760,    272,     17,    272,\n",
            "            17,    294,     17,    384,     17,    760,    282,     17,    282,\n",
            "            17,    384,     17,    294,     17,    760,    272,     17,    272,\n",
            "            17,    425,     17,    362,     17,    760,    479,     17,    479,\n",
            "            17,    479,     17,   1147,     17,   9248,     89,     17,    760,\n",
            "           434,     17,    434,     17,    362,     17,    272,     17,    760,\n",
            "           272,     17,    272,     17,    425,     17,    362,     17,    760,\n",
            "           479,     17,    479,     17,    479,     17,    362,     17,    760,\n",
            "           425,     17,    425,     17,    425,     17,   1147,     17,   9248,\n",
            "            66,      6,     17,    272,      6,     17,    294,      6,     17,\n",
            "           384,      6,     17,    760,    282,      6,     17,    282,      6,\n",
            "            17,    384,     17,    294,     17,    760,    272,      6,     17,\n",
            "           272,      6,     17,    425,     17,    362,     17,    760,    479,\n",
            "            17,    479,     17,    479,     17,   1147,     17,   9248,  13874,\n",
            "         19324, 100137,  40814, 101454,  24339, 116984,  44063, 114091,  31196,\n",
            "         26939, 100646, 103951,  74220,  15946,   3837, 101912,  99350, 101454,\n",
            "        103951,  57191, 106726,  31548,   3837, 105920, 114091,  73670,  18397,\n",
            "         53222,  57191,  23031, 101454,  20742, 100414, 102703,  99898,   1773,\n",
            "        151643], device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100, 106637, 101158, 101042,\n",
            "        108872,  51575, 105080,   3837, 102215,  99795, 102064,   5373, 104564,\n",
            "        102064,  99998,  20074, 100166,   3837,  71268, 101137, 100414,  72881,\n",
            "        102648,  46448,   1773, 106637, 104820,  20412,  60610,  31196,   9370,\n",
            "        100166,   3837, 102119,  17714,  99794,  68862,  31196,  57191,  99553,\n",
            "        102988, 109963,  66017,   8997, 106637,  66558, 118619,  75768,   3837,\n",
            "        100398,  37029, 104339, 108747,  96555, 106637, 106708, 102064,  33108,\n",
            "        109988,  66017,   1773, 101883, 102716, 106637,  99361, 100630,    510,\n",
            "             9,  61991,  99743, 111228, 106637,     25,    220,  75882,  39907,\n",
            "         45181,  31196,   9370, 102198, 100166,  55286,   3837, 104137, 101042,\n",
            "        103991, 108872,   8997,      9,  61991,  99413, 105798, 106637,     25,\n",
            "           220,  75882,  39907,  45181, 106506, 108872,  55286,   3837, 105798,\n",
            "        101042, 101908,  31196, 100166,   8997,      9,    220, 100520, 100040,\n",
            "        102008, 106637,     25,  32181,    247,  86402,  39907,  37029, 108940,\n",
            "        100520, 100040,  32804,  36407, 101042,  31196,   9370, 100166,   1773,\n",
            "        151643], device='cuda:0')]\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:18.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m768\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "<ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œbeginâ–ofâ–sentenceï½œ>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: éª¨åŒ–æ€§æ°”ç®¡æ”¯æ°”ç®¡ç—…çš„è¾…åŠ©æ²»ç–—æœ‰äº›ä»€ä¹ˆï¼Ÿ ASSISTANT:å¯¹ç—‡æ”¯æŒå¤„ç†ï¼›æ°©æ°”åˆ€æ²»ç–—<ï½œendâ–ofâ–sentenceï½œ>\u001b[0m\n",
            "\u001b[32m2025-03-18 17:03:18.326\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m771\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ><ï½œendâ–ofâ–sentenceï½œ>å¯¹ç—‡æ”¯æŒå¤„ç†ï¼›æ°©æ°”åˆ€æ²»ç–—<ï½œendâ–ofâ–sentenceï½œ>\u001b[0m\n",
            "{'loss': 3.4022, 'grad_norm': 0.8456529378890991, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.0}\n",
            "{'loss': 3.3647, 'grad_norm': 0.4965590536594391, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.04}\n",
            "{'loss': 3.6234, 'grad_norm': 1.090477705001831, 'learning_rate': 1.9409282700421944e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3364, 'grad_norm': 0.6400810480117798, 'learning_rate': 1.856540084388186e-05, 'epoch': 0.12}\n",
            "{'loss': 3.1573, 'grad_norm': 0.8033381700515747, 'learning_rate': 1.7721518987341772e-05, 'epoch': 0.16}\n",
            "{'loss': 3.3715, 'grad_norm': 0.7424730658531189, 'learning_rate': 1.687763713080169e-05, 'epoch': 0.2}\n",
            " 20% 50/250 [06:18<28:59,  8.70s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.19s/it]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 4.567862510681152, 'eval_runtime': 6.0488, 'eval_samples_per_second': 1.653, 'eval_steps_per_second': 0.496, 'epoch': 0.2}\n",
            " 20% 50/250 [06:24<28:59,  8.70s/it]\n",
            "100% 3/3 [00:05<00:00,  1.60s/it]\u001b[A\n",
            "{'loss': 3.576, 'grad_norm': 0.8863565325737, 'learning_rate': 1.6033755274261603e-05, 'epoch': 0.24}\n",
            "{'loss': 3.4554, 'grad_norm': 0.7189267873764038, 'learning_rate': 1.5189873417721521e-05, 'epoch': 0.28}\n",
            "{'loss': 3.198, 'grad_norm': 0.6507024168968201, 'learning_rate': 1.4345991561181437e-05, 'epoch': 0.32}\n",
            "{'loss': 2.9968, 'grad_norm': 0.7932102680206299, 'learning_rate': 1.350210970464135e-05, 'epoch': 0.36}\n",
            "{'loss': 3.0513, 'grad_norm': 0.7772051095962524, 'learning_rate': 1.2658227848101268e-05, 'epoch': 0.4}\n",
            " 40% 100/250 [13:06<21:04,  8.43s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.19s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 4.360468864440918, 'eval_runtime': 6.0456, 'eval_samples_per_second': 1.654, 'eval_steps_per_second': 0.496, 'epoch': 0.4}\n",
            " 40% 100/250 [13:12<21:04,  8.43s/it]\n",
            "100% 3/3 [00:05<00:00,  1.59s/it]\u001b[A\n",
            "{'loss': 3.0608, 'grad_norm': 1.256365180015564, 'learning_rate': 1.1814345991561182e-05, 'epoch': 0.44}\n",
            "{'loss': 3.1507, 'grad_norm': 0.8239213228225708, 'learning_rate': 1.0970464135021096e-05, 'epoch': 0.48}\n",
            "{'loss': 2.7946, 'grad_norm': 1.105361819267273, 'learning_rate': 1.0126582278481014e-05, 'epoch': 0.52}\n",
            "{'loss': 2.9203, 'grad_norm': 0.9101645350456238, 'learning_rate': 9.28270042194093e-06, 'epoch': 0.56}\n",
            "{'loss': 2.859, 'grad_norm': 0.7477586269378662, 'learning_rate': 8.438818565400846e-06, 'epoch': 0.6}\n",
            " 60% 150/250 [19:38<11:45,  7.05s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.20s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 4.3128342628479, 'eval_runtime': 6.1072, 'eval_samples_per_second': 1.637, 'eval_steps_per_second': 0.491, 'epoch': 0.6}\n",
            " 60% 150/250 [19:44<11:45,  7.05s/it]\n",
            "100% 3/3 [00:05<00:00,  1.61s/it]\u001b[A\n",
            "{'loss': 3.0153, 'grad_norm': 0.7254159450531006, 'learning_rate': 7.5949367088607605e-06, 'epoch': 0.64}\n",
            "{'loss': 2.8323, 'grad_norm': 0.6179220676422119, 'learning_rate': 6.751054852320675e-06, 'epoch': 0.68}\n",
            "{'loss': 3.0397, 'grad_norm': 0.6511217951774597, 'learning_rate': 5.907172995780591e-06, 'epoch': 0.72}\n",
            "{'loss': 2.8137, 'grad_norm': 0.5921759009361267, 'learning_rate': 5.063291139240507e-06, 'epoch': 0.76}\n",
            "{'loss': 3.0348, 'grad_norm': 0.7604183554649353, 'learning_rate': 4.219409282700423e-06, 'epoch': 0.8}\n",
            " 80% 200/250 [26:35<06:50,  8.21s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.20s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 4.299993991851807, 'eval_runtime': 6.1167, 'eval_samples_per_second': 1.635, 'eval_steps_per_second': 0.49, 'epoch': 0.8}\n",
            " 80% 200/250 [26:41<06:50,  8.21s/it]\n",
            "100% 3/3 [00:05<00:00,  1.61s/it]\u001b[A\n",
            "{'loss': 3.0196, 'grad_norm': 0.8959814310073853, 'learning_rate': 3.3755274261603377e-06, 'epoch': 0.84}\n",
            "{'loss': 3.1594, 'grad_norm': 0.7522596120834351, 'learning_rate': 2.5316455696202535e-06, 'epoch': 0.88}\n",
            "{'loss': 3.4042, 'grad_norm': 1.1143990755081177, 'learning_rate': 1.6877637130801689e-06, 'epoch': 0.92}\n",
            "{'loss': 2.9799, 'grad_norm': 0.6875190734863281, 'learning_rate': 8.438818565400844e-07, 'epoch': 0.96}\n",
            "{'loss': 3.1811, 'grad_norm': 0.863736093044281, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "100% 250/250 [33:23<00:00,  6.80s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:02<00:01,  1.21s/it]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 4.295854568481445, 'eval_runtime': 6.1196, 'eval_samples_per_second': 1.634, 'eval_steps_per_second': 0.49, 'epoch': 1.0}\n",
            "100% 250/250 [33:29<00:00,  6.80s/it]\n",
            "100% 3/3 [00:05<00:00,  1.61s/it]\u001b[A\n",
            "{'train_runtime': 2010.7881, 'train_samples_per_second': 0.496, 'train_steps_per_second': 0.124, 'train_loss': 3.136001777648926, 'epoch': 1.0}\n",
            "100% 250/250 [33:30<00:00,  8.04s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =  3760509GF\n",
            "  train_loss               =      3.136\n",
            "  train_runtime            = 0:33:30.78\n",
            "  train_samples            =       1000\n",
            "  train_samples_per_second =      0.496\n",
            "  train_steps_per_second   =      0.124\n",
            "\u001b[32m2025-03-18 17:36:49.643\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m788\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 2010.7881, 'train_samples_per_second': 0.496, 'train_steps_per_second': 0.124, 'total_flos': 4037816683468800.0, 'train_loss': 3.136001777648926, 'epoch': 1.0, 'train_samples': 1000}\u001b[0m\n",
            "\u001b[32m2025-03-18 17:36:49.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m789\u001b[0m - \u001b[1mSaving model checkpoint to outputs-sft-v1\u001b[0m\n",
            "\u001b[32m2025-03-18 17:36:50.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m798\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 3/3 [00:05<00:00,  1.74s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     4.2959\n",
            "  eval_runtime            = 0:00:06.09\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      1.639\n",
            "  eval_steps_per_second   =      0.492\n",
            "  perplexity              =    73.3949\n",
            "\u001b[32m2025-03-18 17:36:56.616\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m811\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 4.295854568481445, 'eval_runtime': 6.0996, 'eval_samples_per_second': 1.639, 'eval_steps_per_second': 0.492, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 73.39490862858457}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python supervised_finetuning.py \\\n",
        "    --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --output_dir outputs-sft-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tJaxba8rAIb5",
        "outputId": "7c7d51e7-87d4-49a5-d3d0-a580122b70de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 47M\n",
            "-rw-r--r-- 1 root root  816 Mar 18 17:36 adapter_config.json\n",
            "-rw-r--r-- 1 root root  36M Mar 18 17:36 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  429 Mar 18 17:36 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar 18 17:36 \u001b[0m\u001b[01;34mcheckpoint-250\u001b[0m/\n",
            "-rw-r--r-- 1 root root  219 Mar 18 17:36 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar 18 17:36 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Mar 18 17:03 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  485 Mar 18 17:36 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 17:36 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 17:36 tokenizer.json\n",
            "-rw-r--r-- 1 root root 6.0K Mar 18 17:36 trainer_state.json\n",
            "-rw-r--r-- 1 root root  230 Mar 18 17:36 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-sft-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UkFRtFLDAIb5"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.safetensors`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5dQgkBu4AIb5"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "7_HCeoqlglUb",
        "outputId": "a0a4f5b9-006c-497e-fa3b-cd1245716a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z-DKleNSAIb5",
        "outputId": "e45f9832-6d29-4ad9-8052-42d8800cc1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 18:31:15.436851: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742322675.464861   37002 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742322675.473490   37002 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 18:31:15.507627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', tokenizer_path=None, lora_model='outputs-sft-v1', resize_emb=False, output_dir='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
            "LoRA model: outputs-sft-v1\n",
            "Loading LoRA for causal language model\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B --lora_model outputs-sft-v1 --output_dir deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N2dpHHLiAIb6",
        "outputId": "9cc6e211-02a3-4fbc-a7bf-2047013eba90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 3.4G\n",
            "-rw-r--r-- 1 root root  767 Mar 18 18:31 config.json\n",
            "-rw-r--r-- 1 root root  181 Mar 18 18:31 generation_config.json\n",
            "-rw-r--r-- 1 root root 3.4G Mar 18 18:32 model.safetensors\n",
            "-rw-r--r-- 1 root root  485 Mar 18 18:31 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 18:31 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 18:31 tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OEoyRZGrAIb6",
        "outputId": "ba0b8c5d-958c-4d24-b31d-f612860c81aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"_name_or_path\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 131072,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 10000,\n",
            "  \"sliding_window\": 4096,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.49.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fPQGEaWyAIb6"
      },
      "source": [
        "Stage2 SFTè®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:07:40.752635Z",
          "start_time": "2023-06-15T14:07:40.731186Z"
        },
        "id": "i0cZvYIgAIb6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jYG0irUFAIb6"
      },
      "source": [
        "# Stage 3: Reward Modeling\n",
        "\n",
        "ç¬¬ä¸‰é˜¶æ®µï¼šRM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡ï¼Œæ„é€ äººç±»åå¥½æ’åºæ•°æ®é›†ï¼Œè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç”¨æ¥å¯¹é½äººç±»åå¥½ï¼Œä¸»è¦æ˜¯\"HHH\"åŸåˆ™ï¼Œå…·ä½“æ˜¯\"helpful, honest, harmless\"\n",
        "\n",
        "| Stage 3: Reward Modeling        |  [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py) | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "G5UJsUAEAIb7"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Qwen/Qwen2.5-0.5B æˆ–è€… Stage2å¾—åˆ°çš„SFTæ¨¡å‹\n",
        "2. æ•°æ®é›†ï¼šRMé˜¶æ®µä½¿ç”¨çš„æ˜¯åŒ»ç–—rewardæ•°æ®ï¼ŒæŠ½æ ·äº†500æ¡ï¼Œä½äº`data/reward`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MWD-cEtWAIb7"
      },
      "source": [
        "## Stage3 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½æ¨¡å‹å’Œtokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "B32MUuDyAIb7",
        "outputId": "da5b3528-1453-4e82-f2dd-450cb4d7e6f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dpo_zh_500.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/reward/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "id": "byDbV_YiAIb7",
        "outputId": "09b174ed-872c-44b1-9218-ecea55dc90e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-18 18:46:59.548155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742323619.571089   41207 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742323619.577934   41207 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 18:46:59.601777: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[32m2025-03-18 18:47:03.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', tokenizer_name_or_path=None, load_in_4bit=False, load_in_8bit=False, cache_dir=None, use_fast_tokenizer=False, torch_dtype='float32', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:03.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward', validation_file_dir='./data/reward', max_source_length=256, max_target_length=256, max_train_samples=1000, max_eval_samples=10, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4)\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:03.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1mTraining args: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-rm-v1/runs/Mar18_18-47-03_5e53693f8c97,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-rm-v1,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=outputs-rm-v1,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.001,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:03.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:03.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2025-03-18 18:47:09.773\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m398\u001b[0m - \u001b[34m\u001b[1mTokenizer: LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<ï½œbeginâ–ofâ–sentenceï½œ>', 'eos_token': '<ï½œendâ–ofâ–sentenceï½œ>', 'pad_token': '<ï½œendâ–ofâ–sentenceï½œ>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<ï½œendâ–ofâ–sentenceï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<ï½œUserï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151645: AddedToken(\"<ï½œAssistantï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151646: AddedToken(\"<ï½œbeginâ–ofâ–sentenceï½œ>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:09.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:09.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m406\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:09.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m415\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:09.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m416\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 9,233,920 || all params: 1,552,949,760 || trainable%: 0.5946\n",
            "\u001b[32m2025-03-18 18:47:10.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m459\u001b[0m - \u001b[1mtrain files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1meval files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.786\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'system': '', 'history': [], 'question': '20ä¸ªå…³äºæ–°é²œæœæ±èœå•çš„å£å·ï¼Œé€‚ç”¨äºä¸€å®¶åä¸º\"Dishes\"çš„é¤å…', 'response_chosen': 'è¿™é‡Œæ˜¯ä¸€ä¸ªåä¸ºâ€œDishesâ€çš„é¤å…çš„20ä¸ªå£å·ï¼Œçªå‡ºäº†å…¶æ–°é²œæœæ±èœå•ï¼š\\n\\n1. â€œå“å°Dishesæ–°é²œæœæ±ï¼Œæ„Ÿå—ä¸åŒï¼â€\\n2. â€œæ–°é²œæ¦¨å–ï¼Œç›´è¾¾æ‚¨çš„é¤æ¡Œ - Dishesæœæ±çº¯äº«ï¼â€\\n3. â€œç”¨ä¸€æ¯æ¸…æ–°çš„Dishesæœæ±å¼€å¯æ‚¨çš„ä¸€å¤©ï¼â€\\n4. â€œæ¯ä¸€å£Dishesæ–°é²œæœæ±éƒ½æ˜¯å¤§è‡ªç„¶çš„å‘³é“ï¼â€\\n5. â€œDishesï¼šæ–°é²œæœæ±æ˜¯ç„¦ç‚¹ï¼â€\\n6. â€œæ»¡è¶³æ‚¨çš„å£è…¹ä¹‹æ¬²ï¼Œäº«ç”¨Disheså£æ°´ç›´æµçš„å†œåœºæœæ±ï¼â€\\n7. â€œæ–°é²œæœæ±ï¼Œæ–°é²œå‘³é“ï¼Œæ–°é²œèœè‚´ - è¿™æ˜¯Dishesçš„æ‰¿è¯ºï¼â€\\n8. â€œç”¨Dishesè¥å…»æœæ±è·å¾—æ¯æ—¥æ‰€éœ€çš„ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨ï¼â€\\n9. â€œè§£æ¸´æ»‹å…»å¿ƒçµï¼Œå“å°Dishesç¾å‘³æœæ±ï¼â€\\n10. â€œDishesï¼šæ¯ä¸€å£éƒ½æ˜¯å®Œç¾çš„å‘³é“ï¼â€\\n11. â€œæ–°é²œåˆ¶ä½œï¼Œå®Œç¾å¹³è¡¡ - Dishesæœæ±æ˜¯æ„Ÿå®˜çš„äº«å—ï¼â€\\n12. â€œä»å†œåœºåˆ°é¤æ¡Œï¼ŒDishesæœæ±å……æ»¡å¤©ç„¶å¥½å¤„ï¼â€\\n13. â€œè¸å…¥Dishesï¼Œå“å°æˆ‘ä»¬æ–°é²œæœæ±çš„ç”œèœœï¼â€\\n14. â€œç”¨Dishes 100%æ–°é²œæ°´æœæœæ±å‘µæŠ¤æ‚¨çš„èº«ä½“ï¼â€\\n15. â€œDishesï¼šæ¯ä¸€æ¯æœæ±éƒ½æ˜¯ç”¨æ¿€æƒ…å’Œå…³æ€€ç²¾å¿ƒåˆ¶ä½œï¼â€\\n16. â€œæ²‰é†‰äºDishesæ–°é²œæ¦¨å–æœæ±çš„å¥åº·çƒ­æƒ…ï¼â€\\n17. â€œç”¨Dishesæ‹›ç‰Œæœæ±æ··åˆç‰©æå‡æ‚¨çš„ç”¨é¤ä½“éªŒï¼â€\\n18. â€œå¥åº·é¥®å“çš„æ¸…æ–°è½¬å˜ - Dishesæœæ±å¿…å°ï¼â€\\n19. â€œåŠ å…¥Dishesçš„æ–°é²œæœæ±é©å‘½ - æ‚¨çš„å‘³è•¾ä¼šæ„Ÿæ¿€æ‚¨ï¼â€\\n20. â€œDishesï¼šæœæ±æ°¸è¿œæ–°é²œï¼Œå‘³é“æ°¸è¿œç¾å‘³ï¼â€', 'response_rejected': '1. \"ä¸èœè‚´ä¸€èµ·å“å°æ–°é²œï¼\"\\n2. \"èœè‚´ï¼šæ–°é²œæœæ±ï¼Œæ–°çš„å¼€å§‹ï¼\"\\n3. \"ç”¨èœè‚´çš„æ–°é²œæ··åˆæœæ±æç¥ï¼\"\\n4. \"èœè‚´ï¼Œæ–°é²œå°±æ˜¯æœ€å¥½çš„\"\\n5. \"åœ¨èœè‚´åº†ç¥æ–°é²œ\"\\n6. \"ä¸èœè‚´çš„æ–°é²œæœæ±ä¸ºå¥åº·å¹²æ¯\"\\n7. \"åœ¨èœè‚´å‘ç°æ–°é²œçš„é­”åŠ›\"\\n8. \"å“å°èœè‚´çš„æ–°é²œæœæ±ï¼Œæ„Ÿå—ä¸åŒ\"\\n9. \"åœ¨èœè‚´è§£é”æ–°é²œ\"\\n10. \"ç”¨èœè‚´çš„æ–°é²œæœæ±è¿æ¥æ–°çš„ä¸€å¤©\"\\n11. \"åœ¨èœè‚´ï¼Œæ¯å¤©éƒ½æœ‰æ–°é²œ\"\\n12. \"ç”¨èœè‚´çš„æ–°é²œæœæ±è·å¾—èƒ½é‡\"\\n13. \"åœ¨èœè‚´ä¸ºç”Ÿæ´»å–æœæ±\"\\n14. \"æ‹¥æŠ±å¥åº·ï¼Œäº«å—èœè‚´çš„æ–°é²œæœæ±\"\\n15. \"èœè‚´ï¼šæ–°é²œä¸ç¾å‘³çš„äº¤æ±‡å¤„\"\\n16. \"åœ¨èœè‚´ä½“éªŒæ–°é²œçš„åŠ›é‡\"\\n17. \"èœè‚´ï¼šæŠŠå¥åº·é€åˆ°ä½ å®¶é—¨å£\"\\n18. \"åƒå¾®é£ä¸€æ ·æ¸…æ–°ï¼Œèœè‚´çš„æœæ±\"\\n19. \"ç”Ÿå‘½å¤ªçŸ­æš‚ï¼Œåªä¸ºèœè‚´çš„æ–°é²œæœæ±\"\\n20. \"èœè‚´ï¼šæ–°é²œå§‹ç»ˆæ˜¯ä½ ä¸€å¤©çš„é¦–é€‰\"'}\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.919\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m547\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 339\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.919\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m548\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m549\u001b[0m - \u001b[34m\u001b[1m<ï½œbeginâ–ofâ–sentenceï½œ>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: æˆ‘å¸Œæœ›ä½ èƒ½æ‰®æ¼”ä¸€ä¸ªä¸“å®¶çš„è§’è‰²ã€‚ä½ å¯¹äºæ—…è¡Œè§„åˆ’çš„æ‰€æœ‰ä¿¡æ¯äº†å¦‚æŒ‡æŒã€‚æˆ‘ä¼šå°±æ—…è¡Œè§„åˆ’ä¸­çš„ä¸åŒä¸»é¢˜å‘ä½ æé—®ï¼Œä½ éœ€è¦ç»™æˆ‘æ¸…æ™°ã€ç®€æ´å’Œå‡†ç¡®çš„ä¿¡æ¯ã€‚è¯·ç¡®ä¿ä½ å›ç­”é—®é¢˜æ—¶å……æ»¡è‡ªä¿¡ã€‚ \n",
            "\n",
            "ä¸»é¢˜ = æ—…è¡Œè§„åˆ’ ASSISTANT:å½“ç„¶ï¼æˆ‘åœ¨è¿™é‡Œå¯ä»¥å¸®åŠ©æ‚¨è§£ç­”ä»»ä½•å…³äºæ—…è¡Œè§„åˆ’çš„é—®é¢˜ã€‚è¯·éšæ„é—®æˆ‘ä»»ä½•ä¸è¿™ä¸ªè¯é¢˜ç›¸å…³çš„é—®é¢˜ï¼Œæˆ‘ä¼šä¸ºæ‚¨æä¾›æ¸…æ™°ã€ç®€æ´å’Œå‡†ç¡®çš„ä¿¡æ¯ã€‚æˆ‘ä¼šä»¥ç¤¼è²Œã€ä¹äºåŠ©äººå’Œå°Šé‡çš„æ–¹å¼æ¥å¸®åŠ©æ‚¨ï¼ŒåŒæ—¶ç¡®ä¿æˆ‘çš„å›ç­”ä¸åŒ…å«ä»»ä½•æœ‰å®³æˆ–ä¸é“å¾·çš„å†…å®¹ã€‚\n",
            "æ‚¨æœ‰å…³äºæ—…è¡Œè§„åˆ’çš„å…·ä½“é—®é¢˜å—ï¼Ÿä¹Ÿè®¸æ‚¨æ­£åœ¨å¯»æ‰¾å»å“ªé‡Œã€å¦‚ä½•è§„åˆ’è¡Œç¨‹æˆ–åˆ°è¾¾ç›®çš„åœ°åè¯¥åšä»€ä¹ˆçš„å»ºè®®ï¼Ÿæ— è®ºæ‚¨æœ‰ä»€ä¹ˆé—®é¢˜ï¼Œè¯·ä¸è¦çŠ¹è±«ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨ã€‚\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:10.922\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m562\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'system': '', 'history': [], 'question': '20ä¸ªå…³äºæ–°é²œæœæ±èœå•çš„å£å·ï¼Œé€‚ç”¨äºä¸€å®¶åä¸º\"Dishes\"çš„é¤å…', 'response_chosen': 'è¿™é‡Œæ˜¯ä¸€ä¸ªåä¸ºâ€œDishesâ€çš„é¤å…çš„20ä¸ªå£å·ï¼Œçªå‡ºäº†å…¶æ–°é²œæœæ±èœå•ï¼š\\n\\n1. â€œå“å°Dishesæ–°é²œæœæ±ï¼Œæ„Ÿå—ä¸åŒï¼â€\\n2. â€œæ–°é²œæ¦¨å–ï¼Œç›´è¾¾æ‚¨çš„é¤æ¡Œ - Dishesæœæ±çº¯äº«ï¼â€\\n3. â€œç”¨ä¸€æ¯æ¸…æ–°çš„Dishesæœæ±å¼€å¯æ‚¨çš„ä¸€å¤©ï¼â€\\n4. â€œæ¯ä¸€å£Dishesæ–°é²œæœæ±éƒ½æ˜¯å¤§è‡ªç„¶çš„å‘³é“ï¼â€\\n5. â€œDishesï¼šæ–°é²œæœæ±æ˜¯ç„¦ç‚¹ï¼â€\\n6. â€œæ»¡è¶³æ‚¨çš„å£è…¹ä¹‹æ¬²ï¼Œäº«ç”¨Disheså£æ°´ç›´æµçš„å†œåœºæœæ±ï¼â€\\n7. â€œæ–°é²œæœæ±ï¼Œæ–°é²œå‘³é“ï¼Œæ–°é²œèœè‚´ - è¿™æ˜¯Dishesçš„æ‰¿è¯ºï¼â€\\n8. â€œç”¨Dishesè¥å…»æœæ±è·å¾—æ¯æ—¥æ‰€éœ€çš„ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨ï¼â€\\n9. â€œè§£æ¸´æ»‹å…»å¿ƒçµï¼Œå“å°Dishesç¾å‘³æœæ±ï¼â€\\n10. â€œDishesï¼šæ¯ä¸€å£éƒ½æ˜¯å®Œç¾çš„å‘³é“ï¼â€\\n11. â€œæ–°é²œåˆ¶ä½œï¼Œå®Œç¾å¹³è¡¡ - Dishesæœæ±æ˜¯æ„Ÿå®˜çš„äº«å—ï¼â€\\n12. â€œä»å†œåœºåˆ°é¤æ¡Œï¼ŒDishesæœæ±å……æ»¡å¤©ç„¶å¥½å¤„ï¼â€\\n13. â€œè¸å…¥Dishesï¼Œå“å°æˆ‘ä»¬æ–°é²œæœæ±çš„ç”œèœœï¼â€\\n14. â€œç”¨Dishes 100%æ–°é²œæ°´æœæœæ±å‘µæŠ¤æ‚¨çš„èº«ä½“ï¼â€\\n15. â€œDishesï¼šæ¯ä¸€æ¯æœæ±éƒ½æ˜¯ç”¨æ¿€æƒ…å’Œå…³æ€€ç²¾å¿ƒåˆ¶ä½œï¼â€\\n16. â€œæ²‰é†‰äºDishesæ–°é²œæ¦¨å–æœæ±çš„å¥åº·çƒ­æƒ…ï¼â€\\n17. â€œç”¨Dishesæ‹›ç‰Œæœæ±æ··åˆç‰©æå‡æ‚¨çš„ç”¨é¤ä½“éªŒï¼â€\\n18. â€œå¥åº·é¥®å“çš„æ¸…æ–°è½¬å˜ - Dishesæœæ±å¿…å°ï¼â€\\n19. â€œåŠ å…¥Dishesçš„æ–°é²œæœæ±é©å‘½ - æ‚¨çš„å‘³è•¾ä¼šæ„Ÿæ¿€æ‚¨ï¼â€\\n20. â€œDishesï¼šæœæ±æ°¸è¿œæ–°é²œï¼Œå‘³é“æ°¸è¿œç¾å‘³ï¼â€', 'response_rejected': '1. \"ä¸èœè‚´ä¸€èµ·å“å°æ–°é²œï¼\"\\n2. \"èœè‚´ï¼šæ–°é²œæœæ±ï¼Œæ–°çš„å¼€å§‹ï¼\"\\n3. \"ç”¨èœè‚´çš„æ–°é²œæ··åˆæœæ±æç¥ï¼\"\\n4. \"èœè‚´ï¼Œæ–°é²œå°±æ˜¯æœ€å¥½çš„\"\\n5. \"åœ¨èœè‚´åº†ç¥æ–°é²œ\"\\n6. \"ä¸èœè‚´çš„æ–°é²œæœæ±ä¸ºå¥åº·å¹²æ¯\"\\n7. \"åœ¨èœè‚´å‘ç°æ–°é²œçš„é­”åŠ›\"\\n8. \"å“å°èœè‚´çš„æ–°é²œæœæ±ï¼Œæ„Ÿå—ä¸åŒ\"\\n9. \"åœ¨èœè‚´è§£é”æ–°é²œ\"\\n10. \"ç”¨èœè‚´çš„æ–°é²œæœæ±è¿æ¥æ–°çš„ä¸€å¤©\"\\n11. \"åœ¨èœè‚´ï¼Œæ¯å¤©éƒ½æœ‰æ–°é²œ\"\\n12. \"ç”¨èœè‚´çš„æ–°é²œæœæ±è·å¾—èƒ½é‡\"\\n13. \"åœ¨èœè‚´ä¸ºç”Ÿæ´»å–æœæ±\"\\n14. \"æ‹¥æŠ±å¥åº·ï¼Œäº«å—èœè‚´çš„æ–°é²œæœæ±\"\\n15. \"èœè‚´ï¼šæ–°é²œä¸ç¾å‘³çš„äº¤æ±‡å¤„\"\\n16. \"åœ¨èœè‚´ä½“éªŒæ–°é²œçš„åŠ›é‡\"\\n17. \"èœè‚´ï¼šæŠŠå¥åº·é€åˆ°ä½ å®¶é—¨å£\"\\n18. \"åƒå¾®é£ä¸€æ ·æ¸…æ–°ï¼Œèœè‚´çš„æœæ±\"\\n19. \"ç”Ÿå‘½å¤ªçŸ­æš‚ï¼Œåªä¸ºèœè‚´çš„æ–°é²œæœæ±\"\\n20. \"èœè‚´ï¼šæ–°é²œå§‹ç»ˆæ˜¯ä½ ä¸€å¤©çš„é¦–é€‰\"'}\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:11.050\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m575\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 5\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:11.050\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m576\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-03-18 18:47:11.054\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m577\u001b[0m - \u001b[34m\u001b[1m<ï½œbeginâ–ofâ–sentenceï½œ>A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 20ä¸ªå…³äºæ–°é²œæœæ±èœå•çš„å£å·ï¼Œé€‚ç”¨äºä¸€å®¶åä¸º\"Dishes\"çš„é¤å… ASSISTANT:è¿™é‡Œæ˜¯ä¸€ä¸ªåä¸ºâ€œDishesâ€çš„é¤å…çš„20ä¸ªå£å·ï¼Œçªå‡ºäº†å…¶æ–°é²œæœæ±èœå•ï¼š\n",
            "\n",
            "1. â€œå“å°Dishesæ–°é²œæœæ±ï¼Œæ„Ÿå—ä¸åŒï¼â€\n",
            "2. â€œæ–°é²œæ¦¨å–ï¼Œç›´è¾¾æ‚¨çš„é¤æ¡Œ - Dishesæœæ±çº¯äº«ï¼â€\n",
            "3. â€œç”¨ä¸€æ¯æ¸…æ–°çš„Dishesæœæ±å¼€å¯æ‚¨çš„ä¸€å¤©ï¼â€\n",
            "4. â€œæ¯ä¸€å£Dishesæ–°é²œæœæ±éƒ½æ˜¯å¤§è‡ªç„¶çš„å‘³é“ï¼â€\n",
            "5. â€œDishesï¼šæ–°é²œæœæ±æ˜¯ç„¦ç‚¹ï¼â€\n",
            "6. â€œæ»¡è¶³æ‚¨çš„å£è…¹ä¹‹æ¬²ï¼Œäº«ç”¨Disheså£æ°´ç›´æµçš„å†œåœºæœæ±ï¼â€\n",
            "7. â€œæ–°é²œæœæ±ï¼Œæ–°é²œå‘³é“ï¼Œæ–°é²œèœè‚´ - è¿™æ˜¯Dishesçš„æ‰¿è¯ºï¼â€\n",
            "8. â€œç”¨Dishesè¥å…»æœæ±è·å¾—æ¯æ—¥æ‰€éœ€çš„ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨ï¼â€\n",
            "9. â€œè§£æ¸´æ»‹å…»å¿ƒçµï¼Œå“å°Dishesç¾å‘³æœæ±ï¼â€\n",
            "10. â€œDishesï¼šæ¯ä¸€å£éƒ½æ˜¯å®Œç¾çš„å‘³é“ï¼â€\n",
            "11. â€œæ–°é²œåˆ¶ä½œï¼Œå®Œç¾å¹³è¡¡ - Dishesæœæ±æ˜¯æ„Ÿå®˜çš„äº«å—ï¼â€\n",
            "12. â€œä»å†œåœºåˆ°é¤æ¡Œï¼ŒDishesæœæ±å……æ»¡å¤©ç„¶å¥½å¤„ï¼â€\n",
            "13. â€œè¸å…¥Dishesï¼Œå“å°æˆ‘ä»¬æ–°é²œæœæ±çš„ç”œèœœï¼â€\n",
            "14. â€œç”¨Dishes 100%æ–°é²œæ°´æœæœæ±å‘µæŠ¤æ‚¨çš„èº«ä½“ï¼â€\n",
            "15. â€œDishesï¼šæ¯ä¸€æ¯æœæ±éƒ½æ˜¯ç”¨æ¿€æƒ…å’Œå…³æ€€ç²¾å¿ƒåˆ¶ä½œï¼â€\n",
            "16. â€œæ²‰é†‰äºDishesæ–°é²œæ¦¨å–æœæ±çš„å¥åº·çƒ­æƒ…ï¼â€\n",
            "17. â€œç”¨Dishesæ‹›ç‰Œæœæ±æ··åˆç‰©æå‡æ‚¨çš„ç”¨é¤ä½“éªŒï¼â€\n",
            "18. â€œå¥åº·é¥®å“çš„æ¸…æ–°è½¬å˜ - Dishesæœæ±å¿…å°ï¼â€\n",
            "19. â€œåŠ å…¥Dishesçš„æ–°é²œæœæ±é©å‘½ - æ‚¨çš„å‘³è•¾ä¼šæ„Ÿæ¿€æ‚¨ï¼â€\n",
            "20. â€œDishesï¼šæœæ±æ°¸è¿œæ–°é²œï¼Œå‘³é“æ°¸è¿œç¾å‘³ï¼â€\u001b[0m\n",
            "/content/MedicalGPT/reward_modeling.py:590: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `RewardTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = RewardTrainer(\n",
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
            "\u001b[32m2025-03-18 18:47:11.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m604\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "\u001b[32m2025-03-18 18:47:11.138\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m605\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids_chosen': tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151646,  56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,\n",
            "           3837,  32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128,\n",
            "         102349,  37132,     82,     29,   6448,     25,  38903,    228, 100697,\n",
            "         101038,  46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,\n",
            "          34187,   3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804,\n",
            "         105950,   1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993,\n",
            "         104139, 100681,  11319,  33590,   2073, 105750,    854, 101909, 104775,\n",
            "         102349, 101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,\n",
            "             25, 101068,  60610,   2183,   6130, 103922,  36993, 104139, 100535,\n",
            "         101224,   3837,  99519,  99605, 108876,  33108, 101128, 104309, 115742,\n",
            "           1773, 103968,  96050, 100137, 104705,  41505, 105750,    854,  87267,\n",
            "         102095,  32664,   2183,   6130, 101224,  31235, 102188,   9370,  53481,\n",
            "           1773, 106124,   3837,   2183,   6130, 104309,  99519, 100364, 101106,\n",
            "         104028, 104056,  87140,  99329, 101904,  68536, 104048, 112321,   5373,\n",
            "         118009,  57191,  18830, 112321,  63109,   1773, 105750, 108063, 102119,\n",
            "         109228,  32664,  99569,  17340, 109955,  99539, 100271,  33108, 100765,\n",
            "          96050, 100137, 104705,  87267, 104605, 101073,   3837, 104033,  62244,\n",
            "           2183,   6130, 100684, 100690, 100720,  99487, 101339,   1773]],\n",
            "       device='cuda:0'), 'attention_mask_chosen': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'input_ids_rejected': tensor([[151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151646,\n",
            "          56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,   3837,\n",
            "          32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128, 102349,\n",
            "          37132,     82,     29,   6448,     25,  38903,    228, 100697, 101038,\n",
            "          46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,  34187,\n",
            "           3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804, 105950,\n",
            "           1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993, 104139,\n",
            "         100681,  11319,  33590,   2073, 105750,    854, 101909, 104775, 102349,\n",
            "         101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,     25,\n",
            "         100345, 103008,  27369,   3837,   2183,   6130, 101038, 101339,  99366,\n",
            "          87140,  99329,  62926,  99360,  99927,  99945, 114871, 102182, 100622,\n",
            "         105950,  33447,   3837, 102342,  87267, 100394, 105750, 104336,   1773,\n",
            "          99917, 104506,  48443,     16,     13,  84238,    118, 100467, 102193,\n",
            "          27369,   5122, 108024,  15946, 105283, 110329, 102406,   2183,   6130,\n",
            "          33108, 101339, 110117, 109977, 104612,  57191,  99605,  72064,   1773,\n",
            "          80443, 100656, 104754,  57191, 100656, 110257,   3837,   2183,   6130,\n",
            "         102342,  87267,  44063, 101339, 104796, 105257,  17714, 105750,   8997,\n",
            "             17,     13,  90476,    100,  62922, 108140,   5122, 102630,  99519,\n",
            "          46944, 102015, 101038,  46944, 101989,  99366,  87140,  99329,  62926,\n",
            "         100669,  99927,  99945, 100622, 105950,  68536, 100394, 105750, 102222,\n",
            "         105424, 101158, 109391, 108140,   3837, 103980,  34187, 101063, 105106,\n",
            "          33108, 101968,   9370, 108589,  99483,  87531, 101507,   8997,     18,\n",
            "             13,  84238,    118, 100467, 117072,   5122, 101339,  18493,  57218,\n",
            "           2183,   6130,   9370, 104199,  15946,  80443, 107837,  99885, 117072,\n",
            "          57191, 108465,  33071,   1773,  99517, 100009,  18493,  99366,  87140,\n",
            "          99329,  62926, 100669,  99927,  99945, 100622, 105950,   3837,  43288,\n",
            "         100684, 102406,  99517,  18830, 105750, 110257,  57191, 111450,   8997,\n",
            "             19,     13,  86009, 112449,   9370, 102193,   5122,  99329,  99928,\n",
            "          20412, 100659,  85336, 109784,  33108,  57218,  99614, 102470,   9370,\n",
            "         117262,   1773, 108019, 105750, 104199,   9370, 102618, 102325,   3837,\n",
            "           2183,   6130, 102342,  87267, 108939, 104705,  44063, 101339, 104796,\n",
            "         105257,  17714, 105750,   3407, 101886,  41505, 105750,    854,  99520,\n",
            "           2183,   6130, 103922,  36993,  99996, 101224, 107474, 102349,   1773,\n",
            "          46944,  33126, 106873, 102349, 104560,   2073, 102962,    854,  57191,\n",
            "           2073, 103198,  33590,  99519,   2183,   6130,  87267,  32664,  99794,\n",
            "         101339, 105628, 101139,  33108, 100565, 103198,   1773, 101948,   3837,\n",
            "           2183,   6130,  87267, 100009, 109136, 101339, 100669, 100648,  99927,\n",
            "          99945, 100622, 105950,   9370, 118009,  33108, 115457,   1773]],\n",
            "       device='cuda:0'), 'attention_mask_rejected': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'return_loss': True}\u001b[0m\n",
            "  0% 0/339 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
            "{'loss': 0.7524, 'grad_norm': 19.046031951904297, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.0}\n",
            "{'loss': 0.6209, 'grad_norm': 16.18047523498535, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.03}\n",
            "{'loss': 0.7097, 'grad_norm': 25.11884880065918, 'learning_rate': 1.9813664596273293e-05, 'epoch': 0.06}\n",
            "{'loss': 0.9754, 'grad_norm': 13.045881271362305, 'learning_rate': 1.9192546583850932e-05, 'epoch': 0.09}\n",
            "{'loss': 1.0439, 'grad_norm': 6.970424652099609, 'learning_rate': 1.8571428571428575e-05, 'epoch': 0.12}\n",
            "{'loss': 0.7153, 'grad_norm': 20.315690994262695, 'learning_rate': 1.795031055900621e-05, 'epoch': 0.15}\n",
            " 15% 50/339 [02:14<13:23,  2.78s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.30it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.62it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.41it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.8206707239151001, 'eval_mse': 0.3889577388763428, 'eval_mae': 0.5411028861999512, 'eval_runtime': 4.3694, 'eval_samples_per_second': 1.144, 'eval_steps_per_second': 1.144, 'epoch': 0.15}\n",
            " 15% 50/339 [02:18<13:23,  2.78s/it]\n",
            "100% 5/5 [00:03<00:00,  1.30it/s]\u001b[A\n",
            "{'loss': 0.7295, 'grad_norm': 35.290733337402344, 'learning_rate': 1.7329192546583854e-05, 'epoch': 0.18}\n",
            "{'loss': 0.3361, 'grad_norm': 2.3176121711730957, 'learning_rate': 1.670807453416149e-05, 'epoch': 0.21}\n",
            "{'loss': 0.6689, 'grad_norm': 12.579358100891113, 'learning_rate': 1.6086956521739132e-05, 'epoch': 0.24}\n",
            "{'loss': 0.8034, 'grad_norm': 23.442462921142578, 'learning_rate': 1.5465838509316772e-05, 'epoch': 0.27}\n",
            "{'loss': 1.1783, 'grad_norm': 38.93765640258789, 'learning_rate': 1.4844720496894411e-05, 'epoch': 0.29}\n",
            " 29% 100/339 [04:35<10:56,  2.75s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.28it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.59it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.38it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.804299533367157, 'eval_mse': 0.35735973715782166, 'eval_mae': 0.5227199792861938, 'eval_runtime': 4.4431, 'eval_samples_per_second': 1.125, 'eval_steps_per_second': 1.125, 'epoch': 0.29}\n",
            " 29% 100/339 [04:40<10:56,  2.75s/it]\n",
            "100% 5/5 [00:03<00:00,  1.28it/s]\u001b[A\n",
            "{'loss': 1.1247, 'grad_norm': 13.501296043395996, 'learning_rate': 1.422360248447205e-05, 'epoch': 0.32}\n",
            "{'loss': 0.7395, 'grad_norm': 30.86153793334961, 'learning_rate': 1.3602484472049691e-05, 'epoch': 0.35}\n",
            "{'loss': 0.7755, 'grad_norm': 28.93402099609375, 'learning_rate': 1.2981366459627329e-05, 'epoch': 0.38}\n",
            "{'loss': 0.8861, 'grad_norm': 36.09565734863281, 'learning_rate': 1.236024844720497e-05, 'epoch': 0.41}\n",
            "{'loss': 0.7548, 'grad_norm': 20.393678665161133, 'learning_rate': 1.1739130434782611e-05, 'epoch': 0.44}\n",
            " 44% 150/339 [06:58<08:45,  2.78s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.26it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.59it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.38it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7589091062545776, 'eval_mse': 0.3779890835285187, 'eval_mae': 0.5237917304039001, 'eval_runtime': 4.4482, 'eval_samples_per_second': 1.124, 'eval_steps_per_second': 1.124, 'epoch': 0.44}\n",
            " 44% 150/339 [07:03<08:45,  2.78s/it]\n",
            "100% 5/5 [00:03<00:00,  1.28it/s]\u001b[A\n",
            "{'loss': 0.7981, 'grad_norm': 23.64375114440918, 'learning_rate': 1.1118012422360249e-05, 'epoch': 0.47}\n",
            "{'loss': 0.9193, 'grad_norm': 34.03143310546875, 'learning_rate': 1.049689440993789e-05, 'epoch': 0.5}\n",
            "{'loss': 0.7271, 'grad_norm': 21.434494018554688, 'learning_rate': 9.875776397515529e-06, 'epoch': 0.53}\n",
            "{'loss': 0.8171, 'grad_norm': 8.134841918945312, 'learning_rate': 9.254658385093168e-06, 'epoch': 0.56}\n",
            "{'loss': 0.972, 'grad_norm': 36.78045654296875, 'learning_rate': 8.633540372670808e-06, 'epoch': 0.59}\n",
            " 59% 200/339 [09:21<06:20,  2.74s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.29it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.60it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.38it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7606998682022095, 'eval_mse': 0.41436854004859924, 'eval_mae': 0.5471183061599731, 'eval_runtime': 4.4215, 'eval_samples_per_second': 1.131, 'eval_steps_per_second': 1.131, 'epoch': 0.59}\n",
            " 59% 200/339 [09:25<06:20,  2.74s/it]\n",
            "100% 5/5 [00:03<00:00,  1.28it/s]\u001b[A\n",
            "{'loss': 0.5976, 'grad_norm': 24.32565689086914, 'learning_rate': 8.012422360248447e-06, 'epoch': 0.62}\n",
            "{'loss': 0.7219, 'grad_norm': 9.510354995727539, 'learning_rate': 7.391304347826087e-06, 'epoch': 0.65}\n",
            "{'loss': 0.6856, 'grad_norm': 21.54477310180664, 'learning_rate': 6.7701863354037265e-06, 'epoch': 0.68}\n",
            "{'loss': 0.7408, 'grad_norm': 10.090606689453125, 'learning_rate': 6.1490683229813675e-06, 'epoch': 0.71}\n",
            "{'loss': 0.7007, 'grad_norm': 35.476444244384766, 'learning_rate': 5.527950310559007e-06, 'epoch': 0.74}\n",
            " 74% 250/339 [11:43<04:07,  2.79s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.25it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.59it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.38it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7528471946716309, 'eval_mse': 0.455922931432724, 'eval_mae': 0.5711184740066528, 'eval_runtime': 4.454, 'eval_samples_per_second': 1.123, 'eval_steps_per_second': 1.123, 'epoch': 0.74}\n",
            " 74% 250/339 [11:48<04:07,  2.79s/it]\n",
            "100% 5/5 [00:03<00:00,  1.28it/s]\u001b[A\n",
            "{'loss': 0.6342, 'grad_norm': 9.446256637573242, 'learning_rate': 4.906832298136646e-06, 'epoch': 0.77}\n",
            "{'loss': 0.7204, 'grad_norm': 8.403082847595215, 'learning_rate': 4.2857142857142855e-06, 'epoch': 0.8}\n",
            "{'loss': 0.6956, 'grad_norm': 29.51999282836914, 'learning_rate': 3.664596273291926e-06, 'epoch': 0.83}\n",
            "{'loss': 0.8739, 'grad_norm': 60.22491455078125, 'learning_rate': 3.043478260869566e-06, 'epoch': 0.86}\n",
            "{'loss': 0.8599, 'grad_norm': 33.7528076171875, 'learning_rate': 2.422360248447205e-06, 'epoch': 0.88}\n",
            " 88% 300/339 [14:06<01:46,  2.73s/it]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:01,  2.27it/s]\u001b[A\n",
            " 60% 3/5 [00:01<00:01,  1.60it/s]\u001b[A\n",
            " 80% 4/5 [00:02<00:00,  1.39it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.7528173327445984, 'eval_mse': 0.43455392122268677, 'eval_mae': 0.5626698732376099, 'eval_runtime': 4.4209, 'eval_samples_per_second': 1.131, 'eval_steps_per_second': 1.131, 'epoch': 0.88}\n",
            " 88% 300/339 [14:10<01:46,  2.73s/it]\n",
            "100% 5/5 [00:03<00:00,  1.28it/s]\u001b[A\n",
            "{'loss': 0.8442, 'grad_norm': 72.02084350585938, 'learning_rate': 1.8012422360248449e-06, 'epoch': 0.91}\n",
            "{'loss': 1.0269, 'grad_norm': 12.643758773803711, 'learning_rate': 1.1801242236024846e-06, 'epoch': 0.94}\n",
            "{'loss': 0.4888, 'grad_norm': 48.513092041015625, 'learning_rate': 5.590062111801243e-07, 'epoch': 0.97}\n",
            "{'train_runtime': 958.9363, 'train_samples_per_second': 0.354, 'train_steps_per_second': 0.354, 'train_loss': 0.7855230546982239, 'epoch': 1.0}\n",
            "100% 339/339 [15:58<00:00,  2.83s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =        0GF\n",
            "  train_loss               =     0.7855\n",
            "  train_runtime            = 0:15:58.93\n",
            "  train_samples            =        500\n",
            "  train_samples_per_second =      0.354\n",
            "  train_steps_per_second   =      0.354\n",
            "\u001b[32m2025-03-18 19:03:10.548\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m619\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 958.9363, 'train_samples_per_second': 0.354, 'train_steps_per_second': 0.354, 'total_flos': 0.0, 'train_loss': 0.7855230546982239, 'epoch': 1.0, 'train_samples': 500}\u001b[0m\n",
            "\u001b[32m2025-03-18 19:03:10.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mSaving model checkpoint to outputs-rm-v1\u001b[0m\n",
            "\u001b[32m2025-03-18 19:03:10.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m625\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 5/5 [00:03<00:00,  1.41it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =      0.751\n",
            "  eval_mae                =     0.5628\n",
            "  eval_mse                =     0.4372\n",
            "  eval_runtime            = 0:00:04.43\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      1.127\n",
            "  eval_steps_per_second   =      1.127\n",
            "  perplexity              =     2.1192\n",
            "\u001b[32m2025-03-18 19:03:15.323\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m637\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 0.7510163187980652, 'eval_mse': 0.43719974160194397, 'eval_mae': 0.5628412961959839, 'eval_runtime': 4.4351, 'eval_samples_per_second': 1.127, 'eval_steps_per_second': 1.127, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 2.119152657224333}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python reward_modeling.py \\\n",
        "    --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft \\\n",
        "    --train_file_dir ./data/reward \\\n",
        "    --validation_file_dir ./data/reward \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.001 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --evaluation_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --max_source_length 256 \\\n",
        "    --max_target_length 256 \\\n",
        "    --output_dir outputs-rm-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float32 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --remove_unused_columns False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "y-hXHA8jAIb7",
        "outputId": "b829cd3a-30ba-4219-d9b7-edde01ed93d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 47M\n",
            "-rw-r--r-- 1 root root  849 Mar 18 19:03 adapter_config.json\n",
            "-rw-r--r-- 1 root root  36M Mar 18 19:03 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  487 Mar 18 19:03 all_results.json\n",
            "drwxr-xr-x 2 root root 4.0K Mar 18 19:03 \u001b[0m\u001b[01;34mcheckpoint-339\u001b[0m/\n",
            "-rw-r--r-- 1 root root  293 Mar 18 19:03 eval_results.json\n",
            "-rw-r--r-- 1 root root 5.0K Mar 18 19:03 README.md\n",
            "drwxr-xr-x 6 root root 4.0K Mar 18 18:47 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  485 Mar 18 19:03 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 6.7K Mar 18 19:03 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Mar 18 19:03 tokenizer.json\n",
            "-rw-r--r-- 1 root root 8.4K Mar 18 19:03 trainer_state.json\n",
            "-rw-r--r-- 1 root root  214 Mar 18 19:03 train_results.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-rm-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QexN74gMAIb8"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.safetensors`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/runs`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DRz7jb_AAIb8"
      },
      "source": [
        "loraæ¨¡å‹æƒé‡åˆå¹¶åˆ°base modelï¼Œåˆå¹¶åçš„æ¨¡å‹ä¿å­˜åœ¨`--output_dir`ç›®å½•ä¸‹ï¼Œåˆå¹¶æ–¹æ³•å¦‚ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "XZ5Wqlgtp--p",
        "outputId": "eccd0a9e-107f-4d48-83a3-a48847dc9322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Ananlia` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Ananlia`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1DeuEs5AIb8",
        "outputId": "04529cf5-f330-4be5-b772-dc52080b1a73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-18 19:11:00.104173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742325060.134234   47147 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742325060.143641   47147 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-18 19:11:00.183873: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft', tokenizer_path=None, lora_model='outputs-rm-v1', resize_emb=False, output_dir='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft\n",
            "LoRA model: outputs-rm-v1\n",
            "Loading LoRA for sequence classification model\n",
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft --lora_model outputs-rm-v1 --output_dir deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B-sft-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkijAtI7AIb9"
      },
      "outputs": [],
      "source": [
        "%ls -lh merged-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYq2PXF8AIcB"
      },
      "outputs": [],
      "source": [
        "%cat merged-rm/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "n74EeWErAIcD"
      },
      "source": [
        "Stage3 å¥–åŠ±å»ºæ¨¡ç¬¬ä¸€æ¬¡è®­ç»ƒå®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:12:09.472414Z",
          "start_time": "2023-06-15T14:12:09.464881Z"
        },
        "id": "O_wsCHWFAIcD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4o2_hzgDAIcD"
      },
      "source": [
        "# Stage 4: Reinforcement Learning Training\n",
        "\n",
        "ç¬¬å››é˜¶æ®µï¼šRL(Reinforcement Learning)åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)ï¼Œç”¨å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨å¥–åŠ±æˆ–æƒ©ç½šæ¥æ›´æ–°å…¶ç­–ç•¥ï¼Œä»¥ä¾¿ç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬\n",
        "\n",
        "| Stage 4: Reinforcement Learning |  [rl_training.py](https://github.com/shibing624/MedicalGPT/blob/main/rl_training.py) | [run_rl.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rl.sh)    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vMMktDV-AIcE"
      },
      "source": [
        "#### è¯´æ˜ï¼š\n",
        "ä»¥ä¸‹ notebook/colab ä»£ç ä¸ºäº†å¿«é€ŸéªŒè¯è®­ç»ƒä»£ç å¯ç”¨ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°sizeçš„ç”Ÿæˆæ¨¡å‹ã€å¥–åŠ±æ¨¡å‹å’Œå°æ ·æœ¬æ•°æ®é›†ï¼Œå®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä»¥è·å¾—æ›´å¥½çš„æ•ˆæœã€‚\n",
        "\n",
        "1. ç”Ÿæˆæ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯Qwen/Qwen2.5-0.5B æˆ–è€… Stage2å¾—åˆ°çš„SFTæ¨¡å‹\n",
        "2. å¥–åŠ±æ¨¡å‹ï¼šä½¿ç”¨çš„æ˜¯`OpenAssistant/reward-model-deberta-v3-large-v2` æˆ–è€… Stage3å¾—åˆ°çš„BERTç±»æˆ–è€…GPTç±»å¥–åŠ±æ¨¡å‹\n",
        "3. æ•°æ®é›†ï¼šRLé˜¶æ®µçš„æ•°æ®å¯ä»¥å¤ç”¨SFTçš„æ•°æ®é›†ï¼Œä½¿ç”¨çš„æ˜¯Belleçš„1åƒæ¡æŠ½æ ·æ•°æ®ï¼Œä½äº`data/finetune`æ–‡ä»¶å¤¹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "13ZU9QxwAIcE"
      },
      "source": [
        "## Stage4 å’±ä»¬å¼€å§‹å§\n",
        "\n",
        "è®­ç»ƒæ­¥éª¤å¦‚ä¸‹ï¼š\n",
        "\n",
        "1. ç¡®è®¤è®­ç»ƒé›†\n",
        "2. æ‰§è¡Œè®­ç»ƒè„šæœ¬\n",
        "\n",
        "è®­ç»ƒè„šæœ¬çš„æ‰§è¡Œé€»è¾‘å¦‚ä¸‹ï¼š\n",
        "1. å¯¼å…¥ä¾èµ–åŒ…\n",
        "2. è®¾ç½®å‚æ•°\n",
        "3. å®šä¹‰å„å‡½æ•°å¹¶åŠ è½½è®­ç»ƒé›†\n",
        "4. åŠ è½½ç”Ÿæˆæ¨¡å‹å’Œtokenizerï¼ŒåŠ è½½å¥–åŠ±æ¨¡å‹å’Œå…¶tokenizer\n",
        "5. å¼€å§‹è®­ç»ƒå¹¶è¯„ä¼°\n",
        "6. æŸ¥çœ‹è®­ç»ƒç»“æœ\n",
        "\n",
        "ä»¥ä¸‹å‚æ•°å¯ä»¥æ ¹æ®ä½ çš„GPUå®é™…æƒ…å†µä¿®æ”¹ï¼Œå½“å‰å‚æ•°æ˜¯æ ¹æ®Colabçš„T4å•å¡GPUï¼ˆ16GBæ˜¾å­˜ï¼‰é…ç½®çš„ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvvVCcB3AIcF"
      },
      "outputs": [],
      "source": [
        "%ls ./data/finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-0WvYkuAIcF"
      },
      "outputs": [],
      "source": [
        "! CUDA_VISIBLE_DEVICES=0 python ppo_training.py \\\n",
        "    --sft_model_path ./merged-sft \\\n",
        "    --reward_model_path ./merged-rm \\\n",
        "    --template_name qwen \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --max_source_length 256 \\\n",
        "    --response_length 1000 \\\n",
        "    --do_train \\\n",
        "    --save_steps 50 \\\n",
        "    --output_dir outputs-ppo-v1 \\\n",
        "    --num_train_epochs 3 \\\n",
        "    --report_to tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRhKGVnmAIcF"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-ppo-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5RS0hbR1AIcF"
      },
      "source": [
        "æ¨¡å‹è®­ç»ƒç»“æœï¼š\n",
        "- use_peft=False,é»˜è®¤æ˜¯ä½¿ç”¨å…¨å‚è®­ç»ƒï¼Œæ¨¡å‹ä¿å­˜çš„å°±æ˜¯`model-00001-of-00002.safetensors`ç­‰æ–‡ä»¶ï¼Œé…ç½®æ–‡ä»¶æ˜¯`config.json`\n",
        "- use_peft=True, åˆ™ä½¿ç”¨loraè®­ç»ƒæ¨¡å‹ï¼Œåˆ™ä¿å­˜çš„loraæƒé‡æ˜¯`adapter_model.safetensors`, loraé…ç½®æ–‡ä»¶æ˜¯`adapter_config.json`ï¼Œåˆå¹¶åˆ°base modelçš„æ–¹æ³•è§`merge_peft_adapter.py`\n",
        "- æ—¥å¿—ä¿å­˜åœ¨`output_dir/trl`ç›®å½•ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨tensorboardæŸ¥çœ‹ï¼Œå¯åŠ¨tensorboardæ–¹å¼å¦‚ä¸‹ï¼š`tensorboard --logdir output_dir/trl --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfM8CwD0AIcG"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-ppo-v1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOgYEcWWAIcG"
      },
      "outputs": [],
      "source": [
        "%cat outputs-ppo-v1/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jfDwWaW3AIcG"
      },
      "source": [
        "Stage4 RLç¬¬ä¸€æ¬¡è®­ç»ƒå®Œæˆã€‚\n",
        "\n",
        "**è‡³æ­¤ä¸€ä¸ªå®Œæ•´çš„4é˜¶æ®µè®­ç»ƒæµç¨‹æ¼”ç¤ºå®Œæˆã€‚**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UcSzGCDjAIcG"
      },
      "source": [
        "å®é™…æ“ä½œä¸­Stage3å’ŒStage4å¯ä»¥åå¤å¤šæ¬¡ï¼Œç›´åˆ°RLå¾—åˆ°çš„æœ€åæ¨¡å‹æ»¡è¶³è¯„ä¼°è¦æ±‚ã€‚\n",
        "\n",
        "RLHFè¿‡ç¨‹å¯ä»¥æŠŠSFTæ¨¡å‹å½“æˆä¸€ä¸ªåˆå§‹åŒ–æ¨¡å‹ï¼ŒRMæ¨¡å‹å½“åšæŒ‡å¯¼è€å¸ˆï¼Œä½¿ç”¨RL(PPO)è°ƒæ•™SFTæ¨¡å‹ç”ŸæˆæŒ‡å¯¼è€å¸ˆæœ€æ»¡æ„çš„ç»“æœï¼Œå¦‚æœå°å­¦è€å¸ˆæ»¡æ„äº†ï¼Œæˆ‘ä»¬å°±å†è®­ç»ƒä¸€ä¸ªä¸­å­¦è€å¸ˆï¼Œç»§ç»­æŒ‡å¯¼ï¼Œä¸­å­¦è€å¸ˆæ»¡æ„äº†ï¼Œå°±è®­ç»ƒä¸€ä¸ªå¤§å­¦è€å¸ˆï¼Œè¿™æ ·ä¸æ–­è¿­ä»£ï¼Œä½¿å¾—ç”Ÿæˆæ¨¡å‹çš„è´¨é‡è¾¾åˆ°ç”šè‡³è¶…è¿‡äººå·¥æ’°å†™çš„å¤©èŠ±æ¿ã€‚\n",
        "\n",
        "RLHFè®­ç»ƒä¸æ˜“ï¼Œæ­¤é¡¹ç›®æä¾›ç»™å¤§å®¶ä¸€ç§å®ç°çš„æ–¹æ³•å’Œå‚è€ƒï¼Œå¸Œæœ›æŠ›ç –å¼•ç‰ï¼Œå…±åŒä¿ƒè¿›ä¸­æ–‡å¼€æºLLMå‘å±•ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xYJYLp-uAIcH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:34:29.658428Z",
          "start_time": "2023-06-26T12:34:29.620609Z"
        },
        "id": "yfBI7V9xAIcH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lkFI4cjXAIcH"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "eDGvEazZAIcH"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:35:00.864463Z",
          "start_time": "2023-06-26T12:34:47.802087Z"
        },
        "id": "knUJKj_uAIcH"
      },
      "outputs": [],
      "source": [
        "!python inference.py --base_model merged-ppo-v1\n",
        "# æˆ–åœ¨shellä¸­è¿è¡Œ\n",
        "# !python inference.py --base_model merged-ppo-v1 --interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lWqxfnpWAIcI"
      },
      "source": [
        "Input:ä»‹ç»ä¸‹å—äº¬\n",
        "Response:  å—äº¬å¸‚ä½äºæ±Ÿè‹çœè¥¿å—éƒ¨ï¼Œæ˜¯å…¨å›½é¦–æ‰¹å†å²æ–‡åŒ–ååŸã€å›½å®¶ä¸­å¿ƒåŸå¸‚å’Œè‡ªç”±è´¸æ˜“è¯•éªŒåŒºã€‚\n",
        "\n",
        "å®Œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8R_Z1hFAIcI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}